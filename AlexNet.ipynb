{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Bk7sN8VkI92B"
      },
      "outputs": [],
      "source": [
        "%matplotlib inline"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.optim\n",
        "import torch.profiler\n",
        "import torch.utils.data\n",
        "import torchvision.datasets\n",
        "import torchvision.models\n",
        "import torchvision.transforms as T\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "import torch.utils.data as data\n",
        "\n",
        "import torchvision.transforms as transforms\n",
        "import torchvision.datasets as datasets\n",
        "import torch.optim\n",
        "import torch.profiler\n",
        "\n",
        "from sklearn import metrics\n",
        "from sklearn import decomposition\n",
        "from sklearn import manifold\n",
        "from tqdm.notebook import trange, tqdm\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "\n",
        "import copy\n",
        "import random\n",
        "import time"
      ],
      "metadata": {
        "id": "hhb07nn6I--X"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "ROOT = '.data'\n",
        "\n",
        "train_data = datasets.CIFAR10(root=ROOT,\n",
        "                              train=True,\n",
        "                              download=True)\n",
        "\n",
        "means = train_data.data.mean(axis=(0, 1, 2)) / 255\n",
        "stds = train_data.data.std(axis=(0, 1, 2)) / 255\n",
        "\n",
        "print(f'Calculated means: {means}')\n",
        "print(f'Calculated stds: {stds}')"
      ],
      "metadata": {
        "id": "wgC-hBXsI-8Q",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c3cdb4c2-02aa-4145-8075-5f4861b45bbb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz to .data/cifar-10-python.tar.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 170498071/170498071 [00:03<00:00, 47459821.17it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting .data/cifar-10-python.tar.gz to .data\n",
            "Calculated means: [0.49139968 0.48215841 0.44653091]\n",
            "Calculated stds: [0.24703223 0.24348513 0.26158784]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_transforms = transforms.Compose([\n",
        "                           transforms.RandomRotation(5),\n",
        "                           transforms.RandomHorizontalFlip(0.5),\n",
        "                           transforms.RandomCrop(32, padding=2),\n",
        "                           transforms.ToTensor(),\n",
        "                           transforms.Normalize(mean=means,\n",
        "                                                std=stds)\n",
        "                       ])\n",
        "\n",
        "test_transforms = transforms.Compose([\n",
        "                           transforms.ToTensor(),\n",
        "                           transforms.Normalize(mean=means,\n",
        "                                                std=stds)\n",
        "                       ])\n",
        "train_set = torchvision.datasets.CIFAR10(root='./data', train=True, download=True, transform=train_transforms)\n",
        "test_set = torchvision.datasets.CIFAR10(root='./data', train=False, download=True, transform=test_transforms)\n",
        "train_loader = torch.utils.data.DataLoader(train_set, batch_size=32, shuffle=True)\n",
        "test_loader = torch.utils.data.DataLoader(test_set, batch_size=32, shuffle=False)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JagmrhFZI-50",
        "outputId": "792ce94f-ea3e-4c3c-e74d-cadbd30cc723"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz to ./data/cifar-10-python.tar.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 170498071/170498071 [00:04<00:00, 37380074.19it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting ./data/cifar-10-python.tar.gz to ./data\n",
            "Files already downloaded and verified\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
      ],
      "metadata": {
        "id": "Icd24fCHI-1A"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class AlexNet(nn.Module):\n",
        "    def __init__(self, output_dim):\n",
        "        super().__init__()\n",
        "\n",
        "        self.features = nn.Sequential(\n",
        "            nn.Conv2d(3, 64, 3, 2, 1),  # in_channels, out_channels, kernel_size, stride, padding\n",
        "            nn.MaxPool2d(2),  # kernel_size\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.Conv2d(64, 192, 3, padding=1),\n",
        "            nn.MaxPool2d(2),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.Conv2d(192, 384, 3, padding=1),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.Conv2d(384, 256, 3, padding=1),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.Conv2d(256, 256, 3, padding=1),\n",
        "            nn.MaxPool2d(2),\n",
        "            nn.ReLU(inplace=True)\n",
        "        )\n",
        "\n",
        "        self.classifier = nn.Sequential(\n",
        "            nn.Dropout(0.5),\n",
        "            nn.Linear(256 * 2 * 2, 4096),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.Dropout(0.5),\n",
        "            nn.Linear(4096, 4096),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.Linear(4096, output_dim),\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.features(x)\n",
        "        h = x.view(x.shape[0], -1)\n",
        "        x = self.classifier(h)\n",
        "        return x, h"
      ],
      "metadata": {
        "id": "OhF1TjOEI-yI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "OUTPUT_DIM = 10\n",
        "\n",
        "model = AlexNet(OUTPUT_DIM)"
      ],
      "metadata": {
        "id": "1RmdkR1vJJHL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "optimizer = optim.Adam(model.parameters())\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "model = model.to(device)\n",
        "criterion = criterion.to(device)"
      ],
      "metadata": {
        "id": "wgPrmWthJKsY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Profiling"
      ],
      "metadata": {
        "id": "sJ27GdzZQvKs"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model.train()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Sh9upIVcJMGh",
        "outputId": "5d39d6cd-9560-44d4-b983-9ad5aa1fecaa"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "AlexNet(\n",
              "  (features): Sequential(\n",
              "    (0): Conv2d(3, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
              "    (1): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
              "    (2): ReLU(inplace=True)\n",
              "    (3): Conv2d(64, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "    (4): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
              "    (5): ReLU(inplace=True)\n",
              "    (6): Conv2d(192, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "    (7): ReLU(inplace=True)\n",
              "    (8): Conv2d(384, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "    (9): ReLU(inplace=True)\n",
              "    (10): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "    (11): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
              "    (12): ReLU(inplace=True)\n",
              "  )\n",
              "  (classifier): Sequential(\n",
              "    (0): Dropout(p=0.5, inplace=False)\n",
              "    (1): Linear(in_features=1024, out_features=4096, bias=True)\n",
              "    (2): ReLU(inplace=True)\n",
              "    (3): Dropout(p=0.5, inplace=False)\n",
              "    (4): Linear(in_features=4096, out_features=4096, bias=True)\n",
              "    (5): ReLU(inplace=True)\n",
              "    (6): Linear(in_features=4096, out_features=10, bias=True)\n",
              "  )\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def train(data):\n",
        "    #print(data)\n",
        "    inputs, labels = data[0].to(device=device), data[1].to(device=device)\n",
        "    outputs,_ = model(inputs)\n",
        "    loss = criterion(outputs, labels)\n",
        "    optimizer.zero_grad()\n",
        "    loss.backward()\n",
        "    optimizer.step()"
      ],
      "metadata": {
        "id": "bYCI8p9EJNyo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "prof = torch.profiler.profile(\n",
        "        schedule=torch.profiler.schedule(wait=1, warmup=1, active=3, repeat=2),\n",
        "        on_trace_ready=torch.profiler.tensorboard_trace_handler('./log/alexnet'),\n",
        "        record_shapes=True,\n",
        "        with_stack=True)\n",
        "prof.start()\n",
        "for step, batch_data in enumerate(train_loader):\n",
        "    if step >= (1 + 1 + 3) * 2:\n",
        "        break\n",
        "    train(batch_data)\n",
        "    prof.step()\n",
        "prof.stop()"
      ],
      "metadata": {
        "id": "REm5F7BbJPQc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(prof.key_averages())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Lkea-OeNJRHv",
        "outputId": "8b6c594d-7cd5-4100-9d6d-a3cbb2755bb4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "-------------------------------------------------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  \n",
            "                                                   Name    Self CPU %      Self CPU   CPU total %     CPU total  CPU time avg     Self CUDA   Self CUDA %    CUDA total  CUDA time avg    # of Calls  \n",
            "-------------------------------------------------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  \n",
            "                                          ProfilerStep*         9.41%       9.987ms        85.29%      90.513ms      30.171ms       0.000us         0.00%      30.712ms      10.237ms             3  \n",
            "enumerate(DataLoader)#_SingleProcessDataLoaderIter._...        50.19%      53.267ms        66.30%      70.359ms      23.453ms       0.000us         0.00%       0.000us       0.000us             3  \n",
            "void at::native::reduce_kernel<512, 1, at::native::R...         0.00%       0.000us         0.00%       0.000us       0.000us     417.000us         0.75%     417.000us      20.850us            20  \n",
            "void at::native::vectorized_elementwise_kernel<4, at...         0.00%       0.000us         0.00%       0.000us       0.000us     177.000us         0.32%     177.000us       7.080us            25  \n",
            "void cudnn::winograd_nonfused::winogradForwardData4x...         0.00%       0.000us         0.00%       0.000us       0.000us     718.000us         1.29%     718.000us      35.900us            20  \n",
            "void cudnn::winograd_nonfused::winogradForwardFilter...         0.00%       0.000us         0.00%       0.000us       0.000us       1.300ms         2.33%       1.300ms      65.000us            20  \n",
            "                                   volta_sgemm_64x64_nt         0.00%       0.000us         0.00%       0.000us       0.000us       2.855ms         5.12%       2.855ms     150.263us            19  \n",
            "                                            aten::empty         0.86%     915.000us         0.86%     915.000us       1.784us       0.000us         0.00%       0.000us       0.000us           513  \n",
            "                                         aten::uniform_         0.54%     575.000us         0.54%     575.000us       2.995us       0.000us         0.00%       0.000us       0.000us           192  \n",
            "                                             aten::item         0.72%     763.000us         0.77%     819.000us       1.422us       0.000us         0.00%       0.000us       0.000us           576  \n",
            "                              aten::_local_scalar_dense         0.07%      74.000us         0.07%      74.000us       0.128us       0.000us         0.00%       0.000us       0.000us           576  \n",
            "void cudnn::winograd_nonfused::winogradForwardOutput...         0.00%       0.000us         0.00%       0.000us       0.000us     694.000us         1.24%     694.000us      34.700us            20  \n",
            "cask_cudnn::computeWgradSplitKOffsetsKernel(cask_cud...         0.00%       0.000us         0.00%       0.000us       0.000us      28.000us         0.05%      28.000us       4.000us             7  \n",
            "cask_cudnn::computeWgradBOffsetsKernel(cask_cudnn::C...         0.00%       0.000us         0.00%       0.000us       0.000us      28.000us         0.05%      28.000us       4.000us             7  \n",
            "                                             aten::rand         0.49%     517.000us         0.78%     828.000us       8.625us       0.000us         0.00%       0.000us       0.000us            96  \n",
            "                                        Memset (Device)         0.00%       0.000us         0.00%       0.000us       0.000us     137.000us         0.25%     137.000us       7.611us            18  \n",
            "cudnn_volta_scudnn_128x32_stridedB_splitK_small_nn_v...         0.00%       0.000us         0.00%       0.000us       0.000us       3.128ms         5.61%       3.128ms     446.857us             7  \n",
            "                                               aten::lt         0.74%     781.000us         1.80%       1.910ms      19.896us       0.000us         0.00%       0.000us       0.000us            96  \n",
            "                                               aten::to         1.06%       1.128ms         5.04%       5.348ms       8.409us       0.000us         0.00%     103.000us       0.162us           636  \n",
            "                                         aten::_to_copy         2.44%       2.594ms         4.21%       4.472ms       7.098us       0.000us         0.00%     105.000us       0.167us           630  \n",
            "                                    aten::empty_strided         1.16%       1.226ms         1.16%       1.226ms       1.465us       0.000us         0.00%       0.000us       0.000us           837  \n",
            "                                            aten::copy_         1.53%       1.620ms         2.00%       2.122ms       2.582us     105.000us         0.19%     105.000us       0.128us           822  \n",
            "                                       aten::is_nonzero         0.31%     325.000us         0.61%     648.000us       3.375us       0.000us         0.00%       0.000us       0.000us           192  \n",
            "                                          aten::randint         0.79%     841.000us         1.14%       1.206ms       6.281us       0.000us         0.00%       0.000us       0.000us           192  \n",
            "                                          aten::random_         0.22%     235.000us         0.22%     235.000us       1.224us       0.000us         0.00%       0.000us       0.000us           192  \n",
            "                                       aten::lift_fresh         0.13%     140.000us         0.13%     140.000us       0.481us       0.000us         0.00%       0.000us       0.000us           291  \n",
            "                                             aten::view         0.78%     824.000us         0.78%     824.000us       2.719us       0.000us         0.00%       0.000us       0.000us           303  \n",
            "                                          aten::permute         0.55%     586.000us         0.67%     708.000us       7.375us       0.000us         0.00%       0.000us       0.000us            96  \n",
            "                                       aten::as_strided         0.19%     202.000us         0.19%     202.000us       0.802us       0.000us         0.00%       0.000us       0.000us           252  \n",
            "                                       aten::contiguous         0.24%     255.000us         1.53%       1.625ms      16.927us       0.000us         0.00%       0.000us       0.000us            96  \n",
            "                                            aten::clone         0.83%     881.000us         2.10%       2.231ms      11.620us       0.000us         0.00%       0.000us       0.000us           192  \n",
            "                                       aten::empty_like         0.30%     315.000us         0.64%     674.000us       5.761us       0.000us         0.00%       0.000us       0.000us           117  \n",
            "                                              aten::div         0.80%     854.000us         1.34%       1.420ms      14.792us       0.000us         0.00%       0.000us       0.000us            96  \n",
            "                                               aten::eq         0.66%     705.000us         1.20%       1.277ms      13.302us       0.000us         0.00%       0.000us       0.000us            96  \n",
            "                                              aten::any         0.88%     938.000us         0.93%     985.000us      10.260us       0.000us         0.00%       0.000us       0.000us            96  \n",
            "                                            aten::fill_         0.14%     146.000us         0.28%     298.000us       2.685us      81.000us         0.15%      81.000us       0.730us           111  \n",
            "void cudnn::winograd_nonfused::winogradWgradData4x4<...         0.00%       0.000us         0.00%       0.000us       0.000us     128.000us         0.23%     128.000us      16.000us             8  \n",
            "                                             aten::sub_         0.54%     571.000us         0.54%     571.000us       5.948us       0.000us         0.00%       0.000us       0.000us            96  \n",
            "                                             aten::div_         0.31%     327.000us         0.31%     327.000us       3.406us       0.000us         0.00%       0.000us       0.000us            96  \n",
            "void cudnn::winograd_nonfused::winogradWgradDelta4x4...         0.00%       0.000us         0.00%       0.000us       0.000us     181.000us         0.32%     181.000us      22.625us             8  \n",
            "void cudnn::winograd_nonfused::winogradWgradOutput4x...         0.00%       0.000us         0.00%       0.000us       0.000us     979.000us         1.75%     979.000us     122.375us             8  \n",
            "void at::native::vectorized_elementwise_kernel<4, at...         0.00%       0.000us         0.00%       0.000us       0.000us      97.000us         0.17%      97.000us       5.706us            17  \n",
            "void at::native::(anonymous namespace)::max_pool_bac...         0.00%       0.000us         0.00%       0.000us       0.000us       1.466ms         2.63%       1.466ms     133.273us            11  \n",
            "void cudnn::winograd::generateWinogradTilesKernel<0,...         0.00%       0.000us         0.00%       0.000us       0.000us      32.000us         0.06%      32.000us       8.000us             4  \n",
            "cudnn_volta_scudnn_winograd_128x128_ldg1_ldg4_relu_t...         0.00%       0.000us         0.00%       0.000us       0.000us       1.040ms         1.86%       1.040ms     260.000us             4  \n",
            "void wgrad_alg0_engine<float, 128, 5, 5, 3, 3, 3, fa...         0.00%       0.000us         0.00%       0.000us       0.000us     300.000us         0.54%     300.000us      75.000us             4  \n",
            "void at::native::(anonymous namespace)::multi_tensor...         0.00%       0.000us         0.00%       0.000us       0.000us       6.374ms        11.42%       6.374ms     398.375us            16  \n",
            "void at::native::(anonymous namespace)::multi_tensor...         0.00%       0.000us         0.00%       0.000us       0.000us       4.571ms         8.19%       4.571ms     571.375us             8  \n",
            "void at::native::(anonymous namespace)::multi_tensor...         0.00%       0.000us         0.00%       0.000us       0.000us       4.590ms         8.22%       4.590ms     573.750us             8  \n",
            "void at::native::(anonymous namespace)::multi_tensor...         0.00%       0.000us         0.00%       0.000us       0.000us       3.271ms         5.86%       3.271ms     408.875us             8  \n",
            "void at::native::(anonymous namespace)::multi_tensor...         0.00%       0.000us         0.00%       0.000us       0.000us       3.321ms         5.95%       3.321ms     415.125us             8  \n",
            "void at::native::(anonymous namespace)::multi_tensor...         0.00%       0.000us         0.00%       0.000us       0.000us       3.207ms         5.75%       3.207ms     400.875us             8  \n",
            "void at::native::(anonymous namespace)::multi_tensor...         0.00%       0.000us         0.00%       0.000us       0.000us       6.043ms        10.83%       6.043ms     755.375us             8  \n",
            "                                            aten::stack         0.04%      43.000us         0.24%     253.000us      84.333us       0.000us         0.00%       0.000us       0.000us             3  \n",
            "                                              aten::cat         0.19%     204.000us         0.19%     204.000us      68.000us       0.000us         0.00%       0.000us       0.000us             3  \n",
            "                                          aten::detach_         0.01%       7.000us         0.01%      10.000us       3.333us       0.000us         0.00%       0.000us       0.000us             3  \n",
            "                                                detach_         0.00%       3.000us         0.00%       3.000us       1.000us       0.000us         0.00%       0.000us       0.000us             3  \n",
            "                                        cudaMemcpyAsync         0.34%     358.000us         0.34%     358.000us      59.667us       0.000us         0.00%       0.000us       0.000us             6  \n",
            "                                  cudaStreamSynchronize         0.14%     144.000us         0.14%     144.000us      24.000us       0.000us         0.00%       0.000us       0.000us             6  \n",
            "                       Memcpy HtoD (Pageable -> Device)         0.00%       0.000us         0.00%       0.000us       0.000us     105.000us         0.19%     105.000us      17.500us             6  \n",
            "                                           aten::conv2d         0.07%      73.000us         2.06%       2.190ms     146.000us       0.000us         0.00%       4.185ms     279.000us            15  \n",
            "                                      aten::convolution         0.15%     162.000us         1.99%       2.117ms     141.133us       0.000us         0.00%       4.185ms     279.000us            15  \n",
            "                                     aten::_convolution         0.19%     197.000us         1.84%       1.955ms     130.333us       0.000us         0.00%       4.185ms     279.000us            15  \n",
            "                                aten::cudnn_convolution         0.87%     923.000us         1.26%       1.337ms      89.133us       3.990ms         7.15%       3.990ms     266.000us            15  \n",
            "                                  cudaStreamIsCapturing         0.04%      39.000us         0.04%      39.000us       0.765us       0.000us         0.00%       0.000us       0.000us            51  \n",
            "                                  cudaStreamGetPriority         0.00%       0.000us         0.00%       0.000us       0.000us       0.000us         0.00%       0.000us       0.000us            42  \n",
            "                       cudaDeviceGetStreamPriorityRange         0.01%       9.000us         0.01%       9.000us       0.214us       0.000us         0.00%       0.000us       0.000us            42  \n",
            "                                       cudaLaunchKernel         2.56%       2.722ms         2.56%       2.722ms       7.499us       0.000us         0.00%       0.000us       0.000us           363  \n",
            "void cask_cudnn::computeOffsetsKernel<false, false>(...         0.00%       0.000us         0.00%       0.000us       0.000us      30.000us         0.05%      30.000us       5.000us             6  \n",
            "                                        cudaMemsetAsync         0.12%     129.000us         0.12%     129.000us       6.143us       0.000us         0.00%       0.000us       0.000us            21  \n",
            "            cudnn_volta_scudnn_128x32_relu_medium_nn_v1         0.00%       0.000us         0.00%       0.000us       0.000us     107.000us         0.19%     107.000us      35.667us             3  \n",
            "                                          aten::reshape         0.09%      95.000us         0.11%     122.000us       6.778us       0.000us         0.00%       0.000us       0.000us            18  \n",
            "                                   aten::_reshape_alias         0.03%      29.000us         0.03%      29.000us       1.611us       0.000us         0.00%       0.000us       0.000us            18  \n",
            "                                             aten::add_         0.44%     462.000us         0.75%     799.000us      11.414us     195.000us         0.35%     195.000us       2.786us            70  \n",
            "void at::native::elementwise_kernel<128, 2, at::nati...         0.00%       0.000us         0.00%       0.000us       0.000us     195.000us         0.35%     195.000us      13.000us            15  \n",
            "                                       aten::max_pool2d         0.05%      58.000us         0.36%     384.000us      42.667us       0.000us         0.00%     130.000us      14.444us             9  \n",
            "                          aten::max_pool2d_with_indices         0.22%     235.000us         0.34%     357.000us      39.667us     153.000us         0.27%     153.000us      17.000us             9  \n",
            "void at::native::(anonymous namespace)::max_pool_for...         0.00%       0.000us         0.00%       0.000us       0.000us     153.000us         0.27%     153.000us      17.000us             9  \n",
            "                                            aten::relu_         0.30%     315.000us         0.66%     702.000us      33.429us       0.000us         0.00%     114.000us       5.429us            21  \n",
            "                                       aten::clamp_min_         0.22%     229.000us         0.36%     387.000us      18.429us     114.000us         0.20%     114.000us       5.429us            21  \n",
            "void at::native::vectorized_elementwise_kernel<4, at...         0.00%       0.000us         0.00%       0.000us       0.000us     114.000us         0.20%     114.000us       5.429us            21  \n",
            "                                  volta_sgemm_128x64_nn         0.00%       0.000us         0.00%       0.000us       0.000us     195.000us         0.35%     195.000us      65.000us             3  \n",
            "                                   volta_sgemm_64x64_nn         0.00%       0.000us         0.00%       0.000us       0.000us       1.028ms         1.84%       1.028ms     171.333us             6  \n",
            "void cudnn::ops::nchwToNhwcKernel<float, float, floa...         0.00%       0.000us         0.00%       0.000us       0.000us     229.000us         0.41%     229.000us      38.167us             6  \n",
            "cudnn_volta_scudnn_128x32_sliced1x4_ldg4_relu_exp_me...         0.00%       0.000us         0.00%       0.000us       0.000us       1.384ms         2.48%       1.384ms     461.333us             3  \n",
            "                                          aten::dropout         0.02%      20.000us         0.40%     420.000us      70.000us       0.000us         0.00%      53.000us       8.833us             6  \n",
            "                                   aten::native_dropout         0.17%     185.000us         0.38%     400.000us      66.667us      53.000us         0.09%      53.000us       8.833us             6  \n",
            "void cudnn::ops::nhwcToNchwKernel<float, float, floa...         0.00%       0.000us         0.00%       0.000us       0.000us      31.000us         0.06%      31.000us      10.333us             3  \n",
            "                                           aten::linear         0.04%      44.000us         0.83%     884.000us      98.222us       0.000us         0.00%       2.541ms     282.333us             9  \n",
            "                                                aten::t         0.15%     162.000us         0.29%     307.000us       6.822us       0.000us         0.00%       0.000us       0.000us            45  \n",
            "                                        aten::transpose         0.11%     117.000us         0.14%     145.000us       3.222us       0.000us         0.00%       0.000us       0.000us            45  \n",
            "                                            aten::addmm         0.48%     505.000us         0.68%     724.000us      80.444us       2.541ms         4.55%       2.541ms     282.333us             9  \n",
            "          cudaOccupancyMaxActiveBlocksPerMultiprocessor         0.02%      25.000us         0.02%      25.000us       1.389us       0.000us         0.00%       0.000us       0.000us            18  \n",
            "void at::native::(anonymous namespace)::fused_dropou...         0.00%       0.000us         0.00%       0.000us       0.000us      53.000us         0.09%      53.000us       8.833us             6  \n",
            "                        volta_sgemm_128x32_sliced1x4_tn         0.00%       0.000us         0.00%       0.000us       0.000us       2.451ms         4.39%       2.451ms     408.500us             6  \n",
            "                               aten::cross_entropy_loss         0.02%      22.000us         0.23%     249.000us      83.000us       0.000us         0.00%      30.000us      10.000us             3  \n",
            "                                      aten::log_softmax         0.02%      18.000us         0.11%     113.000us      37.667us       0.000us         0.00%      15.000us       5.000us             3  \n",
            "                                     aten::_log_softmax         0.06%      67.000us         0.09%      95.000us      31.667us      15.000us         0.03%      15.000us       5.000us             3  \n",
            "                                      aten::nll_loss_nd         0.01%       7.000us         0.11%     114.000us      38.000us       0.000us         0.00%      15.000us       5.000us             3  \n",
            "                                         aten::nll_loss         0.01%      11.000us         0.10%     107.000us      35.667us       0.000us         0.00%      15.000us       5.000us             3  \n",
            "-------------------------------------------------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  \n",
            "Self CPU time total: 106.127ms\n",
            "Self CUDA time total: 55.807ms\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(prof.key_averages().table(sort_by=\"cpu_time_total\", row_limit=10))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "f1tpbBjuJbtw",
        "outputId": "25c1609a-5ca5-4198-ad5d-2882524e6db9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "-------------------------------------------------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  \n",
            "                                                   Name    Self CPU %      Self CPU   CPU total %     CPU total  CPU time avg     Self CUDA   Self CUDA %    CUDA total  CUDA time avg    # of Calls  \n",
            "-------------------------------------------------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  \n",
            "                                          ProfilerStep*         9.41%       9.987ms        85.29%      90.513ms      30.171ms       0.000us         0.00%      30.712ms      10.237ms             3  \n",
            "enumerate(DataLoader)#_SingleProcessDataLoaderIter._...        50.19%      53.267ms        66.30%      70.359ms      23.453ms       0.000us         0.00%       0.000us       0.000us             3  \n",
            "                                  cudaDeviceSynchronize         8.76%       9.294ms         8.76%       9.294ms       9.294ms       0.000us         0.00%       0.000us       0.000us             1  \n",
            "                                               aten::to         1.06%       1.128ms         5.04%       5.348ms       8.409us       0.000us         0.00%     103.000us       0.162us           636  \n",
            "                                         aten::_to_copy         2.44%       2.594ms         4.21%       4.472ms       7.098us       0.000us         0.00%     105.000us       0.167us           630  \n",
            "                               Optimizer.step#Adam.step         1.90%       2.018ms         3.94%       4.178ms       1.393ms       0.000us         0.00%      23.522ms       7.841ms             3  \n",
            "                                       cudaLaunchKernel         2.56%       2.722ms         2.56%       2.722ms       7.499us       0.000us         0.00%       0.000us       0.000us           363  \n",
            "autograd::engine::evaluate_function: ConvolutionBack...         0.15%     154.000us         2.54%       2.695ms     179.667us       0.000us         0.00%       8.708ms     580.533us            15  \n",
            "                                   ConvolutionBackward0         0.08%      86.000us         2.39%       2.541ms     169.400us       0.000us         0.00%       8.708ms     580.533us            15  \n",
            "                             aten::convolution_backward         1.23%       1.305ms         2.31%       2.455ms     163.667us       8.396ms        15.04%       8.708ms     580.533us            15  \n",
            "-------------------------------------------------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  \n",
            "Self CPU time total: 106.127ms\n",
            "Self CUDA time total: 55.807ms\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(prof.key_averages(group_by_input_shape=True).table(sort_by=\"cpu_time_total\", row_limit=10))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eG-JUCXGJe2b",
        "outputId": "1a637ade-1b36-4604-9d21-0df483cf6775"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "-------------------------------------------------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  --------------------------------------------------------------------------------  \n",
            "                                                   Name    Self CPU %      Self CPU   CPU total %     CPU total  CPU time avg     Self CUDA   Self CUDA %    CUDA total  CUDA time avg    # of Calls                                                                      Input Shapes  \n",
            "-------------------------------------------------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  --------------------------------------------------------------------------------  \n",
            "                                          ProfilerStep*         9.41%       9.987ms        85.29%      90.513ms      30.171ms       0.000us         0.00%      30.712ms      10.237ms             3                                                                                []  \n",
            "enumerate(DataLoader)#_SingleProcessDataLoaderIter._...        50.19%      53.267ms        66.30%      70.359ms      23.453ms       0.000us         0.00%       0.000us       0.000us             3                                                                                []  \n",
            "                                  cudaDeviceSynchronize         8.76%       9.294ms         8.76%       9.294ms       9.294ms       0.000us         0.00%       0.000us       0.000us             1                                                                                []  \n",
            "                               Optimizer.step#Adam.step         1.90%       2.018ms         3.94%       4.178ms       1.393ms       0.000us         0.00%      23.522ms       7.841ms             3                                                                                []  \n",
            "                                       cudaLaunchKernel         2.56%       2.722ms         2.56%       2.722ms       7.499us       0.000us         0.00%       0.000us       0.000us           363                                                                                []  \n",
            "autograd::engine::evaluate_function: ConvolutionBack...         0.15%     154.000us         2.54%       2.695ms     179.667us       0.000us         0.00%       8.708ms     580.533us            15                                                                                []  \n",
            "                                               aten::to         0.48%     507.000us         2.23%       2.362ms       7.030us       0.000us         0.00%       0.000us       0.000us           336                                                              [[], [], [], [], []]  \n",
            "                                            aten::clone         0.83%     881.000us         2.10%       2.231ms      11.620us       0.000us         0.00%       0.000us       0.000us           192                                                                 [[3, 32, 32], []]  \n",
            "                                         aten::_to_copy         1.27%       1.350ms         1.83%       1.946ms       5.792us       0.000us         0.00%       0.000us       0.000us           336                                                      [[], [], [], [], [], [], []]  \n",
            "                                               aten::lt         0.74%     781.000us         1.80%       1.910ms      19.896us       0.000us         0.00%       0.000us       0.000us            96                                                                         [[1], []]  \n",
            "-------------------------------------------------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  --------------------------------------------------------------------------------  \n",
            "Self CPU time total: 106.127ms\n",
            "Self CUDA time total: 55.807ms\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(prof.key_averages().table(sort_by=\"cuda_time_total\", row_limit=10))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EYs1AetHJhUr",
        "outputId": "0c444280-3dca-41cd-eb84-842615ee9daf"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "-------------------------------------------------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  \n",
            "                                                   Name    Self CPU %      Self CPU   CPU total %     CPU total  CPU time avg     Self CUDA   Self CUDA %    CUDA total  CUDA time avg    # of Calls  \n",
            "-------------------------------------------------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  \n",
            "                                          ProfilerStep*         9.41%       9.987ms        85.29%      90.513ms      30.171ms       0.000us         0.00%      30.712ms      10.237ms             3  \n",
            "                               Optimizer.step#Adam.step         1.90%       2.018ms         3.94%       4.178ms       1.393ms       0.000us         0.00%      23.522ms       7.841ms             3  \n",
            "autograd::engine::evaluate_function: ConvolutionBack...         0.15%     154.000us         2.54%       2.695ms     179.667us       0.000us         0.00%       8.708ms     580.533us            15  \n",
            "                                   ConvolutionBackward0         0.08%      86.000us         2.39%       2.541ms     169.400us       0.000us         0.00%       8.708ms     580.533us            15  \n",
            "                             aten::convolution_backward         1.23%       1.305ms         2.31%       2.455ms     163.667us       8.396ms        15.04%       8.708ms     580.533us            15  \n",
            "void at::native::(anonymous namespace)::multi_tensor...         0.00%       0.000us         0.00%       0.000us       0.000us       6.374ms        11.42%       6.374ms     398.375us            16  \n",
            "void at::native::(anonymous namespace)::multi_tensor...         0.00%       0.000us         0.00%       0.000us       0.000us       6.043ms        10.83%       6.043ms     755.375us             8  \n",
            "                                    aten::_foreach_mul_         0.16%     166.000us         0.28%     293.000us      48.833us       4.772ms         8.55%       4.772ms     795.333us             6  \n",
            "void at::native::(anonymous namespace)::multi_tensor...         0.00%       0.000us         0.00%       0.000us       0.000us       4.590ms         8.22%       4.590ms     573.750us             8  \n",
            "void at::native::(anonymous namespace)::multi_tensor...         0.00%       0.000us         0.00%       0.000us       0.000us       4.571ms         8.19%       4.571ms     571.375us             8  \n",
            "-------------------------------------------------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  \n",
            "Self CPU time total: 106.127ms\n",
            "Self CUDA time total: 55.807ms\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(prof.key_averages().table(sort_by=\"self_cpu_memory_usage\", row_limit=10))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BUlle4EGJjTX",
        "outputId": "2827ae2d-9d0c-45f9-db09-595ed098e45e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "-------------------------------------------------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  \n",
            "                                                   Name    Self CPU %      Self CPU   CPU total %     CPU total  CPU time avg     Self CUDA   Self CUDA %    CUDA total  CUDA time avg    # of Calls  \n",
            "-------------------------------------------------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  \n",
            "                                          ProfilerStep*         9.41%       9.987ms        85.29%      90.513ms      30.171ms       0.000us         0.00%      30.712ms      10.237ms             3  \n",
            "enumerate(DataLoader)#_SingleProcessDataLoaderIter._...        50.19%      53.267ms        66.30%      70.359ms      23.453ms       0.000us         0.00%       0.000us       0.000us             3  \n",
            "void at::native::reduce_kernel<512, 1, at::native::R...         0.00%       0.000us         0.00%       0.000us       0.000us     417.000us         0.75%     417.000us      20.850us            20  \n",
            "void at::native::vectorized_elementwise_kernel<4, at...         0.00%       0.000us         0.00%       0.000us       0.000us     177.000us         0.32%     177.000us       7.080us            25  \n",
            "void cudnn::winograd_nonfused::winogradForwardData4x...         0.00%       0.000us         0.00%       0.000us       0.000us     718.000us         1.29%     718.000us      35.900us            20  \n",
            "void cudnn::winograd_nonfused::winogradForwardFilter...         0.00%       0.000us         0.00%       0.000us       0.000us       1.300ms         2.33%       1.300ms      65.000us            20  \n",
            "                                   volta_sgemm_64x64_nt         0.00%       0.000us         0.00%       0.000us       0.000us       2.855ms         5.12%       2.855ms     150.263us            19  \n",
            "                                            aten::empty         0.86%     915.000us         0.86%     915.000us       1.784us       0.000us         0.00%       0.000us       0.000us           513  \n",
            "                                         aten::uniform_         0.54%     575.000us         0.54%     575.000us       2.995us       0.000us         0.00%       0.000us       0.000us           192  \n",
            "                                             aten::item         0.72%     763.000us         0.77%     819.000us       1.422us       0.000us         0.00%       0.000us       0.000us           576  \n",
            "-------------------------------------------------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  \n",
            "Self CPU time total: 106.127ms\n",
            "Self CUDA time total: 55.807ms\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(prof.key_averages().table(sort_by=\"cpu_memory_usage\", row_limit=10))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wY7jCw1jJlS-",
        "outputId": "627998fe-bc74-49ad-f58e-482e82ae0a90"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "-------------------------------------------------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  \n",
            "                                                   Name    Self CPU %      Self CPU   CPU total %     CPU total  CPU time avg     Self CUDA   Self CUDA %    CUDA total  CUDA time avg    # of Calls  \n",
            "-------------------------------------------------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  \n",
            "                                          ProfilerStep*         9.41%       9.987ms        85.29%      90.513ms      30.171ms       0.000us         0.00%      30.712ms      10.237ms             3  \n",
            "enumerate(DataLoader)#_SingleProcessDataLoaderIter._...        50.19%      53.267ms        66.30%      70.359ms      23.453ms       0.000us         0.00%       0.000us       0.000us             3  \n",
            "void at::native::reduce_kernel<512, 1, at::native::R...         0.00%       0.000us         0.00%       0.000us       0.000us     417.000us         0.75%     417.000us      20.850us            20  \n",
            "void at::native::vectorized_elementwise_kernel<4, at...         0.00%       0.000us         0.00%       0.000us       0.000us     177.000us         0.32%     177.000us       7.080us            25  \n",
            "void cudnn::winograd_nonfused::winogradForwardData4x...         0.00%       0.000us         0.00%       0.000us       0.000us     718.000us         1.29%     718.000us      35.900us            20  \n",
            "void cudnn::winograd_nonfused::winogradForwardFilter...         0.00%       0.000us         0.00%       0.000us       0.000us       1.300ms         2.33%       1.300ms      65.000us            20  \n",
            "                                   volta_sgemm_64x64_nt         0.00%       0.000us         0.00%       0.000us       0.000us       2.855ms         5.12%       2.855ms     150.263us            19  \n",
            "                                            aten::empty         0.86%     915.000us         0.86%     915.000us       1.784us       0.000us         0.00%       0.000us       0.000us           513  \n",
            "                                         aten::uniform_         0.54%     575.000us         0.54%     575.000us       2.995us       0.000us         0.00%       0.000us       0.000us           192  \n",
            "                                             aten::item         0.72%     763.000us         0.77%     819.000us       1.422us       0.000us         0.00%       0.000us       0.000us           576  \n",
            "-------------------------------------------------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  \n",
            "Self CPU time total: 106.127ms\n",
            "Self CUDA time total: 55.807ms\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(prof.key_averages(group_by_stack_n=5).table(sort_by=\"self_cuda_time_total\", row_limit=2))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-6JeJkznJnFL",
        "outputId": "2ed6c9cd-96c4-4ed9-a726-3203fd617b28"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "-------------------------------------------------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  \n",
            "                                                   Name    Self CPU %      Self CPU   CPU total %     CPU total  CPU time avg     Self CUDA   Self CUDA %    CUDA total  CUDA time avg    # of Calls  \n",
            "-------------------------------------------------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  \n",
            "                             aten::convolution_backward         1.23%       1.305ms         2.31%       2.455ms     163.667us       8.396ms        15.04%       8.708ms     580.533us            15  \n",
            "void at::native::(anonymous namespace)::multi_tensor...         0.00%       0.000us         0.00%       0.000us       0.000us       6.374ms        11.42%       6.374ms     398.375us            16  \n",
            "-------------------------------------------------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  \n",
            "Self CPU time total: 106.127ms\n",
            "Self CUDA time total: 55.807ms\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UGhIqttCJo5u",
        "outputId": "891d4458-8068-45f1-f325-3291005873d7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!mv /content/log /content/drive/MyDrive"
      ],
      "metadata": {
        "id": "uefqh6jPJ7Kc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Profiling with Automatic Mixed Precision"
      ],
      "metadata": {
        "id": "NRigkrENP1Tm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch, time, gc\n",
        "\n",
        "# Timing utilities\n",
        "start_time = None\n",
        "\n",
        "def start_timer():\n",
        "    global start_time\n",
        "    gc.collect()\n",
        "    torch.cuda.empty_cache()\n",
        "    torch.cuda.reset_max_memory_allocated()\n",
        "    torch.cuda.synchronize()\n",
        "    start_time = time.time()\n",
        "\n",
        "def end_timer_and_print(local_msg):\n",
        "    torch.cuda.synchronize()\n",
        "    end_time = time.time()\n",
        "    print(\"\\n\" + local_msg)\n",
        "    print(\"Total execution time = {:.3f} sec\".format(end_time - start_time))\n",
        "    print(\"Max memory used by tensors = {} bytes\".format(torch.cuda.max_memory_allocated()))"
      ],
      "metadata": {
        "id": "VsLH_Xq_KdwN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.train()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "A7_jrcg-Q9rm",
        "outputId": "d0fade05-1bb7-4645-998e-9657ad462093"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "AlexNet(\n",
              "  (features): Sequential(\n",
              "    (0): Conv2d(3, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
              "    (1): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
              "    (2): ReLU(inplace=True)\n",
              "    (3): Conv2d(64, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "    (4): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
              "    (5): ReLU(inplace=True)\n",
              "    (6): Conv2d(192, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "    (7): ReLU(inplace=True)\n",
              "    (8): Conv2d(384, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "    (9): ReLU(inplace=True)\n",
              "    (10): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "    (11): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
              "    (12): ReLU(inplace=True)\n",
              "  )\n",
              "  (classifier): Sequential(\n",
              "    (0): Dropout(p=0.5, inplace=False)\n",
              "    (1): Linear(in_features=1024, out_features=4096, bias=True)\n",
              "    (2): ReLU(inplace=True)\n",
              "    (3): Dropout(p=0.5, inplace=False)\n",
              "    (4): Linear(in_features=4096, out_features=4096, bias=True)\n",
              "    (5): ReLU(inplace=True)\n",
              "    (6): Linear(in_features=4096, out_features=10, bias=True)\n",
              "  )\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "use_amp = True\n",
        "scaler = torch.cuda.amp.GradScaler(enabled=use_amp)\n",
        "\n",
        "def train(data):\n",
        "  inputs, labels = data[0].to(device=device), data[1].to(device=device)\n",
        "  with torch.autocast(device_type='cuda', dtype=torch.float16, enabled=use_amp):\n",
        "    outputs,_ = model(inputs)\n",
        "    loss = criterion(outputs, labels)\n",
        "  scaler.scale(loss).backward()\n",
        "  scaler.step(optimizer)\n",
        "  scaler.update()\n",
        "  optimizer.zero_grad() # set_to_non"
      ],
      "metadata": {
        "id": "VTT_3WVRRBq0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "prof = torch.profiler.profile(\n",
        "        schedule=torch.profiler.schedule(wait=1, warmup=1, active=3, repeat=2),\n",
        "        on_trace_ready=torch.profiler.tensorboard_trace_handler('./log/alexnet_amp'),\n",
        "        record_shapes=True,\n",
        "        with_stack=True)\n",
        "prof.start()\n",
        "start_timer()\n",
        "for step, batch_data in enumerate(train_loader):\n",
        "\n",
        "    if step >= (1 + 1 + 3) * 2:\n",
        "        break\n",
        "    train(batch_data)\n",
        "    prof.step()\n",
        "prof.stop()\n",
        "end_timer_and_print(\"Mixed precision:\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XJJr__9qSMLb",
        "outputId": "f7fbfe3e-9378-4bf3-f344-40686284088d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/cuda/memory.py:303: FutureWarning: torch.cuda.reset_max_memory_allocated now calls torch.cuda.reset_peak_memory_stats, which resets /all/ peak memory stats.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Mixed precision:\n",
            "Total execution time = 10.659 sec\n",
            "Max memory used by tensors = 577026560 bytes\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(prof.key_averages())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Yymu1yPaSr6l",
        "outputId": "7642a5f1-3b00-4328-821a-046b1eb3a94f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "-------------------------------------------------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  \n",
            "                                                   Name    Self CPU %      Self CPU   CPU total %     CPU total  CPU time avg     Self CUDA   Self CUDA %    CUDA total  CUDA time avg    # of Calls  \n",
            "-------------------------------------------------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  \n",
            "                                          ProfilerStep*        11.31%      13.824ms        87.51%     106.940ms      35.647ms       0.000us         0.00%      35.042ms      11.681ms             3  \n",
            "enumerate(DataLoader)#_SingleProcessDataLoaderIter._...        46.65%      57.003ms        62.15%      75.945ms      25.315ms       0.000us         0.00%       0.000us       0.000us             3  \n",
            "                                            aten::empty         0.82%       1.007ms         0.82%       1.007ms       1.952us       0.000us         0.00%       0.000us       0.000us           516  \n",
            "                                         aten::uniform_         0.52%     638.000us         0.52%     638.000us       3.323us       0.000us         0.00%       0.000us       0.000us           192  \n",
            "                                             aten::item         0.66%     801.000us         3.86%       4.717ms       8.147us       0.000us         0.00%      40.000us       0.069us           579  \n",
            "                              aten::_local_scalar_dense         0.03%      34.000us         3.21%       3.919ms       6.769us       6.000us         0.01%      40.000us       0.069us           579  \n",
            "void at::native::(anonymous namespace)::multi_tensor...         0.00%       0.000us         0.00%       0.000us       0.000us       3.584ms         7.33%       3.584ms     512.000us             7  \n",
            "                                             aten::rand         0.44%     543.000us         0.73%     889.000us       9.260us       0.000us         0.00%       0.000us       0.000us            96  \n",
            "                                               aten::lt         0.74%     901.000us         1.71%       2.085ms      21.719us       0.000us         0.00%       0.000us       0.000us            96  \n",
            "                                               aten::to         1.36%       1.663ms         8.05%       9.832ms      12.954us       0.000us         0.00%       5.074ms       6.685us           759  \n",
            "                                         aten::_to_copy         2.90%       3.544ms         7.03%       8.594ms      11.505us       0.000us         0.00%       5.727ms       7.667us           747  \n",
            "                                    aten::empty_strided         1.77%       2.159ms         1.77%       2.159ms       2.263us       0.000us         0.00%       0.000us       0.000us           954  \n",
            "                                            aten::copy_         2.38%       2.909ms         3.67%       4.480ms       4.771us       5.696ms        11.65%       5.731ms       6.103us           939  \n",
            "                                       aten::is_nonzero         0.26%     320.000us         0.50%     611.000us       3.182us       0.000us         0.00%       0.000us       0.000us           192  \n",
            "void at::native::(anonymous namespace)::multi_tensor...         0.00%       0.000us         0.00%       0.000us       0.000us       5.579ms        11.41%       5.579ms     398.500us            14  \n",
            "                                          aten::randint         0.73%     897.000us         1.17%       1.434ms       7.469us       0.000us         0.00%       0.000us       0.000us           192  \n",
            "                                          aten::random_         0.27%     334.000us         0.27%     334.000us       1.740us       0.000us         0.00%       0.000us       0.000us           192  \n",
            "                                       aten::lift_fresh         0.11%     133.000us         0.11%     133.000us       0.457us       0.000us         0.00%       0.000us       0.000us           291  \n",
            "                                             aten::view         0.69%     849.000us         0.69%     849.000us       2.802us       0.000us         0.00%       0.000us       0.000us           303  \n",
            "                                          aten::permute         0.52%     632.000us         0.62%     755.000us       7.865us       0.000us         0.00%       0.000us       0.000us            96  \n",
            "                                       aten::as_strided         0.23%     277.000us         0.23%     277.000us       1.086us       0.000us         0.00%       0.000us       0.000us           255  \n",
            "                                       aten::contiguous         0.28%     338.000us         1.43%       1.751ms      18.240us       0.000us         0.00%       0.000us       0.000us            96  \n",
            "                                            aten::clone         0.81%     984.000us         2.01%       2.453ms      12.776us       0.000us         0.00%       0.000us       0.000us           192  \n",
            "                                       aten::empty_like         0.28%     347.000us         0.54%     660.000us       5.641us       0.000us         0.00%       0.000us       0.000us           117  \n",
            "                                              aten::div         0.81%     994.000us         1.35%       1.650ms      17.188us       0.000us         0.00%       0.000us       0.000us            96  \n",
            "                                               aten::eq         0.61%     751.000us         1.13%       1.375ms      14.323us       0.000us         0.00%       0.000us       0.000us            96  \n",
            "                                              aten::any         0.77%     945.000us         0.86%       1.045ms      10.885us       0.000us         0.00%       0.000us       0.000us            96  \n",
            "                                            aten::fill_         0.12%     147.000us         0.22%     268.000us       2.351us      75.000us         0.15%     693.000us       6.079us           114  \n",
            "                                             aten::sub_         0.46%     560.000us         0.46%     560.000us       5.833us       0.000us         0.00%       0.000us       0.000us            96  \n",
            "                                             aten::div_         0.27%     325.000us         0.27%     325.000us       3.385us       0.000us         0.00%       0.000us       0.000us            96  \n",
            "void at::native::(anonymous namespace)::multi_tensor...         0.00%       0.000us         0.00%       0.000us       0.000us       4.584ms         9.38%       4.584ms     573.000us             8  \n",
            "void at::native::(anonymous namespace)::multi_tensor...         0.00%       0.000us         0.00%       0.000us       0.000us       3.313ms         6.78%       3.313ms     414.125us             8  \n",
            "void at::native::(anonymous namespace)::multi_tensor...         0.00%       0.000us         0.00%       0.000us       0.000us       3.348ms         6.85%       3.348ms     418.500us             8  \n",
            "void at::native::(anonymous namespace)::multi_tensor...         0.00%       0.000us         0.00%       0.000us       0.000us       3.204ms         6.56%       3.204ms     400.500us             8  \n",
            "void at::native::(anonymous namespace)::multi_tensor...         0.00%       0.000us         0.00%       0.000us       0.000us       6.032ms        12.34%       6.032ms     754.000us             8  \n",
            "at::native::amp_update_scale_cuda_kernel(float*, int...         0.00%       0.000us         0.00%       0.000us       0.000us      20.000us         0.04%      20.000us       5.000us             4  \n",
            "                                            aten::stack         0.04%      52.000us         0.38%     468.000us     156.000us       0.000us         0.00%       0.000us       0.000us             3  \n",
            "                                              aten::cat         0.34%     410.000us         0.34%     410.000us     136.667us       0.000us         0.00%       0.000us       0.000us             3  \n",
            "                                          aten::detach_         0.01%       9.000us         0.01%      12.000us       4.000us       0.000us         0.00%       0.000us       0.000us             3  \n",
            "                                                detach_         0.00%       3.000us         0.00%       3.000us       1.000us       0.000us         0.00%       0.000us       0.000us             3  \n",
            "                                        cudaMemcpyAsync         3.58%       4.379ms         3.58%       4.379ms     291.933us      34.000us         0.07%      34.000us       2.267us            15  \n",
            "                       Memcpy HtoD (Pageable -> Device)         0.00%       0.000us         0.00%       0.000us       0.000us     106.000us         0.22%     106.000us      17.667us             6  \n",
            "                                  cudaStreamSynchronize         0.12%     151.000us         0.12%     151.000us      16.778us       0.000us         0.00%       0.000us       0.000us             9  \n",
            "                                           aten::conv2d         0.11%     138.000us         4.49%       5.482ms     182.733us       0.000us         0.00%       6.543ms     218.100us            30  \n",
            "                                       cudaLaunchKernel         2.90%       3.543ms         2.90%       3.543ms       7.428us       1.605ms         3.28%       1.605ms       3.365us           477  \n",
            "void at::native::unrolled_elementwise_kernel<at::nat...         0.00%       0.000us         0.00%       0.000us       0.000us       2.785ms         5.70%       2.785ms      51.574us            54  \n",
            "                                      aten::convolution         0.11%     135.000us         1.67%       2.039ms     135.933us       0.000us         0.00%       3.043ms     202.867us            15  \n",
            "                                     aten::_convolution         0.17%     203.000us         1.56%       1.904ms     126.933us       0.000us         0.00%       3.043ms     202.867us            15  \n",
            "                                aten::cudnn_convolution         0.72%     875.000us         1.07%       1.304ms      86.933us       2.107ms         4.31%       2.774ms     184.933us            15  \n",
            "                                  cudaStreamIsCapturing         0.01%      16.000us         0.01%      16.000us       0.314us       3.000us         0.01%       3.000us       0.059us            51  \n",
            "                                  cudaStreamGetPriority         0.00%       2.000us         0.00%       2.000us       0.048us     617.000us         1.26%     617.000us      14.690us            42  \n",
            "                       cudaDeviceGetStreamPriorityRange         0.00%       0.000us         0.00%       0.000us       0.000us      24.000us         0.05%      24.000us       0.571us            42  \n",
            "void cask_cudnn::computeOffsetsKernel<false, false>(...         0.00%       0.000us         0.00%       0.000us       0.000us      15.000us         0.03%      15.000us       5.000us             3  \n",
            "                                        cudaMemsetAsync         0.17%     211.000us         0.17%     211.000us       6.394us      29.000us         0.06%      29.000us       0.879us            33  \n",
            "cudnn_volta_fp16_scudnn_fp16_128x32_relu_small_nn_v1...         0.00%       0.000us         0.00%       0.000us       0.000us     108.000us         0.22%     108.000us      36.000us             3  \n",
            "                                          aten::reshape         0.09%     110.000us         0.12%     152.000us       8.444us       0.000us         0.00%       0.000us       0.000us            18  \n",
            "                                   aten::_reshape_alias         0.04%      44.000us         0.04%      44.000us       2.444us       0.000us         0.00%       0.000us       0.000us            18  \n",
            "                                             aten::add_         0.37%     454.000us         0.73%     888.000us      12.870us     189.000us         0.39%     269.000us       3.899us            69  \n",
            "void at::native::elementwise_kernel<128, 4, at::nati...         0.00%       0.000us         0.00%       0.000us       0.000us     189.000us         0.39%     189.000us      12.600us            15  \n",
            "                                       aten::max_pool2d         0.02%      29.000us         0.26%     317.000us      35.222us       0.000us         0.00%     152.000us      16.889us             9  \n",
            "                          aten::max_pool2d_with_indices         0.19%     227.000us         0.24%     288.000us      32.000us     152.000us         0.31%     152.000us      16.889us             9  \n",
            "void at::native::(anonymous namespace)::max_pool_for...         0.00%       0.000us         0.00%       0.000us       0.000us     152.000us         0.31%     152.000us      16.889us             9  \n",
            "                                            aten::relu_         0.26%     323.000us         0.59%     720.000us      34.286us       0.000us         0.00%     105.000us       5.000us            21  \n",
            "                                       aten::clamp_min_         0.21%     254.000us         0.32%     397.000us      18.905us     105.000us         0.21%     105.000us       5.000us            21  \n",
            "void at::native::vectorized_elementwise_kernel<4, at...         0.00%       0.000us         0.00%       0.000us       0.000us     105.000us         0.21%     105.000us       5.000us            21  \n",
            "void cudnn::ops::nchwToNhwcKernel<__half, __half, fl...         0.00%       0.000us         0.00%       0.000us       0.000us       1.603ms         3.28%       1.603ms      20.551us            78  \n",
            "                                                INVALID         0.21%     257.000us         0.21%     257.000us       6.590us      12.000us         0.02%      12.000us       0.308us            39  \n",
            "sm75_xmma_fprop_implicit_gemm_f16f16_f16f32_f32_nhwc...         0.00%       0.000us         0.00%       0.000us       0.000us     185.000us         0.38%     185.000us      61.667us             3  \n",
            "void cudnn::ops::nhwcToNchwKernel<__half, __half, fl...         0.00%       0.000us         0.00%       0.000us       0.000us     769.000us         1.57%     769.000us      19.718us            39  \n",
            "                                        Memset (Device)         0.00%       0.000us         0.00%       0.000us       0.000us      92.000us         0.19%      92.000us       3.067us            30  \n",
            "sm75_xmma_fprop_implicit_gemm_f16f16_f16f32_f32_nhwc...         0.00%       0.000us         0.00%       0.000us       0.000us     336.000us         0.69%     336.000us     112.000us             3  \n",
            "sm75_xmma_fprop_implicit_gemm_indexed_f16f16_f16f32_...         0.00%       0.000us         0.00%       0.000us       0.000us     720.000us         1.47%     720.000us     120.000us             6  \n",
            "                                          aten::dropout         0.02%      21.000us         0.30%     364.000us      60.667us       0.000us         0.00%      52.000us       8.667us             6  \n",
            "                                   aten::native_dropout         0.14%     166.000us         0.28%     343.000us      57.167us      49.000us         0.10%      52.000us       8.667us             6  \n",
            "void at::native::(anonymous namespace)::fused_dropou...         0.00%       0.000us         0.00%       0.000us       0.000us      49.000us         0.10%      49.000us       8.167us             6  \n",
            "                                           aten::linear         0.01%      14.000us         2.03%       2.481ms     137.833us       0.000us         0.00%       4.714ms     261.889us            18  \n",
            "                                                aten::t         0.11%     131.000us         0.24%     291.000us       6.467us       0.000us         0.00%       0.000us       0.000us            45  \n",
            "                                        aten::transpose         0.10%     127.000us         0.13%     160.000us       3.556us       0.000us         0.00%       0.000us       0.000us            45  \n",
            "                                            aten::addmm         0.47%     572.000us         0.63%     769.000us      85.444us     851.000us         1.74%       1.187ms     131.889us             9  \n",
            "          cudaOccupancyMaxActiveBlocksPerMultiprocessor         0.01%      16.000us         0.01%      16.000us       1.067us      68.000us         0.14%      68.000us       4.533us            15  \n",
            "turing_fp16_s1688gemm_fp16_128x64_sliced1x2_ldg8_rel...         0.00%       0.000us         0.00%       0.000us       0.000us     797.000us         1.63%     797.000us     132.833us             6  \n",
            "cudaOccupancyMaxActiveBlocksPerMultiprocessorWithFla...         0.03%      34.000us         0.03%      34.000us       2.833us     268.000us         0.55%     268.000us      22.333us            12  \n",
            "                               aten::cross_entropy_loss         0.02%      24.000us         0.33%     407.000us     135.667us       0.000us         0.00%      48.000us      16.000us             3  \n",
            "                                      aten::log_softmax         0.02%      24.000us         0.12%     144.000us      48.000us       0.000us         0.00%      15.000us       5.000us             3  \n",
            "                                     aten::_log_softmax         0.07%      91.000us         0.10%     120.000us      40.000us      15.000us         0.03%      15.000us       5.000us             3  \n",
            "                                      aten::nll_loss_nd         0.01%      11.000us         0.20%     239.000us      79.667us       0.000us         0.00%      33.000us      11.000us             3  \n",
            "                                         aten::nll_loss        -0.01%     -11.000us         0.27%     335.000us      55.833us       0.000us         0.00%      48.000us       8.000us             6  \n",
            "                                 aten::nll_loss_forward         0.06%      72.000us         0.08%      94.000us      31.333us      15.000us         0.03%      15.000us       5.000us             3  \n",
            "                                          aten::resize_         0.00%       1.000us         0.00%       1.000us       0.333us       0.000us         0.00%       0.000us       0.000us             3  \n",
            "                                              aten::mul         0.12%     151.000us         0.18%     221.000us      36.833us      24.000us         0.05%      24.000us       4.000us             6  \n",
            "                                        aten::ones_like         0.01%      14.000us         0.08%      95.000us      31.667us       0.000us         0.00%       9.000us       3.000us             3  \n",
            "void cutlass::Kernel<cutlass_75_wmma_tensorop_f16_s1...         0.00%       0.000us         0.00%       0.000us       0.000us      33.000us         0.07%      33.000us      11.000us             3  \n",
            "void splitKreduce_kernel<32, 16, int, __half, __half...         0.00%       0.000us         0.00%       0.000us       0.000us      21.000us         0.04%      21.000us       7.000us             3  \n",
            "void (anonymous namespace)::softmax_warp_forward<c10...         0.00%       0.000us         0.00%       0.000us       0.000us      15.000us         0.03%      15.000us       5.000us             3  \n",
            "void at::native::unrolled_elementwise_kernel<at::nat...         0.00%       0.000us         0.00%       0.000us       0.000us       2.766ms         5.66%       2.766ms      51.222us            54  \n",
            "void at::native::(anonymous namespace)::nll_loss_for...         0.00%       0.000us         0.00%       0.000us       0.000us      15.000us         0.03%      15.000us       5.000us             3  \n",
            "void at::native::vectorized_elementwise_kernel<4, at...         0.00%       0.000us         0.00%       0.000us       0.000us      24.000us         0.05%      24.000us       4.000us             6  \n",
            "void at::native::vectorized_elementwise_kernel<4, at...         0.00%       0.000us         0.00%       0.000us       0.000us      27.000us         0.06%      27.000us       3.000us             9  \n",
            "      autograd::engine::evaluate_function: MulBackward0         0.07%      81.000us         0.27%     336.000us     112.000us       0.000us         0.00%      42.000us      14.000us             3  \n",
            "                                           MulBackward0         0.02%      19.000us         0.11%     139.000us      46.333us       0.000us         0.00%      12.000us       4.000us             3  \n",
            "-------------------------------------------------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  \n",
            "Self CPU time total: 122.197ms\n",
            "Self CUDA time total: 48.876ms\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(prof.key_averages().table(sort_by=\"cpu_time_total\", row_limit=10))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xDczy_94TaTc",
        "outputId": "a321ba80-d70b-47b3-9cb5-60976e82c23a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "-------------------------------------------------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  \n",
            "                                                   Name    Self CPU %      Self CPU   CPU total %     CPU total  CPU time avg     Self CUDA   Self CUDA %    CUDA total  CUDA time avg    # of Calls  \n",
            "-------------------------------------------------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  \n",
            "                                          ProfilerStep*        11.31%      13.824ms        87.51%     106.940ms      35.647ms       0.000us         0.00%      35.042ms      11.681ms             3  \n",
            "enumerate(DataLoader)#_SingleProcessDataLoaderIter._...        46.65%      57.003ms        62.15%      75.945ms      25.315ms       0.000us         0.00%       0.000us       0.000us             3  \n",
            "                                               aten::to         1.36%       1.663ms         8.05%       9.832ms      12.954us       0.000us         0.00%       5.074ms       6.685us           759  \n",
            "                                         aten::_to_copy         2.90%       3.544ms         7.03%       8.594ms      11.505us       0.000us         0.00%       5.727ms       7.667us           747  \n",
            "                                  cudaDeviceSynchronize         5.53%       6.752ms         5.53%       6.752ms       6.752ms       0.000us         0.00%       0.000us       0.000us             1  \n",
            "                                           aten::conv2d         0.11%     138.000us         4.49%       5.482ms     182.733us       0.000us         0.00%       6.543ms     218.100us            30  \n",
            "                                             aten::item         0.66%     801.000us         3.86%       4.717ms       8.147us       0.000us         0.00%      40.000us       0.069us           579  \n",
            "                                            aten::copy_         2.38%       2.909ms         3.67%       4.480ms       4.771us       5.696ms        11.65%       5.731ms       6.103us           939  \n",
            "                               Optimizer.step#Adam.step         1.70%       2.075ms         3.66%       4.478ms       1.493ms       0.000us         0.00%      24.414ms       8.138ms             3  \n",
            "                                        cudaMemcpyAsync         3.58%       4.379ms         3.58%       4.379ms     291.933us      34.000us         0.07%      34.000us       2.267us            15  \n",
            "-------------------------------------------------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  \n",
            "Self CPU time total: 122.197ms\n",
            "Self CUDA time total: 48.876ms\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(prof.key_averages(group_by_input_shape=True).table(sort_by=\"cpu_time_total\", row_limit=10))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1EtcnT1lTfb1",
        "outputId": "63044164-0cb5-4c7e-b93a-e398a1309261"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "-------------------------------------------------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  --------------------------------------------------------------------------------  \n",
            "                                                   Name    Self CPU %      Self CPU   CPU total %     CPU total  CPU time avg     Self CUDA   Self CUDA %    CUDA total  CUDA time avg    # of Calls                                                                      Input Shapes  \n",
            "-------------------------------------------------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  --------------------------------------------------------------------------------  \n",
            "                                          ProfilerStep*        11.31%      13.824ms        87.51%     106.940ms      35.647ms       0.000us         0.00%      35.042ms      11.681ms             3                                                                                []  \n",
            "enumerate(DataLoader)#_SingleProcessDataLoaderIter._...        46.65%      57.003ms        62.15%      75.945ms      25.315ms       0.000us         0.00%       0.000us       0.000us             3                                                                                []  \n",
            "                                  cudaDeviceSynchronize         5.53%       6.752ms         5.53%       6.752ms       6.752ms       0.000us         0.00%       0.000us       0.000us             1                                                                                []  \n",
            "                               Optimizer.step#Adam.step         1.70%       2.075ms         3.66%       4.478ms       1.493ms       0.000us         0.00%      24.414ms       8.138ms             3                                                                                []  \n",
            "                                             aten::item         0.43%     529.000us         3.63%       4.440ms      11.473us       0.000us         0.00%      40.000us       0.103us           387                                                                             [[1]]  \n",
            "                                        cudaMemcpyAsync         3.58%       4.379ms         3.58%       4.379ms     291.933us      34.000us         0.07%      34.000us       2.267us            15                                                                                []  \n",
            "                              aten::_local_scalar_dense         0.02%      27.000us         3.20%       3.912ms      10.109us       6.000us         0.01%      40.000us       0.103us           387                                                                             [[1]]  \n",
            "                                       cudaLaunchKernel         2.90%       3.543ms         2.90%       3.543ms       7.428us       1.605ms         3.28%       1.605ms       3.365us           477                                                                                []  \n",
            "autograd::engine::evaluate_function: ConvolutionBack...         0.15%     185.000us         2.37%       2.890ms     192.667us       0.000us         0.00%       4.266ms     284.400us            15                                                                                []  \n",
            "                                               aten::to         0.50%     617.000us         2.18%       2.658ms       7.911us       0.000us         0.00%       0.000us       0.000us           336                                                              [[], [], [], [], []]  \n",
            "-------------------------------------------------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  --------------------------------------------------------------------------------  \n",
            "Self CPU time total: 122.197ms\n",
            "Self CUDA time total: 48.876ms\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(prof.key_averages().table(sort_by=\"cuda_time_total\", row_limit=10))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YdEGlC6STkLP",
        "outputId": "c9b7a355-c4e9-489e-cc65-d0ff55abd284"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "-------------------------------------------------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  \n",
            "                                                   Name    Self CPU %      Self CPU   CPU total %     CPU total  CPU time avg     Self CUDA   Self CUDA %    CUDA total  CUDA time avg    # of Calls  \n",
            "-------------------------------------------------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  \n",
            "                                          ProfilerStep*        11.31%      13.824ms        87.51%     106.940ms      35.647ms       0.000us         0.00%      35.042ms      11.681ms             3  \n",
            "                               Optimizer.step#Adam.step         1.70%       2.075ms         3.66%       4.478ms       1.493ms       0.000us         0.00%      24.414ms       8.138ms             3  \n",
            "                                           aten::conv2d         0.11%     138.000us         4.49%       5.482ms     182.733us       0.000us         0.00%       6.543ms     218.100us            30  \n",
            "void at::native::(anonymous namespace)::multi_tensor...         0.00%       0.000us         0.00%       0.000us       0.000us       6.032ms        12.34%       6.032ms     754.000us             8  \n",
            "                                            aten::copy_         2.38%       2.909ms         3.67%       4.480ms       4.771us       5.696ms        11.65%       5.731ms       6.103us           939  \n",
            "                                         aten::_to_copy         2.90%       3.544ms         7.03%       8.594ms      11.505us       0.000us         0.00%       5.727ms       7.667us           747  \n",
            "void at::native::(anonymous namespace)::multi_tensor...         0.00%       0.000us         0.00%       0.000us       0.000us       5.579ms        11.41%       5.579ms     398.500us            14  \n",
            "                                               aten::to         1.36%       1.663ms         8.05%       9.832ms      12.954us       0.000us         0.00%       5.074ms       6.685us           759  \n",
            "                                    aten::_foreach_mul_         0.16%     192.000us         0.25%     301.000us      50.167us       4.783ms         9.79%       4.800ms     800.000us             6  \n",
            "                                           aten::linear         0.01%      14.000us         2.03%       2.481ms     137.833us       0.000us         0.00%       4.714ms     261.889us            18  \n",
            "-------------------------------------------------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  \n",
            "Self CPU time total: 122.197ms\n",
            "Self CUDA time total: 48.876ms\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(prof.key_averages().table(sort_by=\"self_cpu_memory_usage\", row_limit=10))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rP-JwEMrTmsi",
        "outputId": "3561229a-e614-482b-fb50-c46b9189fa23"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "-------------------------------------------------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  \n",
            "                                                   Name    Self CPU %      Self CPU   CPU total %     CPU total  CPU time avg     Self CUDA   Self CUDA %    CUDA total  CUDA time avg    # of Calls  \n",
            "-------------------------------------------------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  \n",
            "                                          ProfilerStep*        11.31%      13.824ms        87.51%     106.940ms      35.647ms       0.000us         0.00%      35.042ms      11.681ms             3  \n",
            "enumerate(DataLoader)#_SingleProcessDataLoaderIter._...        46.65%      57.003ms        62.15%      75.945ms      25.315ms       0.000us         0.00%       0.000us       0.000us             3  \n",
            "                                            aten::empty         0.82%       1.007ms         0.82%       1.007ms       1.952us       0.000us         0.00%       0.000us       0.000us           516  \n",
            "                                         aten::uniform_         0.52%     638.000us         0.52%     638.000us       3.323us       0.000us         0.00%       0.000us       0.000us           192  \n",
            "                                             aten::item         0.66%     801.000us         3.86%       4.717ms       8.147us       0.000us         0.00%      40.000us       0.069us           579  \n",
            "                              aten::_local_scalar_dense         0.03%      34.000us         3.21%       3.919ms       6.769us       6.000us         0.01%      40.000us       0.069us           579  \n",
            "void at::native::(anonymous namespace)::multi_tensor...         0.00%       0.000us         0.00%       0.000us       0.000us       3.584ms         7.33%       3.584ms     512.000us             7  \n",
            "                                             aten::rand         0.44%     543.000us         0.73%     889.000us       9.260us       0.000us         0.00%       0.000us       0.000us            96  \n",
            "                                               aten::lt         0.74%     901.000us         1.71%       2.085ms      21.719us       0.000us         0.00%       0.000us       0.000us            96  \n",
            "                                               aten::to         1.36%       1.663ms         8.05%       9.832ms      12.954us       0.000us         0.00%       5.074ms       6.685us           759  \n",
            "-------------------------------------------------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  \n",
            "Self CPU time total: 122.197ms\n",
            "Self CUDA time total: 48.876ms\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(prof.key_averages().table(sort_by=\"cpu_memory_usage\", row_limit=10))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XHkeq9EGTo9e",
        "outputId": "6f9d177d-f54b-47ef-f70f-9a1de3a7c402"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "-------------------------------------------------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  \n",
            "                                                   Name    Self CPU %      Self CPU   CPU total %     CPU total  CPU time avg     Self CUDA   Self CUDA %    CUDA total  CUDA time avg    # of Calls  \n",
            "-------------------------------------------------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  \n",
            "                                          ProfilerStep*        11.31%      13.824ms        87.51%     106.940ms      35.647ms       0.000us         0.00%      35.042ms      11.681ms             3  \n",
            "enumerate(DataLoader)#_SingleProcessDataLoaderIter._...        46.65%      57.003ms        62.15%      75.945ms      25.315ms       0.000us         0.00%       0.000us       0.000us             3  \n",
            "                                            aten::empty         0.82%       1.007ms         0.82%       1.007ms       1.952us       0.000us         0.00%       0.000us       0.000us           516  \n",
            "                                         aten::uniform_         0.52%     638.000us         0.52%     638.000us       3.323us       0.000us         0.00%       0.000us       0.000us           192  \n",
            "                                             aten::item         0.66%     801.000us         3.86%       4.717ms       8.147us       0.000us         0.00%      40.000us       0.069us           579  \n",
            "                              aten::_local_scalar_dense         0.03%      34.000us         3.21%       3.919ms       6.769us       6.000us         0.01%      40.000us       0.069us           579  \n",
            "void at::native::(anonymous namespace)::multi_tensor...         0.00%       0.000us         0.00%       0.000us       0.000us       3.584ms         7.33%       3.584ms     512.000us             7  \n",
            "                                             aten::rand         0.44%     543.000us         0.73%     889.000us       9.260us       0.000us         0.00%       0.000us       0.000us            96  \n",
            "                                               aten::lt         0.74%     901.000us         1.71%       2.085ms      21.719us       0.000us         0.00%       0.000us       0.000us            96  \n",
            "                                               aten::to         1.36%       1.663ms         8.05%       9.832ms      12.954us       0.000us         0.00%       5.074ms       6.685us           759  \n",
            "-------------------------------------------------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  \n",
            "Self CPU time total: 122.197ms\n",
            "Self CUDA time total: 48.876ms\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(prof.key_averages(group_by_stack_n=5).table(sort_by=\"self_cuda_time_total\", row_limit=2))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YU3PY2-4TrOs",
        "outputId": "d7269b55-a394-4872-adc7-69ebe074e943"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "-------------------------------------------------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  \n",
            "                                                   Name    Self CPU %      Self CPU   CPU total %     CPU total  CPU time avg     Self CUDA   Self CUDA %    CUDA total  CUDA time avg    # of Calls  \n",
            "-------------------------------------------------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  \n",
            "void at::native::(anonymous namespace)::multi_tensor...         0.00%       0.000us         0.00%       0.000us       0.000us       6.032ms        12.34%       6.032ms     754.000us             8  \n",
            "                                            aten::copy_         2.38%       2.909ms         3.67%       4.480ms       4.771us       5.696ms        11.65%       5.731ms       6.103us           939  \n",
            "-------------------------------------------------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  \n",
            "Self CPU time total: 122.197ms\n",
            "Self CUDA time total: 48.876ms\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_2B5T1odTuuk",
        "outputId": "37659da0-f30a-4b6d-d1bf-91f3b7d71ad0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!mv /content/log /content/drive/MyDrive"
      ],
      "metadata": {
        "id": "tFM2ACVyUFrR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "IfrXPibHUWQ-"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}