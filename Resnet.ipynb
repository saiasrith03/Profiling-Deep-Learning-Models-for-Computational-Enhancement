{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "Bk7sN8VkI92B"
      },
      "outputs": [],
      "source": [
        "%matplotlib inline"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "import torch.optim.lr_scheduler as lr_scheduler\n",
        "from torch.optim.lr_scheduler import _LRScheduler\n",
        "import torch.utils.data as data\n",
        "\n",
        "import torchvision.transforms as transforms\n",
        "import torchvision.datasets as datasets\n",
        "import torchvision.models as models\n",
        "\n",
        "from sklearn import decomposition\n",
        "from sklearn import manifold\n",
        "from sklearn.metrics import confusion_matrix\n",
        "from sklearn.metrics import ConfusionMatrixDisplay\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "\n",
        "import copy\n",
        "from collections import namedtuple\n",
        "import os\n",
        "import random\n",
        "import shutil\n",
        "import time"
      ],
      "metadata": {
        "id": "RpSTsyKuP0FN"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import shutil"
      ],
      "metadata": {
        "id": "CAtbbv2Ax9kb"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "os.environ['KAGGLE_USERNAME'] = 'saiasrithbevnm'\n",
        "os.environ['KAGGLE_KEY'] = 'e454013e09272ecc3b94612b9af53d1c'\n",
        "\n",
        "!pip install kaggle\n",
        "!kaggle datasets download veeralakrishna/200-bird-species-with-11788-images --unzip\n",
        "\n",
        "ROOT = 'data'\n",
        "\n",
        "datasets.utils.extract_archive('CUB_200_2011.tgz', ROOT)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 313
        },
        "id": "tvNv_5JFxjHV",
        "outputId": "f6cf19b5-24fc-43d7-d642-a74af27e6586"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: kaggle in /usr/local/lib/python3.10/dist-packages (1.5.16)\n",
            "Requirement already satisfied: six>=1.10 in /usr/local/lib/python3.10/dist-packages (from kaggle) (1.16.0)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.10/dist-packages (from kaggle) (2023.7.22)\n",
            "Requirement already satisfied: python-dateutil in /usr/local/lib/python3.10/dist-packages (from kaggle) (2.8.2)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from kaggle) (2.31.0)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from kaggle) (4.66.1)\n",
            "Requirement already satisfied: python-slugify in /usr/local/lib/python3.10/dist-packages (from kaggle) (8.0.1)\n",
            "Requirement already satisfied: urllib3 in /usr/local/lib/python3.10/dist-packages (from kaggle) (2.0.4)\n",
            "Requirement already satisfied: bleach in /usr/local/lib/python3.10/dist-packages (from kaggle) (6.0.0)\n",
            "Requirement already satisfied: webencodings in /usr/local/lib/python3.10/dist-packages (from bleach->kaggle) (0.5.1)\n",
            "Requirement already satisfied: text-unidecode>=1.3 in /usr/local/lib/python3.10/dist-packages (from python-slugify->kaggle) (1.3)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->kaggle) (3.2.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->kaggle) (3.4)\n",
            "Downloading 200-bird-species-with-11788-images.zip to /content\n",
            "100% 1.10G/1.11G [00:57<00:00, 22.5MB/s]\n",
            "100% 1.11G/1.11G [00:57<00:00, 20.7MB/s]\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'data'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "TRAIN_RATIO = 0.8\n",
        "\n",
        "data_dir = os.path.join(ROOT, 'CUB_200_2011')\n",
        "images_dir = os.path.join(data_dir, 'images')\n",
        "train_dir = os.path.join(data_dir, 'train')\n",
        "test_dir = os.path.join(data_dir, 'test')\n",
        "\n",
        "if os.path.exists(train_dir):\n",
        "    shutil.rmtree(train_dir)\n",
        "if os.path.exists(test_dir):\n",
        "    shutil.rmtree(test_dir)\n",
        "\n",
        "os.makedirs(train_dir)\n",
        "os.makedirs(test_dir)\n",
        "\n",
        "classes = os.listdir(images_dir)\n",
        "\n",
        "for c in classes:\n",
        "\n",
        "    class_dir = os.path.join(images_dir, c)\n",
        "\n",
        "    images = os.listdir(class_dir)\n",
        "\n",
        "    n_train = int(len(images) * TRAIN_RATIO)\n",
        "\n",
        "    train_images = images[:n_train]\n",
        "    test_images = images[n_train:]\n",
        "\n",
        "    os.makedirs(os.path.join(train_dir, c), exist_ok = True)\n",
        "    os.makedirs(os.path.join(test_dir, c), exist_ok = True)\n",
        "\n",
        "    for image in train_images:\n",
        "        image_src = os.path.join(class_dir, image)\n",
        "        image_dst = os.path.join(train_dir, c, image)\n",
        "        shutil.copyfile(image_src, image_dst)\n",
        "\n",
        "    for image in test_images:\n",
        "        image_src = os.path.join(class_dir, image)\n",
        "        image_dst = os.path.join(test_dir, c, image)\n",
        "        shutil.copyfile(image_src, image_dst)"
      ],
      "metadata": {
        "id": "J5Hgm3b8xjD9"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_data = datasets.ImageFolder(root = train_dir,\n",
        "                                  transform = transforms.ToTensor())\n",
        "\n",
        "means = torch.zeros(3)\n",
        "stds = torch.zeros(3)\n",
        "\n",
        "for img, label in train_data:\n",
        "    means += torch.mean(img, dim = (1,2))\n",
        "    stds += torch.std(img, dim = (1,2))\n",
        "\n",
        "means /= len(train_data)\n",
        "stds /= len(train_data)\n",
        "\n",
        "print(f'Calculated means: {means}')\n",
        "print(f'Calculated stds: {stds}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ATSxEoybxjBB",
        "outputId": "95da89cc-31da-449d-d80b-022d5df32555"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Calculated means: tensor([0.4863, 0.4999, 0.4318])\n",
            "Calculated stds: tensor([0.1825, 0.1816, 0.1936])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pretrained_size = 224\n",
        "pretrained_means = [0.485, 0.456, 0.406]\n",
        "pretrained_stds= [0.229, 0.224, 0.225]\n",
        "\n",
        "train_transforms = transforms.Compose([\n",
        "                           transforms.Resize(pretrained_size),\n",
        "                           transforms.RandomRotation(5),\n",
        "                           transforms.RandomHorizontalFlip(0.5),\n",
        "                           transforms.RandomCrop(pretrained_size, padding = 10),\n",
        "                           transforms.ToTensor(),\n",
        "                           transforms.Normalize(mean = pretrained_means,\n",
        "                                                std = pretrained_stds)\n",
        "                       ])\n",
        "\n",
        "test_transforms = transforms.Compose([\n",
        "                           transforms.Resize(pretrained_size),\n",
        "                           transforms.CenterCrop(pretrained_size),\n",
        "                           transforms.ToTensor(),\n",
        "                           transforms.Normalize(mean = pretrained_means,\n",
        "                                                std = pretrained_stds)\n",
        "                       ])"
      ],
      "metadata": {
        "id": "BSUscgG-yYLq"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_data = datasets.ImageFolder(root = train_dir,\n",
        "                                  transform = train_transforms)\n",
        "\n",
        "test_data = datasets.ImageFolder(root = test_dir,\n",
        "                                 transform = test_transforms)"
      ],
      "metadata": {
        "id": "vU2aJDBRyYIz"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "BATCH_SIZE = 64\n",
        "\n",
        "train_loader = data.DataLoader(train_data,\n",
        "                                 shuffle = True,\n",
        "                                 batch_size = BATCH_SIZE)\n",
        "\n",
        "test_loader = data.DataLoader(test_data,\n",
        "                                batch_size = BATCH_SIZE)"
      ],
      "metadata": {
        "id": "QeXJFJ2HyYFr"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
      ],
      "metadata": {
        "id": "Icd24fCHI-1A"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class ResNet(nn.Module):\n",
        "    def __init__(self, config, output_dim):\n",
        "        super().__init__()\n",
        "\n",
        "        block, n_blocks, channels = config\n",
        "        self.in_channels = channels[0]\n",
        "\n",
        "        assert len(n_blocks) == len(channels) == 4\n",
        "\n",
        "        self.conv1 = nn.Conv2d(3, self.in_channels, kernel_size = 7, stride = 2, padding = 3, bias = False)\n",
        "        self.bn1 = nn.BatchNorm2d(self.in_channels)\n",
        "        self.relu = nn.ReLU(inplace = True)\n",
        "        self.maxpool = nn.MaxPool2d(kernel_size = 3, stride = 2, padding = 1)\n",
        "\n",
        "        self.layer1 = self.get_resnet_layer(block, n_blocks[0], channels[0])\n",
        "        self.layer2 = self.get_resnet_layer(block, n_blocks[1], channels[1], stride = 2)\n",
        "        self.layer3 = self.get_resnet_layer(block, n_blocks[2], channels[2], stride = 2)\n",
        "        self.layer4 = self.get_resnet_layer(block, n_blocks[3], channels[3], stride = 2)\n",
        "\n",
        "        self.avgpool = nn.AdaptiveAvgPool2d((1,1))\n",
        "        self.fc = nn.Linear(self.in_channels, output_dim)\n",
        "\n",
        "    def get_resnet_layer(self, block, n_blocks, channels, stride = 1):\n",
        "\n",
        "        layers = []\n",
        "\n",
        "        if self.in_channels != block.expansion * channels:\n",
        "            downsample = True\n",
        "        else:\n",
        "            downsample = False\n",
        "\n",
        "        layers.append(block(self.in_channels, channels, stride, downsample))\n",
        "\n",
        "        for i in range(1, n_blocks):\n",
        "            layers.append(block(block.expansion * channels, channels))\n",
        "\n",
        "        self.in_channels = block.expansion * channels\n",
        "\n",
        "        return nn.Sequential(*layers)\n",
        "\n",
        "    def forward(self, x):\n",
        "\n",
        "        x = self.conv1(x)\n",
        "        x = self.bn1(x)\n",
        "        x = self.relu(x)\n",
        "        x = self.maxpool(x)\n",
        "\n",
        "        x = self.layer1(x)\n",
        "        x = self.layer2(x)\n",
        "        x = self.layer3(x)\n",
        "        x = self.layer4(x)\n",
        "\n",
        "        x = self.avgpool(x)\n",
        "        h = x.view(x.shape[0], -1)\n",
        "        x = self.fc(h)\n",
        "\n",
        "        return x, h"
      ],
      "metadata": {
        "id": "OhF1TjOEI-yI"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class BasicBlock(nn.Module):\n",
        "\n",
        "    expansion = 1\n",
        "\n",
        "    def __init__(self, in_channels, out_channels, stride = 1, downsample = False):\n",
        "        super().__init__()\n",
        "\n",
        "        self.conv1 = nn.Conv2d(in_channels, out_channels, kernel_size = 3,\n",
        "                               stride = stride, padding = 1, bias = False)\n",
        "        self.bn1 = nn.BatchNorm2d(out_channels)\n",
        "\n",
        "        self.conv2 = nn.Conv2d(out_channels, out_channels, kernel_size = 3,\n",
        "                               stride = 1, padding = 1, bias = False)\n",
        "        self.bn2 = nn.BatchNorm2d(out_channels)\n",
        "\n",
        "        self.relu = nn.ReLU(inplace = True)\n",
        "\n",
        "        if downsample:\n",
        "            conv = nn.Conv2d(in_channels, out_channels, kernel_size = 1,\n",
        "                             stride = stride, bias = False)\n",
        "            bn = nn.BatchNorm2d(out_channels)\n",
        "            downsample = nn.Sequential(conv, bn)\n",
        "        else:\n",
        "            downsample = None\n",
        "\n",
        "        self.downsample = downsample\n",
        "\n",
        "    def forward(self, x):\n",
        "\n",
        "        i = x\n",
        "\n",
        "        x = self.conv1(x)\n",
        "        x = self.bn1(x)\n",
        "        x = self.relu(x)\n",
        "\n",
        "        x = self.conv2(x)\n",
        "        x = self.bn2(x)\n",
        "\n",
        "        if self.downsample is not None:\n",
        "            i = self.downsample(i)\n",
        "\n",
        "        x += i\n",
        "        x = self.relu(x)\n",
        "\n",
        "        return x"
      ],
      "metadata": {
        "id": "TCr1Yqx8O85V"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "ResNetConfig = namedtuple('ResNetConfig', ['block', 'n_blocks', 'channels'])"
      ],
      "metadata": {
        "id": "i1KSBqCCO824"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "resnet18_config = ResNetConfig(block = BasicBlock,\n",
        "                               n_blocks = [2,2,2,2],\n",
        "                               channels = [64, 128, 256, 512])\n",
        "\n",
        "resnet34_config = ResNetConfig(block = BasicBlock,\n",
        "                               n_blocks = [3,4,6,3],\n",
        "                               channels = [64, 128, 256, 512])"
      ],
      "metadata": {
        "id": "Pa5AiOsdO80L"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class Bottleneck(nn.Module):\n",
        "\n",
        "    expansion = 4\n",
        "\n",
        "    def __init__(self, in_channels, out_channels, stride = 1, downsample = False):\n",
        "        super().__init__()\n",
        "\n",
        "        self.conv1 = nn.Conv2d(in_channels, out_channels, kernel_size = 1,\n",
        "                               stride = 1, bias = False)\n",
        "        self.bn1 = nn.BatchNorm2d(out_channels)\n",
        "\n",
        "        self.conv2 = nn.Conv2d(out_channels, out_channels, kernel_size = 3,\n",
        "                               stride = stride, padding = 1, bias = False)\n",
        "        self.bn2 = nn.BatchNorm2d(out_channels)\n",
        "\n",
        "        self.conv3 = nn.Conv2d(out_channels, self.expansion * out_channels, kernel_size = 1,\n",
        "                               stride = 1, bias = False)\n",
        "        self.bn3 = nn.BatchNorm2d(self.expansion * out_channels)\n",
        "\n",
        "        self.relu = nn.ReLU(inplace = True)\n",
        "\n",
        "        if downsample:\n",
        "            conv = nn.Conv2d(in_channels, self.expansion * out_channels, kernel_size = 1,\n",
        "                             stride = stride, bias = False)\n",
        "            bn = nn.BatchNorm2d(self.expansion * out_channels)\n",
        "            downsample = nn.Sequential(conv, bn)\n",
        "        else:\n",
        "            downsample = None\n",
        "\n",
        "        self.downsample = downsample\n",
        "\n",
        "    def forward(self, x):\n",
        "\n",
        "        i = x\n",
        "\n",
        "        x = self.conv1(x)\n",
        "        x = self.bn1(x)\n",
        "        x = self.relu(x)\n",
        "\n",
        "        x = self.conv2(x)\n",
        "        x = self.bn2(x)\n",
        "        x = self.relu(x)\n",
        "\n",
        "        x = self.conv3(x)\n",
        "        x = self.bn3(x)\n",
        "\n",
        "        if self.downsample is not None:\n",
        "            i = self.downsample(i)\n",
        "\n",
        "        x += i\n",
        "        x = self.relu(x)\n",
        "\n",
        "        return x"
      ],
      "metadata": {
        "id": "_seFmRUTO8xT"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "resnet50_config = ResNetConfig(block = Bottleneck,\n",
        "                               n_blocks = [3, 4, 6, 3],\n",
        "                               channels = [64, 128, 256, 512])\n",
        "\n",
        "resnet101_config = ResNetConfig(block = Bottleneck,\n",
        "                                n_blocks = [3, 4, 23, 3],\n",
        "                                channels = [64, 128, 256, 512])\n",
        "\n",
        "resnet152_config = ResNetConfig(block = Bottleneck,\n",
        "                                n_blocks = [3, 8, 36, 3],\n",
        "                                channels = [64, 128, 256, 512])"
      ],
      "metadata": {
        "id": "wK8dC9V8PgY-"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class CIFARResNet(nn.Module):\n",
        "    def __init__(self, config, output_dim):\n",
        "        super().__init__()\n",
        "\n",
        "        block, layers, channels = config\n",
        "        self.in_channels = channels[0]\n",
        "\n",
        "        assert len(layers) == len(channels) == 3\n",
        "        assert all([i == j*2 for i, j in zip(channels[1:], channels[:-1])])\n",
        "\n",
        "        self.conv1 = nn.Conv2d(3, self.in_channels, kernel_size = 3, stride = 1, padding = 1, bias = False)\n",
        "        self.bn1 = nn.BatchNorm2d(self.in_channels)\n",
        "        self.relu = nn.ReLU(inplace = True)\n",
        "\n",
        "        self.layer1 = self.get_resnet_layer(block, layers[0], channels[0])\n",
        "        self.layer2 = self.get_resnet_layer(block, layers[1], channels[1], stride = 2)\n",
        "        self.layer3 = self.get_resnet_layer(block, layers[2], channels[2], stride = 2)\n",
        "\n",
        "        self.avgpool = nn.AdaptiveAvgPool2d((1,1))\n",
        "        self.fc = nn.Linear(self.in_channels, output_dim)\n",
        "\n",
        "    def get_resnet_layer(self, block, n_blocks, channels, stride = 1):\n",
        "\n",
        "        layers = []\n",
        "\n",
        "        if self.in_channels != channels:\n",
        "            downsample = True\n",
        "        else:\n",
        "            downsample = False\n",
        "\n",
        "        layers.append(block(self.in_channels, channels, stride, downsample))\n",
        "\n",
        "        for i in range(1, n_blocks):\n",
        "            layers.append(block(channels, channels))\n",
        "\n",
        "        self.in_channels = channels\n",
        "\n",
        "        return nn.Sequential(*layers)\n",
        "\n",
        "    def forward(self, x):\n",
        "\n",
        "        x = self.conv1(x)\n",
        "        x = self.bn1(x)\n",
        "        x = self.relu(x)\n",
        "\n",
        "        x = self.layer1(x)\n",
        "        x = self.layer2(x)\n",
        "        x = self.layer3(x)\n",
        "\n",
        "        x = self.avgpool(x)\n",
        "        h = x.view(x.shape[0], -1)\n",
        "        x = self.fc(h)\n",
        "\n",
        "        return x, h"
      ],
      "metadata": {
        "id": "HVdG4KnsPgWs"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class Identity(nn.Module):\n",
        "    def __init__(self, f):\n",
        "        super().__init__()\n",
        "        self.f = f\n",
        "\n",
        "    def forward(self, x):\n",
        "        return self.f(x)\n",
        "\n",
        "\n",
        "class CIFARBasicBlock(nn.Module):\n",
        "\n",
        "    def __init__(self, in_channels, out_channels, stride = 1, downsample = False):\n",
        "        super().__init__()\n",
        "\n",
        "        self.conv1 = nn.Conv2d(in_channels, out_channels, kernel_size = 3,\n",
        "                               stride = stride, padding = 1, bias = False)\n",
        "        self.bn1 = nn.BatchNorm2d(out_channels)\n",
        "\n",
        "        self.conv2 = nn.Conv2d(out_channels, out_channels, kernel_size = 3,\n",
        "                               stride = 1, padding = 1, bias = False)\n",
        "        self.bn2 = nn.BatchNorm2d(out_channels)\n",
        "\n",
        "        self.relu = nn.ReLU(inplace = True)\n",
        "\n",
        "        if downsample:\n",
        "            identity_fn = lambda x : F.pad(x[:, :, ::2, ::2],\n",
        "                                           [0, 0, 0, 0, in_channels // 2, in_channels // 2])\n",
        "            downsample = Identity(identity_fn)\n",
        "        else:\n",
        "            downsample = None\n",
        "\n",
        "        self.downsample = downsample\n",
        "\n",
        "    def forward(self, x):\n",
        "\n",
        "        i = x\n",
        "\n",
        "        x = self.conv1(x)\n",
        "        x = self.bn1(x)\n",
        "        x = self.relu(x)\n",
        "\n",
        "        x = self.conv2(x)\n",
        "        x = self.bn2(x)\n",
        "\n",
        "        if self.downsample is not None:\n",
        "            i = self.downsample(i)\n",
        "\n",
        "        x += i\n",
        "        x = self.relu(x)\n",
        "\n",
        "        return x"
      ],
      "metadata": {
        "id": "jVDl8a8GPnls"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "cifar_resnet20_config = ResNetConfig(block = CIFARBasicBlock,\n",
        "                                     n_blocks = [3, 3, 3],\n",
        "                                     channels = [16, 32, 64])\n",
        "\n",
        "cifar_resnet32_config = ResNetConfig(block = CIFARBasicBlock,\n",
        "                                     n_blocks = [5, 5, 5],\n",
        "                                     channels = [16, 32, 64])\n",
        "\n",
        "cifar_resnet44_config = ResNetConfig(block = CIFARBasicBlock,\n",
        "                                     n_blocks = [7, 7, 7],\n",
        "                                     channels = [16, 32, 64])\n",
        "\n",
        "cifar_resnet56_config = ResNetConfig(block = CIFARBasicBlock,\n",
        "                                     n_blocks = [9, 9, 9],\n",
        "                                     channels = [16, 32, 64])\n",
        "\n",
        "cifar_resnet110_config = ResNetConfig(block = CIFARBasicBlock,\n",
        "                                      n_blocks = [18, 18, 18],\n",
        "                                      channels = [16, 32, 64])\n",
        "\n",
        "cifar_resnet1202_config = ResNetConfig(block = CIFARBasicBlock,\n",
        "                                       n_blocks = [20, 20, 20],\n",
        "                                       channels = [16, 32, 64])"
      ],
      "metadata": {
        "id": "9p2cgL_yPnjS"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pretrained_model = models.resnet50(pretrained = True)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fnSHavGgPngq",
        "outputId": "a7570055-bc0d-4e44-df6e-a8879b211137"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet50_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet50_Weights.DEFAULT` to get the most up-to-date weights.\n",
            "  warnings.warn(msg)\n",
            "Downloading: \"https://download.pytorch.org/models/resnet50-0676ba61.pth\" to /root/.cache/torch/hub/checkpoints/resnet50-0676ba61.pth\n",
            "100%|██████████| 97.8M/97.8M [00:00<00:00, 213MB/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(pretrained_model)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zKkvkc6ePgT0",
        "outputId": "b027dccd-b5dc-49b1-c68a-4e441e7afbfd"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ResNet(\n",
            "  (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
            "  (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "  (relu): ReLU(inplace=True)\n",
            "  (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
            "  (layer1): Sequential(\n",
            "    (0): Bottleneck(\n",
            "      (conv1): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (relu): ReLU(inplace=True)\n",
            "      (downsample): Sequential(\n",
            "        (0): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      )\n",
            "    )\n",
            "    (1): Bottleneck(\n",
            "      (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (relu): ReLU(inplace=True)\n",
            "    )\n",
            "    (2): Bottleneck(\n",
            "      (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (relu): ReLU(inplace=True)\n",
            "    )\n",
            "  )\n",
            "  (layer2): Sequential(\n",
            "    (0): Bottleneck(\n",
            "      (conv1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
            "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (relu): ReLU(inplace=True)\n",
            "      (downsample): Sequential(\n",
            "        (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
            "        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      )\n",
            "    )\n",
            "    (1): Bottleneck(\n",
            "      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (relu): ReLU(inplace=True)\n",
            "    )\n",
            "    (2): Bottleneck(\n",
            "      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (relu): ReLU(inplace=True)\n",
            "    )\n",
            "    (3): Bottleneck(\n",
            "      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (relu): ReLU(inplace=True)\n",
            "    )\n",
            "  )\n",
            "  (layer3): Sequential(\n",
            "    (0): Bottleneck(\n",
            "      (conv1): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
            "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (relu): ReLU(inplace=True)\n",
            "      (downsample): Sequential(\n",
            "        (0): Conv2d(512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
            "        (1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      )\n",
            "    )\n",
            "    (1): Bottleneck(\n",
            "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (relu): ReLU(inplace=True)\n",
            "    )\n",
            "    (2): Bottleneck(\n",
            "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (relu): ReLU(inplace=True)\n",
            "    )\n",
            "    (3): Bottleneck(\n",
            "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (relu): ReLU(inplace=True)\n",
            "    )\n",
            "    (4): Bottleneck(\n",
            "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (relu): ReLU(inplace=True)\n",
            "    )\n",
            "    (5): Bottleneck(\n",
            "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (relu): ReLU(inplace=True)\n",
            "    )\n",
            "  )\n",
            "  (layer4): Sequential(\n",
            "    (0): Bottleneck(\n",
            "      (conv1): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
            "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (relu): ReLU(inplace=True)\n",
            "      (downsample): Sequential(\n",
            "        (0): Conv2d(1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
            "        (1): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      )\n",
            "    )\n",
            "    (1): Bottleneck(\n",
            "      (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (relu): ReLU(inplace=True)\n",
            "    )\n",
            "    (2): Bottleneck(\n",
            "      (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (relu): ReLU(inplace=True)\n",
            "    )\n",
            "  )\n",
            "  (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
            "  (fc): Linear(in_features=2048, out_features=1000, bias=True)\n",
            ")\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "IN_FEATURES = pretrained_model.fc.in_features\n",
        "OUTPUT_DIM = len(test_data.classes)\n",
        "\n",
        "fc = nn.Linear(IN_FEATURES, OUTPUT_DIM)"
      ],
      "metadata": {
        "id": "nKzsgsugPgRK"
      },
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pretrained_model.fc = fc"
      ],
      "metadata": {
        "id": "BuvdXiScQAme"
      },
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = ResNet(resnet50_config, OUTPUT_DIM)"
      ],
      "metadata": {
        "id": "y-7e0yt3QAjo"
      },
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.load_state_dict(pretrained_model.state_dict())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CT5jNlrSQAhJ",
        "outputId": "d0309ca9-651f-4df9-c6fc-ba914425bdc5"
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<All keys matched successfully>"
            ]
          },
          "metadata": {},
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "optimizer = optim.Adam(model.parameters())\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "model = model.to(device)\n",
        "criterion = criterion.to(device)"
      ],
      "metadata": {
        "id": "wgPrmWthJKsY"
      },
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Profiling"
      ],
      "metadata": {
        "id": "sJ27GdzZQvKs"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model.train()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Sh9upIVcJMGh",
        "outputId": "ca055f94-7e76-4301-ebf9-cecd52134171"
      },
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "ResNet(\n",
              "  (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
              "  (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "  (relu): ReLU(inplace=True)\n",
              "  (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
              "  (layer1): Sequential(\n",
              "    (0): Bottleneck(\n",
              "      (conv1): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "      (downsample): Sequential(\n",
              "        (0): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      )\n",
              "    )\n",
              "    (1): Bottleneck(\n",
              "      (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "    )\n",
              "    (2): Bottleneck(\n",
              "      (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "    )\n",
              "  )\n",
              "  (layer2): Sequential(\n",
              "    (0): Bottleneck(\n",
              "      (conv1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "      (downsample): Sequential(\n",
              "        (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
              "        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      )\n",
              "    )\n",
              "    (1): Bottleneck(\n",
              "      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "    )\n",
              "    (2): Bottleneck(\n",
              "      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "    )\n",
              "    (3): Bottleneck(\n",
              "      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "    )\n",
              "  )\n",
              "  (layer3): Sequential(\n",
              "    (0): Bottleneck(\n",
              "      (conv1): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "      (downsample): Sequential(\n",
              "        (0): Conv2d(512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
              "        (1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      )\n",
              "    )\n",
              "    (1): Bottleneck(\n",
              "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "    )\n",
              "    (2): Bottleneck(\n",
              "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "    )\n",
              "    (3): Bottleneck(\n",
              "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "    )\n",
              "    (4): Bottleneck(\n",
              "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "    )\n",
              "    (5): Bottleneck(\n",
              "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "    )\n",
              "  )\n",
              "  (layer4): Sequential(\n",
              "    (0): Bottleneck(\n",
              "      (conv1): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "      (downsample): Sequential(\n",
              "        (0): Conv2d(1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
              "        (1): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      )\n",
              "    )\n",
              "    (1): Bottleneck(\n",
              "      (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "    )\n",
              "    (2): Bottleneck(\n",
              "      (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "    )\n",
              "  )\n",
              "  (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
              "  (fc): Linear(in_features=2048, out_features=200, bias=True)\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 29
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def train(data):\n",
        "    #print(data)\n",
        "    inputs, labels = data[0].to(device=device), data[1].to(device=device)\n",
        "    outputs,_ = model(inputs)\n",
        "    loss = criterion(outputs, labels)\n",
        "    optimizer.zero_grad()\n",
        "    loss.backward()\n",
        "    optimizer.step()"
      ],
      "metadata": {
        "id": "bYCI8p9EJNyo"
      },
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "prof = torch.profiler.profile(\n",
        "        schedule=torch.profiler.schedule(wait=1, warmup=1, active=3, repeat=2),\n",
        "        on_trace_ready=torch.profiler.tensorboard_trace_handler('./log/resnet'),\n",
        "        record_shapes=True,\n",
        "        with_stack=True)\n",
        "prof.start()\n",
        "for step, batch_data in enumerate(train_loader):\n",
        "    if step >= (1 + 1 + 3) * 2:\n",
        "        break\n",
        "    train(batch_data)\n",
        "    prof.step()\n",
        "prof.stop()"
      ],
      "metadata": {
        "id": "REm5F7BbJPQc"
      },
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(prof.key_averages())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Lkea-OeNJRHv",
        "outputId": "29f80855-85a9-444d-de70-0051ef9b99ca"
      },
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "-------------------------------------------------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  \n",
            "                                                   Name    Self CPU %      Self CPU   CPU total %     CPU total  CPU time avg     Self CUDA   Self CUDA %    CUDA total  CUDA time avg    # of Calls  \n",
            "-------------------------------------------------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  \n",
            "                                          ProfilerStep*         3.52%      82.385ms        75.69%        1.774s     591.263ms       0.000us         0.00%     574.992ms     191.664ms             3  \n",
            "enumerate(DataLoader)#_SingleProcessDataLoaderIter._...        41.05%     962.092ms        47.79%        1.120s     373.287ms       0.000us         0.00%       0.000us       0.000us             3  \n",
            "void at::native::vectorized_elementwise_kernel<4, at...         0.00%       0.000us         0.00%       0.000us       0.000us     707.000us         0.03%     707.000us       3.432us           206  \n",
            "void cudnn::bn_fw_tr_1C11_kernel_NCHW<float, float, ...         0.00%       0.000us         0.00%       0.000us       0.000us      63.942ms         2.80%      63.942ms       1.640ms            39  \n",
            "void at::native::vectorized_elementwise_kernel<4, at...         0.00%       0.000us         0.00%       0.000us       0.000us      76.858ms         3.37%      76.858ms     402.398us           191  \n",
            "                                  volta_sgemm_128x64_nn         0.00%       0.000us         0.00%       0.000us       0.000us      87.020ms         3.81%      87.020ms       1.116ms            78  \n",
            "                                            aten::empty         0.50%      11.663ms         0.50%      11.663ms       3.967us       0.000us         0.00%       0.000us       0.000us          2940  \n",
            "                                         aten::uniform_         0.10%       2.232ms         0.10%       2.232ms       5.812us       0.000us         0.00%       0.000us       0.000us           384  \n",
            "                                             aten::item         0.09%       2.083ms         0.10%       2.368ms       1.229us       0.000us         0.00%       0.000us       0.000us          1926  \n",
            "                              aten::_local_scalar_dense         0.02%     367.000us         0.02%     367.000us       0.191us       0.000us         0.00%       0.000us       0.000us          1926  \n",
            "                                             aten::rand         0.06%       1.441ms         0.12%       2.797ms      14.568us       0.000us         0.00%       0.000us       0.000us           192  \n",
            "                                               aten::lt         0.09%       2.041ms         0.20%       4.589ms      23.901us       0.000us         0.00%       0.000us       0.000us           192  \n",
            "                                               aten::to         0.12%       2.748ms        22.13%     518.605ms     314.879us       0.000us         0.00%      23.761ms      14.427us          1647  \n",
            "                                         aten::_to_copy         0.26%       6.091ms        22.03%     516.384ms     410.807us       0.000us         0.00%      23.761ms      18.903us          1257  \n",
            "                                    aten::empty_strided         0.28%       6.641ms         0.28%       6.641ms       2.746us       0.000us         0.00%       0.000us       0.000us          2418  \n",
            "                                            aten::copy_         1.58%      36.986ms        22.92%     537.149ms     327.330us      23.761ms         1.04%      23.761ms      14.480us          1641  \n",
            "                                       aten::is_nonzero         0.03%     712.000us         0.06%       1.449ms       3.773us       0.000us         0.00%       0.000us       0.000us           384  \n",
            "void at::native::vectorized_elementwise_kernel<4, at...         0.00%       0.000us         0.00%       0.000us       0.000us     134.178ms         5.88%     134.178ms       1.057ms           127  \n",
            "                                          aten::randint         0.08%       1.888ms         0.15%       3.487ms       9.081us       0.000us         0.00%       0.000us       0.000us           384  \n",
            "                                          aten::random_         0.04%     937.000us         0.04%     937.000us       2.440us       0.000us         0.00%       0.000us       0.000us           384  \n",
            "                                       aten::lift_fresh         0.01%     260.000us         0.01%     260.000us       0.449us       0.000us         0.00%       0.000us       0.000us           579  \n",
            "                                             aten::view         0.10%       2.370ms         0.10%       2.370ms       2.625us       0.000us         0.00%       0.000us       0.000us           903  \n",
            "                                          aten::permute         0.05%       1.243ms         0.06%       1.475ms       7.682us       0.000us         0.00%       0.000us       0.000us           192  \n",
            "                                       aten::as_strided         0.02%     478.000us         0.02%     478.000us       1.189us       0.000us         0.00%       0.000us       0.000us           402  \n",
            "                                       aten::contiguous         0.10%       2.401ms         0.81%      19.031ms      99.120us       0.000us         0.00%       0.000us       0.000us           192  \n",
            "                                            aten::clone         0.12%       2.745ms         1.42%      33.290ms      86.693us       0.000us         0.00%       0.000us       0.000us           384  \n",
            "                                       aten::empty_like         0.06%       1.398ms         0.14%       3.291ms       9.297us       0.000us         0.00%       0.000us       0.000us           354  \n",
            "                                              aten::div         0.63%      14.678ms         0.71%      16.621ms      85.236us     379.000us         0.02%     379.000us       1.944us           195  \n",
            "                                               aten::eq         0.08%       1.976ms         0.18%       4.179ms      21.766us       0.000us         0.00%       0.000us       0.000us           192  \n",
            "                                              aten::any         0.09%       2.039ms         0.10%       2.259ms      11.766us       0.000us         0.00%       0.000us       0.000us           192  \n",
            "                                            aten::fill_         0.00%     111.000us         0.01%     267.000us       1.328us       2.662ms         0.12%       2.662ms      13.244us           201  \n",
            "                                             aten::sub_         0.30%       6.953ms         0.30%       6.953ms      36.214us       0.000us         0.00%       0.000us       0.000us           192  \n",
            "                                             aten::div_         0.32%       7.550ms         0.32%       7.550ms      39.323us       0.000us         0.00%       0.000us       0.000us           192  \n",
            "void cudnn::winograd_nonfused::winogradForwardData4x...         0.00%       0.000us         0.00%       0.000us       0.000us      42.840ms         1.88%      42.840ms     420.000us           102  \n",
            "void cudnn::winograd_nonfused::winogradForwardFilter...         0.00%       0.000us         0.00%       0.000us       0.000us       6.990ms         0.31%       6.990ms      68.529us           102  \n",
            "void cudnn::winograd_nonfused::winogradForwardOutput...         0.00%       0.000us         0.00%       0.000us       0.000us      38.363ms         1.68%      38.363ms     376.108us           102  \n",
            "void cask_cudnn::computeOffsetsKernel<false, false>(...         0.00%       0.000us         0.00%       0.000us       0.000us     494.000us         0.02%     494.000us       3.890us           127  \n",
            "       cudnn_volta_scudnn_128x64_relu_xregs_large_nn_v1         0.00%       0.000us         0.00%       0.000us       0.000us      34.193ms         1.50%      34.193ms       3.108ms            11  \n",
            "void cudnn::bn_fw_tr_1C11_kernel_NCHW<float, float, ...         0.00%       0.000us         0.00%       0.000us       0.000us      71.633ms         3.14%      71.633ms     559.633us           128  \n",
            "            cudnn_volta_scudnn_128x64_relu_medium_nn_v1         0.00%       0.000us         0.00%       0.000us       0.000us      36.172ms         1.58%      36.172ms       1.507ms            24  \n",
            "           cudnn_volta_scudnn_128x128_relu_medium_nn_v1         0.00%       0.000us         0.00%       0.000us       0.000us     167.707ms         7.35%     167.707ms       1.823ms            92  \n",
            "void cudnn::bn_fw_tr_1C11_singleread<float, 512, tru...         0.00%       0.000us         0.00%       0.000us       0.000us       7.588ms         0.33%       7.588ms     210.778us            36  \n",
            "void at::native::reduce_kernel<512, 1, at::native::R...         0.00%       0.000us         0.00%       0.000us       0.000us       1.039ms         0.05%       1.039ms     259.750us             4  \n",
            "                         volta_sgemm_64x32_sliced1x4_tn         0.00%       0.000us         0.00%       0.000us       0.000us     143.000us         0.01%     143.000us      35.750us             4  \n",
            "void splitKreduce_kernel<32, 16, int, float, float, ...         0.00%       0.000us         0.00%       0.000us       0.000us      20.000us         0.00%      20.000us       5.000us             4  \n",
            "void (anonymous namespace)::softmax_warp_forward<flo...         0.00%       0.000us         0.00%       0.000us       0.000us      16.000us         0.00%      16.000us       4.000us             4  \n",
            "void at::native::(anonymous namespace)::nll_loss_for...         0.00%       0.000us         0.00%       0.000us       0.000us      19.000us         0.00%      19.000us       4.750us             4  \n",
            "void at::native::vectorized_elementwise_kernel<4, at...         0.00%       0.000us         0.00%       0.000us       0.000us       3.546ms         0.16%       3.546ms     295.500us            12  \n",
            "void at::native::(anonymous namespace)::nll_loss_bac...         0.00%       0.000us         0.00%       0.000us       0.000us      16.000us         0.00%      16.000us       4.000us             4  \n",
            "void (anonymous namespace)::softmax_warp_backward<fl...         0.00%       0.000us         0.00%       0.000us       0.000us      16.000us         0.00%      16.000us       4.000us             4  \n",
            "                                  volta_sgemm_128x32_nn         0.00%       0.000us         0.00%       0.000us       0.000us     103.000us         0.00%     103.000us      25.750us             4  \n",
            "                                  volta_sgemm_128x32_nt         0.00%       0.000us         0.00%       0.000us       0.000us     110.000us         0.00%     110.000us      27.500us             4  \n",
            "void at::native::reduce_kernel<128, 4, at::native::R...         0.00%       0.000us         0.00%       0.000us       0.000us      44.000us         0.00%      44.000us      11.000us             4  \n",
            "void at::native::elementwise_kernel<128, 2, at::nati...         0.00%       0.000us         0.00%       0.000us       0.000us     500.000us         0.02%     500.000us     125.000us             4  \n",
            "void at::native::vectorized_elementwise_kernel<4, at...         0.00%       0.000us         0.00%       0.000us       0.000us     117.748ms         5.16%     117.748ms     600.755us           196  \n",
            "void cudnn::bn_bw_1C11_singleread<float, 512, true, ...         0.00%       0.000us         0.00%       0.000us       0.000us       9.027ms         0.40%       9.027ms     250.750us            36  \n",
            "void cask_cudnn::computeOffsetsKernel<true, false>(c...         0.00%       0.000us         0.00%       0.000us       0.000us     295.000us         0.01%     295.000us       4.338us            68  \n",
            "cask_cudnn::computeBOffsetsKernel(cask_cudnn::Comput...         0.00%       0.000us         0.00%       0.000us       0.000us     236.000us         0.01%     236.000us       3.471us            68  \n",
            "         cudnn_volta_scudnn_128x64_stridedB_small_nn_v1         0.00%       0.000us         0.00%       0.000us       0.000us     133.105ms         5.83%     133.105ms       1.957ms            68  \n",
            "                                  volta_sgemm_128x64_tn         0.00%       0.000us         0.00%       0.000us       0.000us     235.849ms        10.33%     235.849ms       2.106ms           112  \n",
            "void cudnn::cnn::reduce_wgrad_nchw_helper<float, flo...         0.00%       0.000us         0.00%       0.000us       0.000us      40.246ms         1.76%      40.246ms     346.948us           116  \n",
            "                                  volta_sgemm_128x64_nt         0.00%       0.000us         0.00%       0.000us       0.000us     199.685ms         8.75%     199.685ms       1.387ms           144  \n",
            "void cudnn::winograd_nonfused::winogradWgradData4x4<...         0.00%       0.000us         0.00%       0.000us       0.000us      21.819ms         0.96%      21.819ms     419.596us            52  \n",
            "void cudnn::winograd_nonfused::winogradWgradDelta4x4...         0.00%       0.000us         0.00%       0.000us       0.000us      23.099ms         1.01%      23.099ms     444.212us            52  \n",
            "void cudnn::winograd_nonfused::winogradWgradOutput4x...         0.00%       0.000us         0.00%       0.000us       0.000us       6.000ms         0.26%       6.000ms     115.385us            52  \n",
            "void cudnn::ops::scalePackedTensor_kernel<float, flo...         0.00%       0.000us         0.00%       0.000us       0.000us       8.939ms         0.39%       8.939ms     446.950us            20  \n",
            "void cudnn::detail::dgrad_engine<float, 512, 6, 5, 3...         0.00%       0.000us         0.00%       0.000us       0.000us      53.958ms         2.36%      53.958ms       6.745ms             8  \n",
            "                                        Memset (Device)         0.00%       0.000us         0.00%       0.000us       0.000us     358.000us         0.02%     358.000us       5.967us            60  \n",
            "void cudnn::cnn::wgrad_alg1_engine<float, float, 128...         0.00%       0.000us         0.00%       0.000us       0.000us      20.837ms         0.91%      20.837ms       5.209ms             4  \n",
            "cask_cudnn::computeWgradSplitKOffsetsKernel(cask_cud...         0.00%       0.000us         0.00%       0.000us       0.000us      59.000us         0.00%      59.000us       3.688us            16  \n",
            "cask_cudnn::computeWgradBOffsetsKernel(cask_cudnn::C...         0.00%       0.000us         0.00%       0.000us       0.000us      52.000us         0.00%      52.000us       3.250us            16  \n",
            "cudnn_turing_scudnn_128x64_stridedB_splitK_xregs_lar...         0.00%       0.000us         0.00%       0.000us       0.000us      74.960ms         3.28%      74.960ms       4.685ms            16  \n",
            "void cudnn::bn_bw_1C11_kernel_new<float, float, floa...         0.00%       0.000us         0.00%       0.000us       0.000us     119.631ms         5.24%     119.631ms     934.617us           128  \n",
            "void cudnn::detail::dgrad_engine<float, 128, 6, 8, 3...         0.00%       0.000us         0.00%       0.000us       0.000us      63.969ms         2.80%      63.969ms       5.331ms            12  \n",
            "void wgrad_alg0_engine<float, 128, 6, 8, 3, 3, 5, fa...         0.00%       0.000us         0.00%       0.000us       0.000us      80.898ms         3.54%      80.898ms       3.371ms            24  \n",
            "                                   volta_sgemm_64x64_nt         0.00%       0.000us         0.00%       0.000us       0.000us      32.685ms         1.43%      32.685ms       1.362ms            24  \n",
            "                                            aten::stack         0.01%     135.000us         2.31%      54.193ms      18.064ms       0.000us         0.00%       0.000us       0.000us             3  \n",
            "                                              aten::cat         2.31%      54.042ms         2.31%      54.042ms      18.014ms       0.000us         0.00%       0.000us       0.000us             3  \n",
            "                                          aten::detach_         0.00%      11.000us         0.00%      18.000us       6.000us       0.000us         0.00%       0.000us       0.000us             3  \n",
            "                                                detach_         0.00%       7.000us         0.00%       7.000us       2.333us       0.000us         0.00%       0.000us       0.000us             3  \n",
            "                                        cudaMemcpyAsync        21.33%     499.972ms        21.33%     499.972ms      83.329ms       0.000us         0.00%       0.000us       0.000us             6  \n",
            "void fft2d_r2c_32x32<float, true, 0u, false>(float2*...         0.00%       0.000us         0.00%       0.000us       0.000us       4.968ms         0.22%       4.968ms     310.500us            16  \n",
            "void fft2d_r2c_32x32<float, false, 1u, false>(float2...         0.00%       0.000us         0.00%       0.000us       0.000us       1.545ms         0.07%       1.545ms     386.250us             4  \n",
            "                                  volta_gcgemm_64x32_nt         0.00%       0.000us         0.00%       0.000us       0.000us      17.457ms         0.76%      17.457ms       1.091ms            16  \n",
            "void fft2d_c2r_32x32<float, false, false, 0u, false,...         0.00%       0.000us         0.00%       0.000us       0.000us       8.119ms         0.36%       8.119ms     507.438us            16  \n",
            "void cudnn::bn_bw_1C11_kernel_new<float, float, floa...         0.00%       0.000us         0.00%       0.000us       0.000us     117.335ms         5.14%     117.335ms       2.667ms            44  \n",
            "                                   volta_sgemm_64x64_tn         0.00%       0.000us         0.00%       0.000us       0.000us       4.181ms         0.18%       4.181ms       1.045ms             4  \n",
            "void at::native::(anonymous namespace)::max_pool_bac...         0.00%       0.000us         0.00%       0.000us       0.000us      21.131ms         0.93%      21.131ms       5.283ms             4  \n",
            "void cudnn::bn_bw_1C11_kernel_new<float, float, floa...         0.00%       0.000us         0.00%       0.000us       0.000us      19.770ms         0.87%      19.770ms       4.942ms             4  \n",
            "void at::native::(anonymous namespace)::multi_tensor...         0.00%       0.000us         0.00%       0.000us       0.000us       6.537ms         0.29%       6.537ms     408.562us            16  \n",
            "void at::native::(anonymous namespace)::multi_tensor...         0.00%       0.000us         0.00%       0.000us       0.000us       4.745ms         0.21%       4.745ms     395.417us            12  \n",
            "void at::native::(anonymous namespace)::multi_tensor...         0.00%       0.000us         0.00%       0.000us       0.000us       4.744ms         0.21%       4.744ms     296.500us            16  \n",
            "void at::native::(anonymous namespace)::multi_tensor...         0.00%       0.000us         0.00%       0.000us       0.000us       3.365ms         0.15%       3.365ms     280.417us            12  \n",
            "void at::native::(anonymous namespace)::multi_tensor...         0.00%       0.000us         0.00%       0.000us       0.000us       3.353ms         0.15%       3.353ms     279.417us            12  \n",
            "void at::native::(anonymous namespace)::multi_tensor...         0.00%       0.000us         0.00%       0.000us       0.000us       3.352ms         0.15%       3.352ms     279.333us            12  \n",
            "void at::native::(anonymous namespace)::multi_tensor...         0.00%       0.000us         0.00%       0.000us       0.000us       6.270ms         0.27%       6.270ms     391.875us            16  \n",
            "                       Memcpy HtoD (Pageable -> Device)         0.00%       0.000us         0.00%       0.000us       0.000us      23.761ms         1.04%      23.761ms       3.960ms             6  \n",
            "                                  cudaStreamSynchronize         0.01%     191.000us         0.01%     191.000us      31.833us       0.000us         0.00%       0.000us       0.000us             6  \n",
            "                                           aten::conv2d         0.03%     722.000us         0.60%      14.089ms      88.610us       0.000us         0.00%     284.144ms       1.787ms           159  \n",
            "                                      aten::convolution         0.07%       1.640ms         0.57%      13.428ms      84.453us       0.000us         0.00%     285.570ms       1.796ms           159  \n",
            "-------------------------------------------------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  \n",
            "Self CPU time total: 2.344s\n",
            "Self CUDA time total: 2.282s\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(prof.key_averages().table(sort_by=\"cpu_time_total\", row_limit=10))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "f1tpbBjuJbtw",
        "outputId": "ea07db49-4481-4854-d4bc-9b43de176af6"
      },
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "-------------------------------------------------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  \n",
            "                                                   Name    Self CPU %      Self CPU   CPU total %     CPU total  CPU time avg     Self CUDA   Self CUDA %    CUDA total  CUDA time avg    # of Calls  \n",
            "-------------------------------------------------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  \n",
            "                                          ProfilerStep*         3.52%      82.385ms        75.69%        1.774s     591.263ms       0.000us         0.00%     574.992ms     191.664ms             3  \n",
            "enumerate(DataLoader)#_SingleProcessDataLoaderIter._...        41.05%     962.092ms        47.79%        1.120s     373.287ms       0.000us         0.00%       0.000us       0.000us             3  \n",
            "                                            aten::copy_         1.58%      36.986ms        22.92%     537.149ms     327.330us      23.761ms         1.04%      23.761ms      14.480us          1641  \n",
            "                                               aten::to         0.12%       2.748ms        22.13%     518.605ms     314.879us       0.000us         0.00%      23.761ms      14.427us          1647  \n",
            "                                  cudaDeviceSynchronize        22.05%     516.714ms        22.05%     516.714ms     516.714ms       0.000us         0.00%       0.000us       0.000us             1  \n",
            "                                         aten::_to_copy         0.26%       6.091ms        22.03%     516.384ms     410.807us       0.000us         0.00%      23.761ms      18.903us          1257  \n",
            "                                        cudaMemcpyAsync        21.33%     499.972ms        21.33%     499.972ms      83.329ms       0.000us         0.00%       0.000us       0.000us             6  \n",
            "                                            aten::stack         0.01%     135.000us         2.31%      54.193ms      18.064ms       0.000us         0.00%       0.000us       0.000us             3  \n",
            "                                              aten::cat         2.31%      54.042ms         2.31%      54.042ms      18.014ms       0.000us         0.00%       0.000us       0.000us             3  \n",
            "                                            aten::clone         0.12%       2.745ms         1.42%      33.290ms      86.693us       0.000us         0.00%       0.000us       0.000us           384  \n",
            "-------------------------------------------------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  \n",
            "Self CPU time total: 2.344s\n",
            "Self CUDA time total: 2.282s\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(prof.key_averages(group_by_input_shape=True).table(sort_by=\"cpu_time_total\", row_limit=10))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eG-JUCXGJe2b",
        "outputId": "0d54ee8e-8317-4761-8397-48a7f762d15b"
      },
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "-------------------------------------------------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  --------------------------------------------------------------------------------  \n",
            "                                                   Name    Self CPU %      Self CPU   CPU total %     CPU total  CPU time avg     Self CUDA   Self CUDA %    CUDA total  CUDA time avg    # of Calls                                                                      Input Shapes  \n",
            "-------------------------------------------------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  --------------------------------------------------------------------------------  \n",
            "                                          ProfilerStep*         3.52%      82.385ms        75.69%        1.774s     591.263ms       0.000us         0.00%     574.992ms     191.664ms             3                                                                                []  \n",
            "enumerate(DataLoader)#_SingleProcessDataLoaderIter._...        41.05%     962.092ms        47.79%        1.120s     373.287ms       0.000us         0.00%       0.000us       0.000us             3                                                                                []  \n",
            "                                  cudaDeviceSynchronize        22.05%     516.714ms        22.05%     516.714ms     516.714ms       0.000us         0.00%       0.000us       0.000us             1                                                                                []  \n",
            "                                               aten::to         0.00%     116.000us        21.35%     500.403ms     166.801ms       0.000us         0.00%      23.758ms       7.919ms             3                                   [[64, 3, 224, 224], [], [], [], [], [], [], []]  \n",
            "                                         aten::_to_copy         0.00%      50.000us        21.35%     500.287ms     166.762ms       0.000us         0.00%      23.758ms       7.919ms             3                                       [[64, 3, 224, 224], [], [], [], [], [], []]  \n",
            "                                            aten::copy_         0.00%     113.000us        21.34%     500.152ms     166.717ms      23.758ms         1.04%      23.758ms       7.919ms             3                                        [[64, 3, 224, 224], [64, 3, 224, 224], []]  \n",
            "                                        cudaMemcpyAsync        21.33%     499.972ms        21.33%     499.972ms      83.329ms       0.000us         0.00%       0.000us       0.000us             6                                                                                []  \n",
            "                                            aten::stack         0.01%     135.000us         2.31%      54.193ms      18.064ms       0.000us         0.00%       0.000us       0.000us             3                                                                          [[], []]  \n",
            "                                              aten::cat         2.31%      54.042ms         2.31%      54.042ms      18.014ms       0.000us         0.00%       0.000us       0.000us             3                                                                          [[], []]  \n",
            "                                            aten::copy_         1.51%      35.433ms         1.51%      35.433ms      61.516us       0.000us         0.00%       0.000us       0.000us           576                                                [[3, 224, 224], [3, 224, 224], []]  \n",
            "-------------------------------------------------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  --------------------------------------------------------------------------------  \n",
            "Self CPU time total: 2.344s\n",
            "Self CUDA time total: 2.282s\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(prof.key_averages().table(sort_by=\"cuda_time_total\", row_limit=10))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EYs1AetHJhUr",
        "outputId": "d3775648-44c2-4e6e-c917-962ed11f840a"
      },
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "-------------------------------------------------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  \n",
            "                                                   Name    Self CPU %      Self CPU   CPU total %     CPU total  CPU time avg     Self CUDA   Self CUDA %    CUDA total  CUDA time avg    # of Calls  \n",
            "-------------------------------------------------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  \n",
            "autograd::engine::evaluate_function: ConvolutionBack...         0.10%       2.270ms         1.08%      25.299ms     159.113us       0.000us         0.00%     863.215ms       5.429ms           159  \n",
            "                                   ConvolutionBackward0         0.04%     984.000us         0.94%      21.985ms     138.270us       0.000us         0.00%     811.943ms       5.107ms           159  \n",
            "                             aten::convolution_backward         0.59%      13.830ms         0.90%      21.001ms     132.082us     811.943ms        35.58%     811.943ms       5.107ms           159  \n",
            "                                          ProfilerStep*         3.52%      82.385ms        75.69%        1.774s     591.263ms       0.000us         0.00%     574.992ms     191.664ms             3  \n",
            "                                      aten::convolution         0.07%       1.640ms         0.57%      13.428ms      84.453us       0.000us         0.00%     285.570ms       1.796ms           159  \n",
            "                                     aten::_convolution         0.05%       1.090ms         0.50%      11.788ms      74.138us       0.000us         0.00%     285.570ms       1.796ms           159  \n",
            "                                aten::cudnn_convolution         0.34%       7.899ms         0.46%      10.698ms      67.283us     285.570ms        12.51%     285.570ms       1.796ms           159  \n",
            "                                           aten::conv2d         0.03%     722.000us         0.60%      14.089ms      88.610us       0.000us         0.00%     284.144ms       1.787ms           159  \n",
            "                                  volta_sgemm_128x64_tn         0.00%       0.000us         0.00%       0.000us       0.000us     235.849ms        10.33%     235.849ms       2.106ms           112  \n",
            "                                  volta_sgemm_128x64_nt         0.00%       0.000us         0.00%       0.000us       0.000us     199.685ms         8.75%     199.685ms       1.387ms           144  \n",
            "-------------------------------------------------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  \n",
            "Self CPU time total: 2.344s\n",
            "Self CUDA time total: 2.282s\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(prof.key_averages().table(sort_by=\"self_cpu_memory_usage\", row_limit=10))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BUlle4EGJjTX",
        "outputId": "4cd9dea0-e472-4a64-f07b-f70f48eca85c"
      },
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "-------------------------------------------------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  \n",
            "                                                   Name    Self CPU %      Self CPU   CPU total %     CPU total  CPU time avg     Self CUDA   Self CUDA %    CUDA total  CUDA time avg    # of Calls  \n",
            "-------------------------------------------------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  \n",
            "                                          ProfilerStep*         3.52%      82.385ms        75.69%        1.774s     591.263ms       0.000us         0.00%     574.992ms     191.664ms             3  \n",
            "enumerate(DataLoader)#_SingleProcessDataLoaderIter._...        41.05%     962.092ms        47.79%        1.120s     373.287ms       0.000us         0.00%       0.000us       0.000us             3  \n",
            "void at::native::vectorized_elementwise_kernel<4, at...         0.00%       0.000us         0.00%       0.000us       0.000us     707.000us         0.03%     707.000us       3.432us           206  \n",
            "void cudnn::bn_fw_tr_1C11_kernel_NCHW<float, float, ...         0.00%       0.000us         0.00%       0.000us       0.000us      63.942ms         2.80%      63.942ms       1.640ms            39  \n",
            "void at::native::vectorized_elementwise_kernel<4, at...         0.00%       0.000us         0.00%       0.000us       0.000us      76.858ms         3.37%      76.858ms     402.398us           191  \n",
            "                                  volta_sgemm_128x64_nn         0.00%       0.000us         0.00%       0.000us       0.000us      87.020ms         3.81%      87.020ms       1.116ms            78  \n",
            "                                            aten::empty         0.50%      11.663ms         0.50%      11.663ms       3.967us       0.000us         0.00%       0.000us       0.000us          2940  \n",
            "                                         aten::uniform_         0.10%       2.232ms         0.10%       2.232ms       5.812us       0.000us         0.00%       0.000us       0.000us           384  \n",
            "                                             aten::item         0.09%       2.083ms         0.10%       2.368ms       1.229us       0.000us         0.00%       0.000us       0.000us          1926  \n",
            "                              aten::_local_scalar_dense         0.02%     367.000us         0.02%     367.000us       0.191us       0.000us         0.00%       0.000us       0.000us          1926  \n",
            "-------------------------------------------------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  \n",
            "Self CPU time total: 2.344s\n",
            "Self CUDA time total: 2.282s\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(prof.key_averages().table(sort_by=\"cpu_memory_usage\", row_limit=10))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wY7jCw1jJlS-",
        "outputId": "db541f15-d3aa-4004-922c-68d681ae8ae2"
      },
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "-------------------------------------------------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  \n",
            "                                                   Name    Self CPU %      Self CPU   CPU total %     CPU total  CPU time avg     Self CUDA   Self CUDA %    CUDA total  CUDA time avg    # of Calls  \n",
            "-------------------------------------------------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  \n",
            "                                          ProfilerStep*         3.52%      82.385ms        75.69%        1.774s     591.263ms       0.000us         0.00%     574.992ms     191.664ms             3  \n",
            "enumerate(DataLoader)#_SingleProcessDataLoaderIter._...        41.05%     962.092ms        47.79%        1.120s     373.287ms       0.000us         0.00%       0.000us       0.000us             3  \n",
            "void at::native::vectorized_elementwise_kernel<4, at...         0.00%       0.000us         0.00%       0.000us       0.000us     707.000us         0.03%     707.000us       3.432us           206  \n",
            "void cudnn::bn_fw_tr_1C11_kernel_NCHW<float, float, ...         0.00%       0.000us         0.00%       0.000us       0.000us      63.942ms         2.80%      63.942ms       1.640ms            39  \n",
            "void at::native::vectorized_elementwise_kernel<4, at...         0.00%       0.000us         0.00%       0.000us       0.000us      76.858ms         3.37%      76.858ms     402.398us           191  \n",
            "                                  volta_sgemm_128x64_nn         0.00%       0.000us         0.00%       0.000us       0.000us      87.020ms         3.81%      87.020ms       1.116ms            78  \n",
            "                                            aten::empty         0.50%      11.663ms         0.50%      11.663ms       3.967us       0.000us         0.00%       0.000us       0.000us          2940  \n",
            "                                         aten::uniform_         0.10%       2.232ms         0.10%       2.232ms       5.812us       0.000us         0.00%       0.000us       0.000us           384  \n",
            "                                             aten::item         0.09%       2.083ms         0.10%       2.368ms       1.229us       0.000us         0.00%       0.000us       0.000us          1926  \n",
            "                              aten::_local_scalar_dense         0.02%     367.000us         0.02%     367.000us       0.191us       0.000us         0.00%       0.000us       0.000us          1926  \n",
            "-------------------------------------------------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  \n",
            "Self CPU time total: 2.344s\n",
            "Self CUDA time total: 2.282s\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(prof.key_averages(group_by_stack_n=5).table(sort_by=\"self_cuda_time_total\", row_limit=2))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-6JeJkznJnFL",
        "outputId": "7c8bac04-73b7-4ca5-80d5-48f43c631c84"
      },
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "-------------------------------------------------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  \n",
            "                                                   Name    Self CPU %      Self CPU   CPU total %     CPU total  CPU time avg     Self CUDA   Self CUDA %    CUDA total  CUDA time avg    # of Calls  \n",
            "-------------------------------------------------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  \n",
            "                             aten::convolution_backward         0.59%      13.830ms         0.90%      21.001ms     132.082us     811.943ms        35.58%     811.943ms       5.107ms           159  \n",
            "                                aten::cudnn_convolution         0.34%       7.899ms         0.46%      10.698ms      67.283us     285.570ms        12.51%     285.570ms       1.796ms           159  \n",
            "-------------------------------------------------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  \n",
            "Self CPU time total: 2.344s\n",
            "Self CUDA time total: 2.282s\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UGhIqttCJo5u",
        "outputId": "931e597f-02f5-4ec0-f0d8-ad8fd5dde483"
      },
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!mv /content/log /content/drive/MyDrive"
      ],
      "metadata": {
        "id": "uefqh6jPJ7Kc"
      },
      "execution_count": 40,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Profiling with Automatic Mixed Precision"
      ],
      "metadata": {
        "id": "NRigkrENP1Tm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch, time, gc\n",
        "\n",
        "# Timing utilities\n",
        "start_time = None\n",
        "\n",
        "def start_timer():\n",
        "    global start_time\n",
        "    gc.collect()\n",
        "    torch.cuda.empty_cache()\n",
        "    torch.cuda.reset_max_memory_allocated()\n",
        "    torch.cuda.synchronize()\n",
        "    start_time = time.time()\n",
        "\n",
        "def end_timer_and_print(local_msg):\n",
        "    torch.cuda.synchronize()\n",
        "    end_time = time.time()\n",
        "    print(\"\\n\" + local_msg)\n",
        "    print(\"Total execution time = {:.3f} sec\".format(end_time - start_time))\n",
        "    print(\"Max memory used by tensors = {} bytes\".format(torch.cuda.max_memory_allocated()))"
      ],
      "metadata": {
        "id": "VsLH_Xq_KdwN"
      },
      "execution_count": 41,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.train()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "A7_jrcg-Q9rm",
        "outputId": "c7fc2d27-087b-419b-eedd-8bbe6d06abdf"
      },
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "ResNet(\n",
              "  (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
              "  (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "  (relu): ReLU(inplace=True)\n",
              "  (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
              "  (layer1): Sequential(\n",
              "    (0): Bottleneck(\n",
              "      (conv1): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "      (downsample): Sequential(\n",
              "        (0): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      )\n",
              "    )\n",
              "    (1): Bottleneck(\n",
              "      (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "    )\n",
              "    (2): Bottleneck(\n",
              "      (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "    )\n",
              "  )\n",
              "  (layer2): Sequential(\n",
              "    (0): Bottleneck(\n",
              "      (conv1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "      (downsample): Sequential(\n",
              "        (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
              "        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      )\n",
              "    )\n",
              "    (1): Bottleneck(\n",
              "      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "    )\n",
              "    (2): Bottleneck(\n",
              "      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "    )\n",
              "    (3): Bottleneck(\n",
              "      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "    )\n",
              "  )\n",
              "  (layer3): Sequential(\n",
              "    (0): Bottleneck(\n",
              "      (conv1): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "      (downsample): Sequential(\n",
              "        (0): Conv2d(512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
              "        (1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      )\n",
              "    )\n",
              "    (1): Bottleneck(\n",
              "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "    )\n",
              "    (2): Bottleneck(\n",
              "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "    )\n",
              "    (3): Bottleneck(\n",
              "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "    )\n",
              "    (4): Bottleneck(\n",
              "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "    )\n",
              "    (5): Bottleneck(\n",
              "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "    )\n",
              "  )\n",
              "  (layer4): Sequential(\n",
              "    (0): Bottleneck(\n",
              "      (conv1): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "      (downsample): Sequential(\n",
              "        (0): Conv2d(1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
              "        (1): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      )\n",
              "    )\n",
              "    (1): Bottleneck(\n",
              "      (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "    )\n",
              "    (2): Bottleneck(\n",
              "      (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "    )\n",
              "  )\n",
              "  (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
              "  (fc): Linear(in_features=2048, out_features=200, bias=True)\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 42
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "use_amp = True\n",
        "scaler = torch.cuda.amp.GradScaler(enabled=use_amp)\n",
        "\n",
        "def train(data):\n",
        "  inputs, labels = data[0].to(device=device), data[1].to(device=device)\n",
        "  with torch.autocast(device_type='cuda', dtype=torch.float16, enabled=use_amp):\n",
        "    outputs,_ = model(inputs)\n",
        "    loss = criterion(outputs, labels)\n",
        "  scaler.scale(loss).backward()\n",
        "  scaler.step(optimizer)\n",
        "  scaler.update()\n",
        "  optimizer.zero_grad() # set_to_non"
      ],
      "metadata": {
        "id": "VTT_3WVRRBq0"
      },
      "execution_count": 43,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "prof = torch.profiler.profile(\n",
        "        schedule=torch.profiler.schedule(wait=1, warmup=1, active=3, repeat=2),\n",
        "        on_trace_ready=torch.profiler.tensorboard_trace_handler('./log/resnet_amp'),\n",
        "        record_shapes=True,\n",
        "        with_stack=True)\n",
        "prof.start()\n",
        "start_timer()\n",
        "for step, batch_data in enumerate(train_loader):\n",
        "\n",
        "    if step >= (1 + 1 + 3) * 2:\n",
        "        break\n",
        "    train(batch_data)\n",
        "    prof.step()\n",
        "prof.stop()\n",
        "end_timer_and_print(\"Mixed precision:\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XJJr__9qSMLb",
        "outputId": "8bed3c3a-a97d-4d84-937a-6f3cb8bcd732"
      },
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/cuda/memory.py:303: FutureWarning: torch.cuda.reset_max_memory_allocated now calls torch.cuda.reset_peak_memory_stats, which resets /all/ peak memory stats.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Mixed precision:\n",
            "Total execution time = 15.291 sec\n",
            "Max memory used by tensors = 3337145344 bytes\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(prof.key_averages())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Yymu1yPaSr6l",
        "outputId": "3da29b32-1193-42ad-bc9d-4dc0987e55f5"
      },
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "-------------------------------------------------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  \n",
            "                                                   Name    Self CPU %      Self CPU   CPU total %     CPU total  CPU time avg     Self CUDA   Self CUDA %    CUDA total  CUDA time avg    # of Calls  \n",
            "-------------------------------------------------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  \n",
            "at::native::amp_update_scale_cuda_kernel(float*, int...         0.00%       0.000us         0.00%       0.000us       0.000us      14.000us         0.00%      14.000us       3.500us             4  \n",
            "                                          ProfilerStep*         5.76%     153.105ms        96.30%        2.560s     853.294ms       0.000us         0.00%     288.596ms      96.199ms             3  \n",
            "enumerate(DataLoader)#_SingleProcessDataLoaderIter._...        60.29%        1.603s        67.52%        1.795s     598.301ms       0.000us         0.00%       0.000us       0.000us             3  \n",
            "                                            aten::empty         0.67%      17.713ms         0.67%      17.713ms       6.019us       0.000us         0.00%       0.000us       0.000us          2943  \n",
            "                                         aten::uniform_         0.11%       3.048ms         0.11%       3.048ms       7.938us       0.000us         0.00%       0.000us       0.000us           384  \n",
            "                                             aten::item         0.14%       3.768ms        17.38%     462.105ms     239.557us       0.000us         0.00%       6.000us       0.003us          1929  \n",
            "                              aten::_local_scalar_dense         0.03%     885.000us        17.24%     458.364ms     237.617us       6.000us         0.00%       6.000us       0.003us          1929  \n",
            "                                             aten::rand         0.09%       2.291ms         0.17%       4.566ms      23.781us       0.000us         0.00%       0.000us       0.000us           192  \n",
            "                                               aten::lt         0.10%       2.730ms         0.23%       6.064ms      31.583us       0.000us         0.00%       0.000us       0.000us           192  \n",
            "                                               aten::to         0.21%       5.450ms         2.60%      69.184ms      34.523us       0.000us         0.00%      31.053ms      15.496us          2004  \n",
            "                                         aten::_to_copy         0.45%      11.973ms         2.42%      64.422ms      40.063us       0.000us         0.00%      31.118ms      19.352us          1608  \n",
            "                                    aten::empty_strided         0.60%      15.951ms         0.60%      15.951ms       5.761us       0.000us         0.00%       0.000us       0.000us          2769  \n",
            "                                            aten::copy_         2.17%      57.801ms         3.33%      88.645ms      44.501us      31.118ms         4.35%      31.118ms      15.621us          1992  \n",
            "                                       aten::is_nonzero         0.03%     930.000us         0.08%       2.100ms       5.469us       0.000us         0.00%       0.000us       0.000us           384  \n",
            "                                          aten::randint         0.12%       3.230ms         0.21%       5.501ms      14.326us       0.000us         0.00%       0.000us       0.000us           384  \n",
            "                                          aten::random_         0.05%       1.333ms         0.05%       1.333ms       3.471us       0.000us         0.00%       0.000us       0.000us           384  \n",
            "                                       aten::lift_fresh         0.02%     441.000us         0.02%     441.000us       0.762us       0.000us         0.00%       0.000us       0.000us           579  \n",
            "                                             aten::view         0.12%       3.284ms         0.12%       3.284ms       3.637us       0.000us         0.00%       0.000us       0.000us           903  \n",
            "                                          aten::permute         0.06%       1.708ms         0.08%       2.106ms      10.969us       0.000us         0.00%       0.000us       0.000us           192  \n",
            "                                       aten::as_strided         0.03%     674.000us         0.03%     674.000us       1.664us       0.000us         0.00%       0.000us       0.000us           405  \n",
            "                                       aten::contiguous         0.05%       1.256ms         1.24%      33.015ms     171.953us       0.000us         0.00%       0.000us       0.000us           192  \n",
            "                                            aten::clone         0.18%       4.663ms         1.92%      50.963ms     132.716us       0.000us         0.00%       0.000us       0.000us           384  \n",
            "                                       aten::empty_like         0.07%       1.778ms         0.17%       4.486ms      12.672us       0.000us         0.00%       0.000us       0.000us           354  \n",
            "                                              aten::div         0.61%      16.312ms         0.70%      18.709ms      95.944us     265.000us         0.04%     265.000us       1.359us           195  \n",
            "                                               aten::eq         0.10%       2.770ms         0.21%       5.481ms      28.547us       0.000us         0.00%       0.000us       0.000us           192  \n",
            "                                              aten::any         0.10%       2.627ms         0.11%       2.878ms      14.990us       0.000us         0.00%       0.000us       0.000us           192  \n",
            "                                            aten::fill_         0.01%     151.000us         0.01%     309.000us       1.515us       1.345ms         0.19%       1.345ms       6.593us           204  \n",
            "                                             aten::sub_         0.28%       7.505ms         0.28%       7.505ms      39.089us       0.000us         0.00%       0.000us       0.000us           192  \n",
            "                                             aten::div_         0.29%       7.820ms         0.29%       7.820ms      40.729us       0.000us         0.00%       0.000us       0.000us           192  \n",
            "                                            aten::stack         0.01%     207.000us         2.14%      56.971ms      18.990ms       0.000us         0.00%       0.000us       0.000us             3  \n",
            "                                              aten::cat         2.13%      56.746ms         2.13%      56.746ms      18.915ms       0.000us         0.00%       0.000us       0.000us             3  \n",
            "                                          aten::detach_         0.00%      12.000us         0.00%      19.000us       6.333us       0.000us         0.00%       0.000us       0.000us             3  \n",
            "                                                detach_         0.00%       7.000us         0.00%       7.000us       2.333us       0.000us         0.00%       0.000us       0.000us             3  \n",
            "                                        cudaMemcpyAsync        18.19%     483.503ms        18.19%     483.503ms      32.234ms       0.000us         0.00%       0.000us       0.000us            15  \n",
            "                       Memcpy HtoD (Pageable -> Device)         0.00%       0.000us         0.00%       0.000us       0.000us      25.131ms         3.52%      25.131ms       4.189ms             6  \n",
            "                                  cudaStreamSynchronize         0.01%     248.000us         0.01%     248.000us      27.556us       0.000us         0.00%       0.000us       0.000us             9  \n",
            "                                           aten::conv2d         0.09%       2.476ms         1.92%      50.983ms     160.324us       0.000us         0.00%     220.215ms     692.500us           318  \n",
            "                                       cudaLaunchKernel         1.31%      34.815ms         1.31%      34.815ms      14.204us       0.000us         0.00%       0.000us       0.000us          2451  \n",
            "void at::native::unrolled_elementwise_kernel<at::nat...         0.00%       0.000us         0.00%       0.000us       0.000us       3.419ms         0.48%       3.419ms      19.994us           171  \n",
            "                                      aten::convolution         0.07%       1.896ms         0.73%      19.390ms     121.950us       0.000us         0.00%     109.082ms     686.050us           159  \n",
            "                                     aten::_convolution         0.05%       1.456ms         0.66%      17.494ms     110.025us       0.000us         0.00%     109.082ms     686.050us           159  \n",
            "                                aten::cudnn_convolution         0.44%      11.654ms         0.60%      16.038ms     100.868us     109.082ms        15.26%     109.082ms     686.050us           159  \n",
            "                                  cudaStreamIsCapturing         0.02%     619.000us         0.02%     619.000us       0.779us       0.000us         0.00%       0.000us       0.000us           795  \n",
            "                                  cudaStreamGetPriority         0.01%     217.000us         0.01%     217.000us       0.274us       0.000us         0.00%       0.000us       0.000us           792  \n",
            "                       cudaDeviceGetStreamPriorityRange         0.00%      94.000us         0.00%      94.000us       0.119us       0.000us         0.00%       0.000us       0.000us           792  \n",
            "                                        cudaMemsetAsync         0.07%       1.931ms         0.07%       1.931ms       9.753us       0.000us         0.00%       0.000us       0.000us           198  \n",
            "                                                INVALID         0.12%       3.180ms         0.12%       3.180ms       9.298us       0.000us         0.00%       0.000us       0.000us           342  \n",
            "                                        Memset (Device)         0.00%       0.000us         0.00%       0.000us       0.000us       2.341ms         0.33%       2.341ms      12.386us           189  \n",
            "void cudnn::ops::nchwToNhwcKernel<__half, __half, fl...         0.00%       0.000us         0.00%       0.000us       0.000us      72.738ms        10.17%      72.738ms     138.549us           525  \n",
            "                                             aten::add_         0.31%       8.188ms         0.58%      15.418ms      20.863us      49.618ms         6.94%      49.618ms      67.142us           739  \n",
            "                                       aten::batch_norm         0.03%     727.000us         0.83%      22.194ms     139.585us       0.000us         0.00%      65.063ms     409.201us           159  \n",
            "                           aten::_batch_norm_impl_index         0.04%     975.000us         0.81%      21.617ms     135.956us       0.000us         0.00%      65.141ms     409.692us           159  \n",
            "                                 aten::cudnn_batch_norm         0.38%       9.997ms         0.78%      20.642ms     129.824us      65.141ms         9.11%      65.141ms     409.692us           159  \n",
            "                                            aten::relu_         0.10%       2.625ms         0.24%       6.442ms      43.823us       0.000us         0.00%      29.606ms     201.401us           147  \n",
            "                                       aten::clamp_min_         0.08%       2.187ms         0.14%       3.817ms      25.966us      29.606ms         4.14%      29.606ms     201.401us           147  \n",
            "                                       aten::max_pool2d         0.00%      20.000us         0.01%     175.000us      58.333us       0.000us         0.00%       3.367ms       1.122ms             3  \n",
            "                          aten::max_pool2d_with_indices         0.00%     116.000us         0.01%     155.000us      51.667us       3.367ms         0.47%       3.367ms       1.122ms             3  \n",
            "sm75_xmma_fprop_image_first_layer_f16f16_f32_f16_nhw...         0.00%       0.000us         0.00%       0.000us       0.000us       2.637ms         0.37%       2.637ms     879.000us             3  \n",
            "void cudnn::ops::nhwcToNchwKernel<__half, __half, fl...         0.00%       0.000us         0.00%       0.000us       0.000us      34.925ms         4.89%      34.925ms     136.961us           255  \n",
            "void at::native::vectorized_elementwise_kernel<4, at...         0.00%       0.000us         0.00%       0.000us       0.000us     520.000us         0.07%     520.000us       3.270us           159  \n",
            "void cudnn::bn_fw_tr_1C11_kernel_NCHW<__half, float,...         0.00%       0.000us         0.00%       0.000us       0.000us       5.345ms         0.75%       5.345ms       1.782ms             3  \n",
            "void at::native::vectorized_elementwise_kernel<4, at...         0.00%       0.000us         0.00%       0.000us       0.000us      29.606ms         4.14%      29.606ms     201.401us           147  \n",
            "void at::native::(anonymous namespace)::max_pool_for...         0.00%       0.000us         0.00%       0.000us       0.000us       3.367ms         0.47%       3.367ms       1.122ms             3  \n",
            "turing_fp16_s1688gemm_fp16_256x64_ldg8_f2f_stages_32...         0.00%       0.000us         0.00%       0.000us       0.000us       3.839ms         0.54%       3.839ms     426.556us             9  \n",
            "void cudnn::bn_fw_tr_1C11_kernel_NCHW<__half, float,...         0.00%       0.000us         0.00%       0.000us       0.000us      29.600ms         4.14%      29.600ms     896.970us            33  \n",
            "sm75_xmma_fprop_implicit_gemm_f16f16_f16f32_f32_nhwc...         0.00%       0.000us         0.00%       0.000us       0.000us       4.499ms         0.63%       4.499ms     499.889us             9  \n",
            "turing_fp16_s1688gemm_fp16_128x128_ldg8_f2f_stages_3...         0.00%       0.000us         0.00%       0.000us       0.000us      18.356ms         2.57%      18.356ms     470.667us            39  \n",
            "void at::native::vectorized_elementwise_kernel<4, at...         0.00%       0.000us         0.00%       0.000us       0.000us      49.098ms         6.87%      49.098ms     511.438us            96  \n",
            "                              aten::adaptive_avg_pool2d         0.00%      22.000us         0.01%     213.000us      71.000us       0.000us         0.00%     782.000us     260.667us             3  \n",
            "                                             aten::mean         0.01%     148.000us         0.01%     191.000us      63.667us     782.000us         0.11%     782.000us     260.667us             3  \n",
            "                                           aten::linear         0.00%      21.000us         0.06%       1.482ms     247.000us       0.000us         0.00%     163.000us      27.167us             6  \n",
            "                                                aten::t         0.00%      78.000us         0.01%     168.000us      11.200us       0.000us         0.00%       0.000us       0.000us            15  \n",
            "                                        aten::transpose         0.00%      65.000us         0.00%      90.000us       6.000us       0.000us         0.00%       0.000us       0.000us            15  \n",
            "                                            aten::addmm         0.01%     356.000us         0.02%     490.000us     163.333us      53.000us         0.01%      53.000us      17.667us             3  \n",
            "cudaOccupancyMaxActiveBlocksPerMultiprocessorWithFla...         0.00%      73.000us         0.00%      73.000us       3.042us       0.000us         0.00%       0.000us       0.000us            24  \n",
            "sm75_xmma_fprop_implicit_gemm_f16f16_f16f32_f32_nhwc...         0.00%       0.000us         0.00%       0.000us       0.000us      31.126ms         4.35%      31.126ms     384.272us            81  \n",
            "                               aten::cross_entropy_loss         0.00%      38.000us         0.03%     919.000us     306.333us       0.000us         0.00%      42.000us      14.000us             3  \n",
            "                                      aten::log_softmax         0.00%      38.000us         0.02%     462.000us     154.000us       0.000us         0.00%      12.000us       4.000us             3  \n",
            "                                     aten::_log_softmax         0.00%     126.000us         0.02%     422.000us     140.667us      12.000us         0.00%      12.000us       4.000us             3  \n",
            "                                      aten::nll_loss_nd        -0.00%     -43.000us         0.02%     419.000us     139.667us       0.000us         0.00%      30.000us      10.000us             3  \n",
            "                                         aten::nll_loss         0.00%      94.000us         0.02%     607.000us     101.167us       0.000us         0.00%      40.000us       6.667us             6  \n",
            "                                 aten::nll_loss_forward         0.00%     126.000us         0.01%     189.000us      63.000us      15.000us         0.00%      15.000us       5.000us             3  \n",
            "                                          aten::resize_         0.00%       3.000us         0.00%       3.000us       1.000us       0.000us         0.00%       0.000us       0.000us             3  \n",
            "                                              aten::mul         0.01%     204.000us         0.01%     318.000us      53.000us      18.000us         0.00%      18.000us       3.000us             6  \n",
            "                                        aten::ones_like         0.00%      49.000us         0.01%     168.000us      56.000us       0.000us         0.00%       6.000us       2.000us             3  \n",
            "void cudnn::bn_fw_tr_1C11_kernel_NCHW<__half, float,...         0.00%       0.000us         0.00%       0.000us       0.000us      17.084ms         2.39%      17.084ms     438.051us            39  \n",
            "      autograd::engine::evaluate_function: MulBackward0         0.00%     118.000us         0.02%     480.000us     160.000us       0.000us         0.00%      31.000us      10.333us             3  \n",
            "                                           MulBackward0         0.00%      30.000us         0.01%     177.000us      59.000us       0.000us         0.00%       9.000us       3.000us             3  \n",
            "                                              aten::sum         0.01%     223.000us         0.01%     302.000us      50.333us      55.000us         0.01%      55.000us       9.167us             6  \n",
            "autograd::engine::evaluate_function: NllLossBackward...         0.00%      41.000us         0.01%     268.000us      89.333us       0.000us         0.00%      21.000us       7.000us             3  \n",
            "                                       NllLossBackward0         0.00%      22.000us         0.01%     227.000us      75.667us       0.000us         0.00%      21.000us       7.000us             3  \n",
            "                                aten::nll_loss_backward         0.00%      76.000us         0.01%     205.000us      68.333us      12.000us         0.00%      21.000us       7.000us             3  \n",
            "                                            aten::zero_         0.00%      36.000us         0.01%     175.000us      29.167us       0.000us         0.00%       1.329ms     221.500us             6  \n",
            "autograd::engine::evaluate_function: ToCopyBackward0...         0.05%       1.382ms         0.40%      10.513ms      62.577us       0.000us         0.00%       2.530ms      15.060us           168  \n",
            "                                        ToCopyBackward0         0.02%     453.000us         0.34%       8.985ms      53.482us       0.000us         0.00%       2.487ms      14.804us           168  \n",
            "autograd::engine::evaluate_function: LogSoftmaxBackw...         0.00%      29.000us         0.01%     158.000us      52.667us       0.000us         0.00%      12.000us       4.000us             3  \n",
            "                                    LogSoftmaxBackward0         0.00%      24.000us         0.00%     129.000us      43.000us       0.000us         0.00%      12.000us       4.000us             3  \n",
            "                       aten::_log_softmax_backward_data         0.00%      64.000us         0.00%     105.000us      35.000us      12.000us         0.00%      12.000us       4.000us             3  \n",
            "    autograd::engine::evaluate_function: AddmmBackward0         0.00%      63.000us         0.02%     663.000us     221.000us       0.000us         0.00%     116.000us      38.667us             3  \n",
            "                                         AddmmBackward0         0.00%      79.000us         0.02%     473.000us     157.667us       0.000us         0.00%      83.000us      27.667us             3  \n",
            "-------------------------------------------------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  \n",
            "Self CPU time total: 2.658s\n",
            "Self CUDA time total: 714.885ms\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(prof.key_averages().table(sort_by=\"cpu_time_total\", row_limit=10))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xDczy_94TaTc",
        "outputId": "058ec862-e9c4-4fff-e355-d3b5f3c66647"
      },
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "-------------------------------------------------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  \n",
            "                                                   Name    Self CPU %      Self CPU   CPU total %     CPU total  CPU time avg     Self CUDA   Self CUDA %    CUDA total  CUDA time avg    # of Calls  \n",
            "-------------------------------------------------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  \n",
            "                                          ProfilerStep*         5.76%     153.105ms        96.30%        2.560s     853.294ms       0.000us         0.00%     288.596ms      96.199ms             3  \n",
            "enumerate(DataLoader)#_SingleProcessDataLoaderIter._...        60.29%        1.603s        67.52%        1.795s     598.301ms       0.000us         0.00%       0.000us       0.000us             3  \n",
            "                                        cudaMemcpyAsync        18.19%     483.503ms        18.19%     483.503ms      32.234ms       0.000us         0.00%       0.000us       0.000us            15  \n",
            "                                             aten::item         0.14%       3.768ms        17.38%     462.105ms     239.557us       0.000us         0.00%       6.000us       0.003us          1929  \n",
            "                              aten::_local_scalar_dense         0.03%     885.000us        17.24%     458.364ms     237.617us       6.000us         0.00%       6.000us       0.003us          1929  \n",
            "                                            aten::copy_         2.17%      57.801ms         3.33%      88.645ms      44.501us      31.118ms         4.35%      31.118ms      15.621us          1992  \n",
            "                                               aten::to         0.21%       5.450ms         2.60%      69.184ms      34.523us       0.000us         0.00%      31.053ms      15.496us          2004  \n",
            "                                         aten::_to_copy         0.45%      11.973ms         2.42%      64.422ms      40.063us       0.000us         0.00%      31.118ms      19.352us          1608  \n",
            "                                            aten::stack         0.01%     207.000us         2.14%      56.971ms      18.990ms       0.000us         0.00%       0.000us       0.000us             3  \n",
            "                                              aten::cat         2.13%      56.746ms         2.13%      56.746ms      18.915ms       0.000us         0.00%       0.000us       0.000us             3  \n",
            "-------------------------------------------------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  \n",
            "Self CPU time total: 2.658s\n",
            "Self CUDA time total: 714.885ms\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(prof.key_averages(group_by_input_shape=True).table(sort_by=\"cpu_time_total\", row_limit=10))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1EtcnT1lTfb1",
        "outputId": "8e4957d0-14c7-44ab-e84d-5d75e2d27278"
      },
      "execution_count": 47,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "-------------------------------------------------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  --------------------------------------------------------------------------------  \n",
            "                                                   Name    Self CPU %      Self CPU   CPU total %     CPU total  CPU time avg     Self CUDA   Self CUDA %    CUDA total  CUDA time avg    # of Calls                                                                      Input Shapes  \n",
            "-------------------------------------------------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  --------------------------------------------------------------------------------  \n",
            "                                          ProfilerStep*         5.76%     153.105ms        96.30%        2.560s     853.294ms       0.000us         0.00%     288.596ms      96.199ms             3                                                                                []  \n",
            "enumerate(DataLoader)#_SingleProcessDataLoaderIter._...        60.29%        1.603s        67.52%        1.795s     598.301ms       0.000us         0.00%       0.000us       0.000us             3                                                                                []  \n",
            "                                        cudaMemcpyAsync        18.19%     483.503ms        18.19%     483.503ms      32.234ms       0.000us         0.00%       0.000us       0.000us            15                                                                                []  \n",
            "                                             aten::item         0.06%       1.691ms        17.30%     459.812ms     596.384us       0.000us         0.00%       6.000us       0.008us           771                                                                             [[1]]  \n",
            "                              aten::_local_scalar_dense         0.02%     663.000us        17.23%     458.142ms     594.218us       6.000us         0.00%       6.000us       0.008us           771                                                                             [[1]]  \n",
            "                                            aten::stack         0.01%     207.000us         2.14%      56.971ms      18.990ms       0.000us         0.00%       0.000us       0.000us             3                                                                          [[], []]  \n",
            "                                              aten::cat         2.13%      56.746ms         2.13%      56.746ms      18.915ms       0.000us         0.00%       0.000us       0.000us             3                                                                          [[], []]  \n",
            "                               Optimizer.step#Adam.step         0.99%      26.251ms         2.09%      55.680ms      18.560ms       0.000us         0.00%      24.290ms       8.097ms             3                                                                                []  \n",
            "                                            aten::clone         0.18%       4.663ms         1.92%      50.963ms     132.716us       0.000us         0.00%       0.000us       0.000us           384                                                               [[3, 224, 224], []]  \n",
            "                                            aten::copy_         1.90%      50.389ms         1.90%      50.389ms      87.481us       0.000us         0.00%       0.000us       0.000us           576                                                [[3, 224, 224], [3, 224, 224], []]  \n",
            "-------------------------------------------------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  --------------------------------------------------------------------------------  \n",
            "Self CPU time total: 2.658s\n",
            "Self CUDA time total: 714.885ms\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(prof.key_averages().table(sort_by=\"cuda_time_total\", row_limit=10))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YdEGlC6STkLP",
        "outputId": "5ce4f6fa-f350-4b31-d704-c4ed89c81dbd"
      },
      "execution_count": 48,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "-------------------------------------------------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  \n",
            "                                                   Name    Self CPU %      Self CPU   CPU total %     CPU total  CPU time avg     Self CUDA   Self CUDA %    CUDA total  CUDA time avg    # of Calls  \n",
            "-------------------------------------------------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  \n",
            "                                          ProfilerStep*         5.76%     153.105ms        96.30%        2.560s     853.294ms       0.000us         0.00%     288.596ms      96.199ms             3  \n",
            "autograd::engine::evaluate_function: ConvolutionBack...         0.11%       2.982ms         1.69%      44.947ms     282.686us       0.000us         0.00%     252.353ms       1.587ms           159  \n",
            "                                   ConvolutionBackward0         0.05%       1.446ms         1.53%      40.609ms     255.403us       0.000us         0.00%     227.881ms       1.433ms           159  \n",
            "                             aten::convolution_backward         0.74%      19.732ms         1.47%      39.163ms     246.308us     227.881ms        31.88%     227.881ms       1.433ms           159  \n",
            "                                           aten::conv2d         0.09%       2.476ms         1.92%      50.983ms     160.324us       0.000us         0.00%     220.215ms     692.500us           318  \n",
            "autograd::engine::evaluate_function: CudnnBatchNormB...         0.26%       6.815ms         0.86%      22.869ms     143.830us       0.000us         0.00%     110.539ms     695.214us           159  \n",
            "                                CudnnBatchNormBackward0         0.05%       1.407ms         0.60%      16.054ms     100.969us       0.000us         0.00%     110.539ms     695.214us           159  \n",
            "                        aten::cudnn_batch_norm_backward         0.28%       7.570ms         0.55%      14.647ms      92.119us     110.539ms        15.46%     110.539ms     695.214us           159  \n",
            "                                      aten::convolution         0.07%       1.896ms         0.73%      19.390ms     121.950us       0.000us         0.00%     109.082ms     686.050us           159  \n",
            "                                     aten::_convolution         0.05%       1.456ms         0.66%      17.494ms     110.025us       0.000us         0.00%     109.082ms     686.050us           159  \n",
            "-------------------------------------------------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  \n",
            "Self CPU time total: 2.658s\n",
            "Self CUDA time total: 714.885ms\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(prof.key_averages().table(sort_by=\"self_cpu_memory_usage\", row_limit=10))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rP-JwEMrTmsi",
        "outputId": "db8d824c-b3f7-44ba-ab40-f8bbdd95cf28"
      },
      "execution_count": 49,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "-------------------------------------------------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  \n",
            "                                                   Name    Self CPU %      Self CPU   CPU total %     CPU total  CPU time avg     Self CUDA   Self CUDA %    CUDA total  CUDA time avg    # of Calls  \n",
            "-------------------------------------------------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  \n",
            "at::native::amp_update_scale_cuda_kernel(float*, int...         0.00%       0.000us         0.00%       0.000us       0.000us      14.000us         0.00%      14.000us       3.500us             4  \n",
            "                                          ProfilerStep*         5.76%     153.105ms        96.30%        2.560s     853.294ms       0.000us         0.00%     288.596ms      96.199ms             3  \n",
            "enumerate(DataLoader)#_SingleProcessDataLoaderIter._...        60.29%        1.603s        67.52%        1.795s     598.301ms       0.000us         0.00%       0.000us       0.000us             3  \n",
            "                                            aten::empty         0.67%      17.713ms         0.67%      17.713ms       6.019us       0.000us         0.00%       0.000us       0.000us          2943  \n",
            "                                         aten::uniform_         0.11%       3.048ms         0.11%       3.048ms       7.938us       0.000us         0.00%       0.000us       0.000us           384  \n",
            "                                             aten::item         0.14%       3.768ms        17.38%     462.105ms     239.557us       0.000us         0.00%       6.000us       0.003us          1929  \n",
            "                              aten::_local_scalar_dense         0.03%     885.000us        17.24%     458.364ms     237.617us       6.000us         0.00%       6.000us       0.003us          1929  \n",
            "                                             aten::rand         0.09%       2.291ms         0.17%       4.566ms      23.781us       0.000us         0.00%       0.000us       0.000us           192  \n",
            "                                               aten::lt         0.10%       2.730ms         0.23%       6.064ms      31.583us       0.000us         0.00%       0.000us       0.000us           192  \n",
            "                                               aten::to         0.21%       5.450ms         2.60%      69.184ms      34.523us       0.000us         0.00%      31.053ms      15.496us          2004  \n",
            "-------------------------------------------------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  \n",
            "Self CPU time total: 2.658s\n",
            "Self CUDA time total: 714.885ms\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(prof.key_averages().table(sort_by=\"cpu_memory_usage\", row_limit=10))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XHkeq9EGTo9e",
        "outputId": "f7e04836-86d4-486f-9f4f-d6065ae23fd5"
      },
      "execution_count": 50,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "-------------------------------------------------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  \n",
            "                                                   Name    Self CPU %      Self CPU   CPU total %     CPU total  CPU time avg     Self CUDA   Self CUDA %    CUDA total  CUDA time avg    # of Calls  \n",
            "-------------------------------------------------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  \n",
            "at::native::amp_update_scale_cuda_kernel(float*, int...         0.00%       0.000us         0.00%       0.000us       0.000us      14.000us         0.00%      14.000us       3.500us             4  \n",
            "                                          ProfilerStep*         5.76%     153.105ms        96.30%        2.560s     853.294ms       0.000us         0.00%     288.596ms      96.199ms             3  \n",
            "enumerate(DataLoader)#_SingleProcessDataLoaderIter._...        60.29%        1.603s        67.52%        1.795s     598.301ms       0.000us         0.00%       0.000us       0.000us             3  \n",
            "                                            aten::empty         0.67%      17.713ms         0.67%      17.713ms       6.019us       0.000us         0.00%       0.000us       0.000us          2943  \n",
            "                                         aten::uniform_         0.11%       3.048ms         0.11%       3.048ms       7.938us       0.000us         0.00%       0.000us       0.000us           384  \n",
            "                                             aten::item         0.14%       3.768ms        17.38%     462.105ms     239.557us       0.000us         0.00%       6.000us       0.003us          1929  \n",
            "                              aten::_local_scalar_dense         0.03%     885.000us        17.24%     458.364ms     237.617us       6.000us         0.00%       6.000us       0.003us          1929  \n",
            "                                             aten::rand         0.09%       2.291ms         0.17%       4.566ms      23.781us       0.000us         0.00%       0.000us       0.000us           192  \n",
            "                                               aten::lt         0.10%       2.730ms         0.23%       6.064ms      31.583us       0.000us         0.00%       0.000us       0.000us           192  \n",
            "                                               aten::to         0.21%       5.450ms         2.60%      69.184ms      34.523us       0.000us         0.00%      31.053ms      15.496us          2004  \n",
            "-------------------------------------------------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  \n",
            "Self CPU time total: 2.658s\n",
            "Self CUDA time total: 714.885ms\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(prof.key_averages(group_by_stack_n=5).table(sort_by=\"self_cuda_time_total\", row_limit=2))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YU3PY2-4TrOs",
        "outputId": "fcc33dfa-0f9f-4f7e-efe6-e3ab46088b20"
      },
      "execution_count": 51,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "-------------------------------------------------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  \n",
            "                                                   Name    Self CPU %      Self CPU   CPU total %     CPU total  CPU time avg     Self CUDA   Self CUDA %    CUDA total  CUDA time avg    # of Calls  \n",
            "-------------------------------------------------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  \n",
            "                             aten::convolution_backward         0.74%      19.732ms         1.47%      39.163ms     246.308us     227.881ms        31.88%     227.881ms       1.433ms           159  \n",
            "                        aten::cudnn_batch_norm_backward         0.28%       7.570ms         0.55%      14.647ms      92.119us     110.539ms        15.46%     110.539ms     695.214us           159  \n",
            "-------------------------------------------------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  \n",
            "Self CPU time total: 2.658s\n",
            "Self CUDA time total: 714.885ms\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_2B5T1odTuuk",
        "outputId": "20154dca-ddf7-402e-d865-cfbafd1a7b18"
      },
      "execution_count": 52,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!mv /content/log /content/drive/MyDrive"
      ],
      "metadata": {
        "id": "tFM2ACVyUFrR",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4b81e417-88c1-4f0c-877d-b6e995ab6865"
      },
      "execution_count": 53,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "mv: inter-device move failed: '/content/log' to '/content/drive/MyDrive/log'; unable to remove target: Directory not empty\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "IfrXPibHUWQ-"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}