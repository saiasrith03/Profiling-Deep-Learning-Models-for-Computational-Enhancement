{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Bk7sN8VkI92B"
      },
      "outputs": [],
      "source": [
        "%matplotlib inline"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.optim\n",
        "import torch.profiler\n",
        "import torch.utils.data\n",
        "import torchvision.datasets\n",
        "import torchvision.models\n",
        "import torchvision.transforms as T\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "import torch.utils.data as data\n",
        "\n",
        "import torchvision.transforms as transforms\n",
        "import torchvision.datasets as datasets\n",
        "import torch.optim\n",
        "import torch.profiler\n",
        "\n",
        "from sklearn import metrics\n",
        "from sklearn import decomposition\n",
        "from sklearn import manifold\n",
        "from tqdm.notebook import trange, tqdm\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "\n",
        "import copy\n",
        "import random\n",
        "import time"
      ],
      "metadata": {
        "id": "hhb07nn6I--X"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pretrained_size = 224\n",
        "pretrained_means = [0.485, 0.456, 0.406]\n",
        "pretrained_stds = [0.229, 0.224, 0.225]\n",
        "\n",
        "train_transforms = transforms.Compose([\n",
        "                           transforms.Resize(pretrained_size),\n",
        "                           transforms.RandomRotation(5),\n",
        "                           transforms.RandomHorizontalFlip(0.5),\n",
        "                           transforms.RandomCrop(pretrained_size, padding=10),\n",
        "                           transforms.ToTensor(),\n",
        "                           transforms.Normalize(mean=pretrained_means,\n",
        "                                                std=pretrained_stds)\n",
        "                       ])\n",
        "\n",
        "test_transforms = transforms.Compose([\n",
        "                           transforms.Resize(pretrained_size),\n",
        "                           transforms.ToTensor(),\n",
        "                           transforms.Normalize(mean=pretrained_means,\n",
        "                                                std=pretrained_stds)\n",
        "                       ])"
      ],
      "metadata": {
        "id": "wgC-hBXsI-8Q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "ROOT = '.data'\n",
        "\n",
        "train_data = torchvision.datasets.CIFAR10(ROOT,\n",
        "                              train=True,\n",
        "                              download=True,\n",
        "                              transform=train_transforms)\n",
        "\n",
        "test_data = torchvision.datasets.CIFAR10(ROOT,\n",
        "                             train=False,\n",
        "                             download=True,\n",
        "                             transform=test_transforms)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PCcfeHZvotPM",
        "outputId": "90b8df27-38b7-4cad-fff0-0fcbb3a9f2d0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz to .data/cifar-10-python.tar.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 170498071/170498071 [00:04<00:00, 34571125.56it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting .data/cifar-10-python.tar.gz to .data\n",
            "Files already downloaded and verified\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_loader = torch.utils.data.DataLoader(train_data, batch_size=32, shuffle=True)\n",
        "test_loader = torch.utils.data.DataLoader(test_data, batch_size=32, shuffle=False)"
      ],
      "metadata": {
        "id": "FScOFdCAquN-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
      ],
      "metadata": {
        "id": "Icd24fCHI-1A"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class VGG(nn.Module):\n",
        "    def __init__(self, features, output_dim):\n",
        "        super().__init__()\n",
        "\n",
        "        self.features = features\n",
        "\n",
        "        self.avgpool = nn.AdaptiveAvgPool2d(7)\n",
        "\n",
        "        self.classifier = nn.Sequential(\n",
        "            nn.Linear(512 * 7 * 7, 4096),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.Dropout(0.5),\n",
        "            nn.Linear(4096, 4096),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.Dropout(0.5),\n",
        "            nn.Linear(4096, output_dim),\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.features(x)\n",
        "        x = self.avgpool(x)\n",
        "        h = x.view(x.shape[0], -1)\n",
        "        x = self.classifier(h)\n",
        "        return x, h"
      ],
      "metadata": {
        "id": "OhF1TjOEI-yI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "vgg11_config = [64, 'M', 128, 'M', 256, 256, 'M', 512, 512, 'M', 512, 512, 'M']\n",
        "\n",
        "vgg13_config = [64, 64, 'M', 128, 128, 'M', 256, 256, 'M', 512, 512, 'M', 512,\n",
        "                512, 'M']\n",
        "\n",
        "vgg16_config = [64, 64, 'M', 128, 128, 'M', 256, 256, 256, 'M', 512, 512, 512,\n",
        "                'M', 512, 512, 512, 'M']\n",
        "\n",
        "vgg19_config = [64, 64, 'M', 128, 128, 'M', 256, 256, 256, 256, 'M', 512, 512,\n",
        "                512, 512, 'M', 512, 512, 512, 512, 'M']"
      ],
      "metadata": {
        "id": "O09xbb1wpEZa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def get_vgg_layers(config, batch_norm):\n",
        "\n",
        "    layers = []\n",
        "    in_channels = 3\n",
        "\n",
        "    for c in config:\n",
        "        assert c == 'M' or isinstance(c, int)\n",
        "        if c == 'M':\n",
        "            layers += [nn.MaxPool2d(kernel_size=2)]\n",
        "        else:\n",
        "            conv2d = nn.Conv2d(in_channels, c, kernel_size=3, padding=1)\n",
        "            if batch_norm:\n",
        "                layers += [conv2d, nn.BatchNorm2d(c), nn.ReLU(inplace=True)]\n",
        "            else:\n",
        "                layers += [conv2d, nn.ReLU(inplace=True)]\n",
        "            in_channels = c\n",
        "\n",
        "    return nn.Sequential(*layers)"
      ],
      "metadata": {
        "id": "csuE2P3Opa_n"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "vgg11_layers = get_vgg_layers(vgg11_config, batch_norm=True)"
      ],
      "metadata": {
        "id": "OQp68MpDpryE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(vgg11_layers)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8RQgVgSbptpr",
        "outputId": "9107003b-75f9-4ae4-eac3-45a9b86958bc"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sequential(\n",
            "  (0): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "  (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "  (2): ReLU(inplace=True)\n",
            "  (3): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "  (4): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "  (5): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "  (6): ReLU(inplace=True)\n",
            "  (7): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "  (8): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "  (9): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "  (10): ReLU(inplace=True)\n",
            "  (11): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "  (12): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "  (13): ReLU(inplace=True)\n",
            "  (14): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "  (15): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "  (16): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "  (17): ReLU(inplace=True)\n",
            "  (18): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "  (19): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "  (20): ReLU(inplace=True)\n",
            "  (21): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "  (22): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "  (23): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "  (24): ReLU(inplace=True)\n",
            "  (25): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "  (26): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "  (27): ReLU(inplace=True)\n",
            "  (28): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            ")\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "OUTPUT_DIM = 10\n",
        "\n",
        "model = VGG(vgg11_layers, OUTPUT_DIM)\n",
        "\n",
        "print(model)"
      ],
      "metadata": {
        "id": "1RmdkR1vJJHL",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1ad38aeb-6bc9-4611-cd31-223235f01f5d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "VGG(\n",
            "  (features): Sequential(\n",
            "    (0): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (2): ReLU(inplace=True)\n",
            "    (3): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "    (4): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (5): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (6): ReLU(inplace=True)\n",
            "    (7): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "    (8): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (9): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (10): ReLU(inplace=True)\n",
            "    (11): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (12): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (13): ReLU(inplace=True)\n",
            "    (14): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "    (15): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (16): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (17): ReLU(inplace=True)\n",
            "    (18): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (19): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (20): ReLU(inplace=True)\n",
            "    (21): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "    (22): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (23): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (24): ReLU(inplace=True)\n",
            "    (25): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (26): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (27): ReLU(inplace=True)\n",
            "    (28): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "  )\n",
            "  (avgpool): AdaptiveAvgPool2d(output_size=7)\n",
            "  (classifier): Sequential(\n",
            "    (0): Linear(in_features=25088, out_features=4096, bias=True)\n",
            "    (1): ReLU(inplace=True)\n",
            "    (2): Dropout(p=0.5, inplace=False)\n",
            "    (3): Linear(in_features=4096, out_features=4096, bias=True)\n",
            "    (4): ReLU(inplace=True)\n",
            "    (5): Dropout(p=0.5, inplace=False)\n",
            "    (6): Linear(in_features=4096, out_features=10, bias=True)\n",
            "  )\n",
            ")\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torchvision.models as models\n",
        "\n",
        "pretrained_model = models.vgg11_bn(pretrained=True)\n",
        "\n",
        "print(pretrained_model)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dW2_4uhnp-ox",
        "outputId": "4bc91529-cab9-49ba-fb20-fc48b7414934"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=VGG11_BN_Weights.IMAGENET1K_V1`. You can also use `weights=VGG11_BN_Weights.DEFAULT` to get the most up-to-date weights.\n",
            "  warnings.warn(msg)\n",
            "Downloading: \"https://download.pytorch.org/models/vgg11_bn-6002323d.pth\" to /root/.cache/torch/hub/checkpoints/vgg11_bn-6002323d.pth\n",
            "100%|██████████| 507M/507M [00:02<00:00, 258MB/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "VGG(\n",
            "  (features): Sequential(\n",
            "    (0): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (2): ReLU(inplace=True)\n",
            "    (3): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "    (4): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (5): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (6): ReLU(inplace=True)\n",
            "    (7): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "    (8): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (9): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (10): ReLU(inplace=True)\n",
            "    (11): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (12): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (13): ReLU(inplace=True)\n",
            "    (14): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "    (15): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (16): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (17): ReLU(inplace=True)\n",
            "    (18): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (19): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (20): ReLU(inplace=True)\n",
            "    (21): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "    (22): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (23): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (24): ReLU(inplace=True)\n",
            "    (25): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (26): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (27): ReLU(inplace=True)\n",
            "    (28): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "  )\n",
            "  (avgpool): AdaptiveAvgPool2d(output_size=(7, 7))\n",
            "  (classifier): Sequential(\n",
            "    (0): Linear(in_features=25088, out_features=4096, bias=True)\n",
            "    (1): ReLU(inplace=True)\n",
            "    (2): Dropout(p=0.5, inplace=False)\n",
            "    (3): Linear(in_features=4096, out_features=4096, bias=True)\n",
            "    (4): ReLU(inplace=True)\n",
            "    (5): Dropout(p=0.5, inplace=False)\n",
            "    (6): Linear(in_features=4096, out_features=1000, bias=True)\n",
            "  )\n",
            ")\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pretrained_model.classifier[-1]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kLp_FLh8qB2J",
        "outputId": "2c7e9868-8bf1-458e-d6b5-f59c6c070ee4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Linear(in_features=4096, out_features=1000, bias=True)"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "IN_FEATURES = pretrained_model.classifier[-1].in_features\n",
        "\n",
        "final_fc = nn.Linear(IN_FEATURES, OUTPUT_DIM)"
      ],
      "metadata": {
        "id": "j-OO_wFbqF6x"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pretrained_model.classifier[-1] = final_fc"
      ],
      "metadata": {
        "id": "i9jO3EkGqItO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(pretrained_model.classifier)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "g6c--W6lqIXQ",
        "outputId": "4f076201-74a2-451d-c0dd-a32bba206425"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sequential(\n",
            "  (0): Linear(in_features=25088, out_features=4096, bias=True)\n",
            "  (1): ReLU(inplace=True)\n",
            "  (2): Dropout(p=0.5, inplace=False)\n",
            "  (3): Linear(in_features=4096, out_features=4096, bias=True)\n",
            "  (4): ReLU(inplace=True)\n",
            "  (5): Dropout(p=0.5, inplace=False)\n",
            "  (6): Linear(in_features=4096, out_features=10, bias=True)\n",
            ")\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.load_state_dict(pretrained_model.state_dict())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "B52wALfSqNcf",
        "outputId": "58c7a358-ac6e-416c-d3fd-e7d9022b5d35"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<All keys matched successfully>"
            ]
          },
          "metadata": {},
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "optimizer = optim.Adam(model.parameters())\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "model = model.to(device)\n",
        "criterion = criterion.to(device)"
      ],
      "metadata": {
        "id": "wgPrmWthJKsY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Profiling"
      ],
      "metadata": {
        "id": "sJ27GdzZQvKs"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model.train()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Sh9upIVcJMGh",
        "outputId": "becf848c-f43d-4e9e-fd63-19380d6a6c5e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "VGG(\n",
              "  (features): Sequential(\n",
              "    (0): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "    (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    (2): ReLU(inplace=True)\n",
              "    (3): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
              "    (4): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "    (5): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    (6): ReLU(inplace=True)\n",
              "    (7): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
              "    (8): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "    (9): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    (10): ReLU(inplace=True)\n",
              "    (11): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "    (12): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    (13): ReLU(inplace=True)\n",
              "    (14): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
              "    (15): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "    (16): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    (17): ReLU(inplace=True)\n",
              "    (18): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "    (19): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    (20): ReLU(inplace=True)\n",
              "    (21): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
              "    (22): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "    (23): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    (24): ReLU(inplace=True)\n",
              "    (25): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "    (26): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    (27): ReLU(inplace=True)\n",
              "    (28): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
              "  )\n",
              "  (avgpool): AdaptiveAvgPool2d(output_size=7)\n",
              "  (classifier): Sequential(\n",
              "    (0): Linear(in_features=25088, out_features=4096, bias=True)\n",
              "    (1): ReLU(inplace=True)\n",
              "    (2): Dropout(p=0.5, inplace=False)\n",
              "    (3): Linear(in_features=4096, out_features=4096, bias=True)\n",
              "    (4): ReLU(inplace=True)\n",
              "    (5): Dropout(p=0.5, inplace=False)\n",
              "    (6): Linear(in_features=4096, out_features=10, bias=True)\n",
              "  )\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def train(data):\n",
        "    #print(data)\n",
        "    inputs, labels = data[0].to(device=device), data[1].to(device=device)\n",
        "    outputs,_ = model(inputs)\n",
        "    loss = criterion(outputs, labels)\n",
        "    optimizer.zero_grad()\n",
        "    loss.backward()\n",
        "    optimizer.step()"
      ],
      "metadata": {
        "id": "bYCI8p9EJNyo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "prof = torch.profiler.profile(\n",
        "        schedule=torch.profiler.schedule(wait=1, warmup=1, active=3, repeat=2),\n",
        "        on_trace_ready=torch.profiler.tensorboard_trace_handler('./log/vgg'),\n",
        "        record_shapes=True,\n",
        "        with_stack=True)\n",
        "prof.start()\n",
        "for step, batch_data in enumerate(train_loader):\n",
        "    if step >= (1 + 1 + 3) * 2:\n",
        "        break\n",
        "    train(batch_data)\n",
        "    prof.step()\n",
        "prof.stop()"
      ],
      "metadata": {
        "id": "REm5F7BbJPQc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(prof.key_averages())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Lkea-OeNJRHv",
        "outputId": "16136421-79ef-44f2-8245-148c41792992"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "-------------------------------------------------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  \n",
            "                                                   Name    Self CPU %      Self CPU   CPU total %     CPU total  CPU time avg     Self CUDA   Self CUDA %    CUDA total  CUDA time avg    # of Calls  \n",
            "-------------------------------------------------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  \n",
            "                                          ProfilerStep*         1.67%      19.090ms        75.54%     863.461ms     287.820ms       0.000us         0.00%     473.907ms     157.969ms             3  \n",
            "enumerate(DataLoader)#_SingleProcessDataLoaderIter._...        12.39%     141.622ms        18.11%     207.015ms      69.005ms       0.000us         0.00%       0.000us       0.000us             3  \n",
            "                                            aten::empty         0.26%       2.959ms         0.26%       2.959ms       3.161us       0.000us         0.00%       0.000us       0.000us           936  \n",
            "                                         aten::uniform_         0.10%       1.148ms         0.10%       1.148ms       5.979us       0.000us         0.00%       0.000us       0.000us           192  \n",
            "                                             aten::item         0.07%     807.000us         0.09%     973.000us       1.374us       0.000us         0.00%       0.000us       0.000us           708  \n",
            "                              aten::_local_scalar_dense         0.02%     231.000us         0.02%     231.000us       0.326us       0.000us         0.00%       0.000us       0.000us           708  \n",
            "                                             aten::rand         0.05%     608.000us         0.11%       1.272ms      13.250us       0.000us         0.00%       0.000us       0.000us            96  \n",
            "                                               aten::lt         0.09%     976.000us         0.19%       2.227ms      23.198us       0.000us         0.00%       0.000us       0.000us            96  \n",
            "                                               aten::to         0.11%       1.211ms        54.85%     626.994ms     893.154us       0.000us         0.00%      13.076ms      18.627us           702  \n",
            "                                         aten::_to_copy         0.23%       2.585ms        54.77%     626.051ms       1.242ms       0.000us         0.00%      13.076ms      25.944us           504  \n",
            "                                    aten::empty_strided         0.19%       2.129ms         0.19%       2.129ms       2.526us       0.000us         0.00%       0.000us       0.000us           843  \n",
            "                                            aten::copy_         1.92%      21.914ms        55.87%     638.564ms     917.477us      13.076ms         1.16%      13.076ms      18.787us           696  \n",
            "                                       aten::is_nonzero         0.03%     326.000us         0.06%     686.000us       3.573us       0.000us         0.00%       0.000us       0.000us           192  \n",
            "                                          aten::randint         0.08%     888.000us         0.13%       1.526ms       7.948us       0.000us         0.00%       0.000us       0.000us           192  \n",
            "                                          aten::random_         0.04%     405.000us         0.04%     405.000us       2.109us       0.000us         0.00%       0.000us       0.000us           192  \n",
            "                                       aten::lift_fresh         0.02%     175.000us         0.02%     175.000us       0.601us       0.000us         0.00%       0.000us       0.000us           291  \n",
            "                                             aten::view         0.09%       1.023ms         0.09%       1.023ms       2.915us       0.000us         0.00%       0.000us       0.000us           351  \n",
            "void at::native::vectorized_elementwise_kernel<4, at...         0.00%       0.000us         0.00%       0.000us       0.000us      31.761ms         2.82%      31.761ms     794.025us            40  \n",
            "                                          aten::permute         0.06%     667.000us         0.07%     811.000us       8.448us       0.000us         0.00%       0.000us       0.000us            96  \n",
            "                                       aten::as_strided         0.03%     315.000us         0.03%     315.000us       1.207us       0.000us         0.00%       0.000us       0.000us           261  \n",
            "                                       aten::contiguous         0.10%       1.109ms         0.81%       9.281ms      96.677us       0.000us         0.00%       0.000us       0.000us            96  \n",
            "                                            aten::clone         0.11%       1.305ms         1.57%      17.948ms      93.479us       0.000us         0.00%       0.000us       0.000us           192  \n",
            "                                       aten::empty_like         0.05%     519.000us         0.10%       1.159ms       8.049us       0.000us         0.00%       0.000us       0.000us           144  \n",
            "                                              aten::div         0.77%       8.805ms         0.84%       9.592ms      99.917us       0.000us         0.00%       0.000us       0.000us            96  \n",
            "                                               aten::eq         0.08%     926.000us         0.17%       1.949ms      20.302us       0.000us         0.00%       0.000us       0.000us            96  \n",
            "                                              aten::any         0.09%       1.026ms         0.10%       1.125ms      11.719us       0.000us         0.00%       0.000us       0.000us            96  \n",
            "                                            aten::fill_         0.02%     201.000us         0.04%     423.000us       3.525us      10.075ms         0.89%      10.075ms      83.958us           120  \n",
            "                                             aten::sub_         0.36%       4.093ms         0.36%       4.093ms      42.635us       0.000us         0.00%       0.000us       0.000us            96  \n",
            "                                             aten::div_         0.32%       3.655ms         0.32%       3.655ms      38.073us       0.000us         0.00%       0.000us       0.000us            96  \n",
            "void at::native::(anonymous namespace)::max_pool_for...         0.00%       0.000us         0.00%       0.000us       0.000us      22.983ms         2.04%      22.983ms       1.149ms            20  \n",
            "void cudnn::winograd_nonfused::winogradForwardData4x...         0.00%       0.000us         0.00%       0.000us       0.000us      61.956ms         5.50%      61.956ms       1.106ms            56  \n",
            "void cudnn::winograd_nonfused::winogradForwardFilter...         0.00%       0.000us         0.00%       0.000us       0.000us       7.695ms         0.68%       7.695ms     137.411us            56  \n",
            "                                  volta_sgemm_128x64_nn         0.00%       0.000us         0.00%       0.000us       0.000us     101.989ms         9.06%     101.989ms       3.642ms            28  \n",
            "void cudnn::winograd_nonfused::winogradForwardOutput...         0.00%       0.000us         0.00%       0.000us       0.000us      53.157ms         4.72%      53.157ms     949.232us            56  \n",
            "void at::native::elementwise_kernel<128, 2, at::nati...         0.00%       0.000us         0.00%       0.000us       0.000us      28.252ms         2.51%      28.252ms     911.355us            31  \n",
            "void at::native::vectorized_elementwise_kernel<4, at...         0.00%       0.000us         0.00%       0.000us       0.000us     101.000us         0.01%     101.000us       3.258us            31  \n",
            "void cudnn::bn_fw_tr_1C11_kernel_NCHW<float, float, ...         0.00%       0.000us         0.00%       0.000us       0.000us      30.636ms         2.72%      30.636ms       4.377ms             7  \n",
            "void cudnn::bn_fw_tr_1C11_kernel_NCHW<float, float, ...         0.00%       0.000us         0.00%       0.000us       0.000us      11.735ms         1.04%      11.735ms       1.467ms             8  \n",
            "void cudnn::bn_fw_tr_1C11_kernel_NCHW<float, float, ...         0.00%       0.000us         0.00%       0.000us       0.000us       5.497ms         0.49%       5.497ms     687.125us             8  \n",
            "void cudnn::bn_fw_tr_1C11_singleread<float, 512, tru...         0.00%       0.000us         0.00%       0.000us       0.000us       1.232ms         0.11%       1.232ms     154.000us             8  \n",
            "void at::native::(anonymous namespace)::adaptive_ave...         0.00%       0.000us         0.00%       0.000us       0.000us       1.401ms         0.12%       1.401ms     350.250us             4  \n",
            "                                        Memset (Device)         0.00%       0.000us         0.00%       0.000us       0.000us      20.000us         0.00%      20.000us       1.667us            12  \n",
            "                        volta_sgemm_128x32_sliced1x4_tn         0.00%       0.000us         0.00%       0.000us       0.000us      11.287ms         1.00%      11.287ms       1.411ms             8  \n",
            "                                            aten::stack         0.01%      92.000us         0.82%       9.418ms       3.139ms       0.000us         0.00%       0.000us       0.000us             3  \n",
            "                                              aten::cat         0.82%       9.316ms         0.82%       9.316ms       3.105ms       0.000us         0.00%       0.000us       0.000us             3  \n",
            "void at::native::(anonymous namespace)::fused_dropou...         0.00%       0.000us         0.00%       0.000us       0.000us      51.000us         0.00%      51.000us       6.375us             8  \n",
            "                         volta_sgemm_32x32_sliced1x4_tn         0.00%       0.000us         0.00%       0.000us       0.000us      56.000us         0.00%      56.000us      14.000us             4  \n",
            "void splitKreduce_kernel<32, 16, int, float, float, ...         0.00%       0.000us         0.00%       0.000us       0.000us      20.000us         0.00%      20.000us       5.000us             4  \n",
            "void (anonymous namespace)::softmax_warp_forward<flo...         0.00%       0.000us         0.00%       0.000us       0.000us      12.000us         0.00%      12.000us       3.000us             4  \n",
            "void at::native::(anonymous namespace)::nll_loss_for...         0.00%       0.000us         0.00%       0.000us       0.000us      15.000us         0.00%      15.000us       3.750us             4  \n",
            "void at::native::vectorized_elementwise_kernel<4, at...         0.00%       0.000us         0.00%       0.000us       0.000us      13.434ms         1.19%      13.434ms     419.812us            32  \n",
            "void at::native::(anonymous namespace)::nll_loss_bac...         0.00%       0.000us         0.00%       0.000us       0.000us      14.000us         0.00%      14.000us       3.500us             4  \n",
            "void (anonymous namespace)::softmax_warp_backward<fl...         0.00%       0.000us         0.00%       0.000us       0.000us      12.000us         0.00%      12.000us       3.000us             4  \n",
            "                                  volta_sgemm_128x32_nn         0.00%       0.000us         0.00%       0.000us       0.000us      33.000us         0.00%      33.000us       8.250us             4  \n",
            "                                  volta_sgemm_128x32_nt         0.00%       0.000us         0.00%       0.000us       0.000us      36.000us         0.00%      36.000us       9.000us             4  \n",
            "void at::native::reduce_kernel<256, 2, at::native::R...         0.00%       0.000us         0.00%       0.000us       0.000us      32.000us         0.00%      32.000us       8.000us             4  \n",
            "void at::native::vectorized_elementwise_kernel<4, at...         0.00%       0.000us         0.00%       0.000us       0.000us      42.000us         0.00%      42.000us       5.250us             8  \n",
            "void at::native::vectorized_elementwise_kernel<4, at...         0.00%       0.000us         0.00%       0.000us       0.000us      45.548ms         4.04%      45.548ms       1.139ms            40  \n",
            "                        volta_sgemm_128x32_sliced1x4_nn         0.00%       0.000us         0.00%       0.000us       0.000us       8.099ms         0.72%       8.099ms       1.012ms             8  \n",
            "                                  volta_sgemm_128x64_nt         0.00%       0.000us         0.00%       0.000us       0.000us     184.778ms        16.41%     184.778ms       3.553ms            52  \n",
            "void at::native::reduce_kernel<128, 4, at::native::R...         0.00%       0.000us         0.00%       0.000us       0.000us     108.000us         0.01%     108.000us      13.500us             8  \n",
            "                                 volta_sgemm_128x128_nt         0.00%       0.000us         0.00%       0.000us       0.000us       8.125ms         0.72%       8.125ms       2.031ms             4  \n",
            "                                          aten::detach_         0.00%      11.000us         0.00%      14.000us       4.667us       0.000us         0.00%       0.000us       0.000us             3  \n",
            "                                                detach_         0.00%       3.000us         0.00%       3.000us       1.000us       0.000us         0.00%       0.000us       0.000us             3  \n",
            "                                        cudaMemcpyAsync        53.94%     616.563ms        53.94%     616.563ms     102.760ms       0.000us         0.00%       0.000us       0.000us             6  \n",
            "void at::native::(anonymous namespace)::atomic_adapt...         0.00%       0.000us         0.00%       0.000us       0.000us       1.101ms         0.10%       1.101ms     275.250us             4  \n",
            "void at::native::(anonymous namespace)::max_pool_bac...         0.00%       0.000us         0.00%       0.000us       0.000us      65.074ms         5.78%      65.074ms       3.254ms            20  \n",
            "void cudnn::bn_bw_1C11_kernel_new<float, float, floa...         0.00%       0.000us         0.00%       0.000us       0.000us      11.327ms         1.01%      11.327ms     707.938us            16  \n",
            "void cudnn::winograd_nonfused::winogradWgradData4x4<...         0.00%       0.000us         0.00%       0.000us       0.000us      25.427ms         2.26%      25.427ms     908.107us            28  \n",
            "void cudnn::winograd_nonfused::winogradWgradDelta4x4...         0.00%       0.000us         0.00%       0.000us       0.000us      41.713ms         3.70%      41.713ms       1.490ms            28  \n",
            "void cudnn::winograd_nonfused::winogradWgradOutput4x...         0.00%       0.000us         0.00%       0.000us       0.000us       5.726ms         0.51%       5.726ms     204.500us            28  \n",
            "void at::native::reduce_kernel<512, 1, at::native::R...         0.00%       0.000us         0.00%       0.000us       0.000us      15.726ms         1.40%      15.726ms     491.438us            32  \n",
            "void cudnn::bn_bw_1C11_kernel_new<float, float, floa...         0.00%       0.000us         0.00%       0.000us       0.000us      19.241ms         1.71%      19.241ms       2.405ms             8  \n",
            "                                   volta_sgemm_64x64_nt         0.00%       0.000us         0.00%       0.000us       0.000us      39.498ms         3.51%      39.498ms       4.937ms             8  \n",
            "void cudnn::bn_bw_1C11_kernel_new<float, float, floa...         0.00%       0.000us         0.00%       0.000us       0.000us      60.996ms         5.42%      60.996ms       7.625ms             8  \n",
            "void wgrad_alg0_engine<float, 128, 5, 5, 3, 3, 3, fa...         0.00%       0.000us         0.00%       0.000us       0.000us      16.414ms         1.46%      16.414ms       4.104ms             4  \n",
            "void at::native::(anonymous namespace)::multi_tensor...         0.00%       0.000us         0.00%       0.000us       0.000us      35.601ms         3.16%      35.601ms     635.732us            56  \n",
            "void at::native::(anonymous namespace)::multi_tensor...         0.00%       0.000us         0.00%       0.000us       0.000us      25.405ms         2.26%      25.405ms     907.321us            28  \n",
            "void at::native::(anonymous namespace)::multi_tensor...         0.00%       0.000us         0.00%       0.000us       0.000us      25.430ms         2.26%      25.430ms     908.214us            28  \n",
            "void at::native::(anonymous namespace)::multi_tensor...         0.00%       0.000us         0.00%       0.000us       0.000us      18.021ms         1.60%      18.021ms     643.607us            28  \n",
            "void at::native::(anonymous namespace)::multi_tensor...         0.00%       0.000us         0.00%       0.000us       0.000us      18.038ms         1.60%      18.038ms     644.214us            28  \n",
            "void at::native::(anonymous namespace)::multi_tensor...         0.00%       0.000us         0.00%       0.000us       0.000us      17.937ms         1.59%      17.937ms     640.607us            28  \n",
            "void at::native::(anonymous namespace)::multi_tensor...         0.00%       0.000us         0.00%       0.000us       0.000us      33.271ms         2.95%      33.271ms       1.188ms            28  \n",
            "                       Memcpy HtoD (Pageable -> Device)         0.00%       0.000us         0.00%       0.000us       0.000us      13.076ms         1.16%      13.076ms       2.179ms             6  \n",
            "                                  cudaStreamSynchronize         0.01%      87.000us         0.01%      87.000us      14.500us       0.000us         0.00%       0.000us       0.000us             6  \n",
            "                                           aten::conv2d         0.01%     111.000us         0.33%       3.826ms     159.417us       0.000us         0.00%     184.746ms       7.698ms            24  \n",
            "                                      aten::convolution         0.03%     327.000us         0.33%       3.715ms     154.792us       0.000us         0.00%     184.746ms       7.698ms            24  \n",
            "                                     aten::_convolution         0.03%     354.000us         0.30%       3.388ms     141.167us       0.000us         0.00%     184.746ms       7.698ms            24  \n",
            "                                aten::cudnn_convolution         0.15%       1.692ms         0.20%       2.320ms      96.667us     132.730ms        11.79%     161.001ms       6.708ms            24  \n",
            "                                  cudaStreamIsCapturing         0.00%      27.000us         0.00%      27.000us       0.214us      14.895ms         1.32%      14.895ms     118.214us           126  \n",
            "                                  cudaStreamGetPriority         0.00%       4.000us         0.00%       4.000us       0.034us      16.809ms         1.49%      16.809ms     143.667us           117  \n",
            "                       cudaDeviceGetStreamPriorityRange         0.00%       0.000us         0.00%       0.000us       0.000us     234.000us         0.02%     234.000us       2.000us           117  \n",
            "                                       cudaLaunchKernel         0.43%       4.957ms         0.43%       4.957ms       6.772us      77.185ms         6.85%      77.185ms     105.444us           732  \n",
            "void cask_cudnn::computeOffsetsKernel<false, false>(...         0.00%       0.000us         0.00%       0.000us       0.000us      12.000us         0.00%      12.000us       4.000us             3  \n",
            "                                        cudaMemsetAsync         0.01%     145.000us         0.01%     145.000us      12.083us       0.000us         0.00%       0.000us       0.000us            12  \n",
            "            cudnn_volta_scudnn_128x64_relu_medium_nn_v1         0.00%       0.000us         0.00%       0.000us       0.000us       6.919ms         0.61%       6.919ms       2.306ms             3  \n",
            "                                          aten::reshape         0.01%     164.000us         0.02%     211.000us       7.815us       0.000us         0.00%       0.000us       0.000us            27  \n",
            "                                   aten::_reshape_alias         0.00%      49.000us         0.00%      49.000us       1.815us       0.000us         0.00%       0.000us       0.000us            27  \n",
            "                                             aten::add_         0.10%       1.122ms         0.18%       2.052ms      12.071us      23.825ms         2.12%      26.810ms     157.706us           170  \n",
            "                                       aten::batch_norm         0.04%     406.000us         0.21%       2.415ms     100.625us       0.000us         0.00%      48.256ms       2.011ms            24  \n",
            "-------------------------------------------------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  \n",
            "Self CPU time total: 1.143s\n",
            "Self CUDA time total: 1.126s\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(prof.key_averages().table(sort_by=\"cpu_time_total\", row_limit=10))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "f1tpbBjuJbtw",
        "outputId": "c71efe4a-dd48-4907-826c-469704c889e6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "-------------------------------------------------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  \n",
            "                                                   Name    Self CPU %      Self CPU   CPU total %     CPU total  CPU time avg     Self CUDA   Self CUDA %    CUDA total  CUDA time avg    # of Calls  \n",
            "-------------------------------------------------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  \n",
            "                                          ProfilerStep*         1.67%      19.090ms        75.54%     863.461ms     287.820ms       0.000us         0.00%     473.907ms     157.969ms             3  \n",
            "                                            aten::copy_         1.92%      21.914ms        55.87%     638.564ms     917.477us      13.076ms         1.16%      13.076ms      18.787us           696  \n",
            "                                               aten::to         0.11%       1.211ms        54.85%     626.994ms     893.154us       0.000us         0.00%      13.076ms      18.627us           702  \n",
            "                                         aten::_to_copy         0.23%       2.585ms        54.77%     626.051ms       1.242ms       0.000us         0.00%      13.076ms      25.944us           504  \n",
            "                                        cudaMemcpyAsync        53.94%     616.563ms        53.94%     616.563ms     102.760ms       0.000us         0.00%       0.000us       0.000us             6  \n",
            "                                  cudaDeviceSynchronize        23.43%     267.814ms        23.43%     267.814ms     267.814ms       0.000us         0.00%       0.000us       0.000us             1  \n",
            "enumerate(DataLoader)#_SingleProcessDataLoaderIter._...        12.39%     141.622ms        18.11%     207.015ms      69.005ms       0.000us         0.00%       0.000us       0.000us             3  \n",
            "                                            aten::clone         0.11%       1.305ms         1.57%      17.948ms      93.479us       0.000us         0.00%       0.000us       0.000us           192  \n",
            "                                              aten::div         0.77%       8.805ms         0.84%       9.592ms      99.917us       0.000us         0.00%       0.000us       0.000us            96  \n",
            "                                            aten::stack         0.01%      92.000us         0.82%       9.418ms       3.139ms       0.000us         0.00%       0.000us       0.000us             3  \n",
            "-------------------------------------------------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  \n",
            "Self CPU time total: 1.143s\n",
            "Self CUDA time total: 1.126s\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(prof.key_averages(group_by_input_shape=True).table(sort_by=\"cpu_time_total\", row_limit=10))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eG-JUCXGJe2b",
        "outputId": "f155814a-1ee7-4e21-a1df-4299fb923411"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "-------------------------------------------------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  --------------------------------------------------------------------------------  \n",
            "                                                   Name    Self CPU %      Self CPU   CPU total %     CPU total  CPU time avg     Self CUDA   Self CUDA %    CUDA total  CUDA time avg    # of Calls                                                                      Input Shapes  \n",
            "-------------------------------------------------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  --------------------------------------------------------------------------------  \n",
            "                                          ProfilerStep*         1.67%      19.090ms        75.54%     863.461ms     287.820ms       0.000us         0.00%     473.907ms     157.969ms             3                                                                                []  \n",
            "                                               aten::to         0.01%      73.000us        53.97%     616.844ms     205.615ms       0.000us         0.00%      13.073ms       4.358ms             3                                   [[32, 3, 224, 224], [], [], [], [], [], [], []]  \n",
            "                                         aten::_to_copy         0.00%      53.000us        53.96%     616.771ms     205.590ms       0.000us         0.00%      13.073ms       4.358ms             3                                       [[32, 3, 224, 224], [], [], [], [], [], []]  \n",
            "                                            aten::copy_         0.01%     116.000us        53.95%     616.662ms     205.554ms      13.073ms         1.16%      13.073ms       4.358ms             3                                        [[32, 3, 224, 224], [32, 3, 224, 224], []]  \n",
            "                                        cudaMemcpyAsync        53.94%     616.563ms        53.94%     616.563ms     102.760ms       0.000us         0.00%       0.000us       0.000us             6                                                                                []  \n",
            "                                  cudaDeviceSynchronize        23.43%     267.814ms        23.43%     267.814ms     267.814ms       0.000us         0.00%       0.000us       0.000us             1                                                                                []  \n",
            "enumerate(DataLoader)#_SingleProcessDataLoaderIter._...        12.39%     141.622ms        18.11%     207.015ms      69.005ms       0.000us         0.00%       0.000us       0.000us             3                                                                                []  \n",
            "                                            aten::copy_         1.84%      21.066ms         1.84%      21.066ms      73.146us       0.000us         0.00%       0.000us       0.000us           288                                                [[3, 224, 224], [3, 224, 224], []]  \n",
            "                                            aten::clone         0.11%       1.305ms         1.57%      17.948ms      93.479us       0.000us         0.00%       0.000us       0.000us           192                                                               [[3, 224, 224], []]  \n",
            "                                              aten::div         0.77%       8.805ms         0.84%       9.592ms      99.917us       0.000us         0.00%       0.000us       0.000us            96                                                               [[3, 224, 224], []]  \n",
            "-------------------------------------------------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  --------------------------------------------------------------------------------  \n",
            "Self CPU time total: 1.143s\n",
            "Self CUDA time total: 1.126s\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(prof.key_averages().table(sort_by=\"cuda_time_total\", row_limit=10))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EYs1AetHJhUr",
        "outputId": "c380d31b-bb83-45c4-b886-f4a61d6ffb3f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "-------------------------------------------------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  \n",
            "                                                   Name    Self CPU %      Self CPU   CPU total %     CPU total  CPU time avg     Self CUDA   Self CUDA %    CUDA total  CUDA time avg    # of Calls  \n",
            "-------------------------------------------------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  \n",
            "                                          ProfilerStep*         1.67%      19.090ms        75.54%     863.461ms     287.820ms       0.000us         0.00%     473.907ms     157.969ms             3  \n",
            "autograd::engine::evaluate_function: ConvolutionBack...         0.02%     268.000us         0.42%       4.753ms     198.042us       0.000us         0.00%     319.341ms      13.306ms            24  \n",
            "                                   ConvolutionBackward0         0.01%     147.000us         0.39%       4.485ms     186.875us       0.000us         0.00%     319.341ms      13.306ms            24  \n",
            "                             aten::convolution_backward         0.21%       2.345ms         0.38%       4.338ms     180.750us     282.811ms        25.11%     319.341ms      13.306ms            24  \n",
            "                                  volta_sgemm_128x64_nt         0.00%       0.000us         0.00%       0.000us       0.000us     184.778ms        16.41%     184.778ms       3.553ms            52  \n",
            "                                           aten::conv2d         0.01%     111.000us         0.33%       3.826ms     159.417us       0.000us         0.00%     184.746ms       7.698ms            24  \n",
            "                                      aten::convolution         0.03%     327.000us         0.33%       3.715ms     154.792us       0.000us         0.00%     184.746ms       7.698ms            24  \n",
            "                                     aten::_convolution         0.03%     354.000us         0.30%       3.388ms     141.167us       0.000us         0.00%     184.746ms       7.698ms            24  \n",
            "                                aten::cudnn_convolution         0.15%       1.692ms         0.20%       2.320ms      96.667us     132.730ms        11.79%     161.001ms       6.708ms            24  \n",
            "                               Optimizer.step#Adam.step         0.35%       4.041ms         0.79%       9.018ms       3.006ms       0.000us         0.00%     153.879ms      51.293ms             3  \n",
            "-------------------------------------------------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  \n",
            "Self CPU time total: 1.143s\n",
            "Self CUDA time total: 1.126s\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(prof.key_averages().table(sort_by=\"self_cpu_memory_usage\", row_limit=10))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BUlle4EGJjTX",
        "outputId": "ee0f0987-c2cb-48ad-edc8-ac6190d46a71"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "-------------------------------------------------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  \n",
            "                                                   Name    Self CPU %      Self CPU   CPU total %     CPU total  CPU time avg     Self CUDA   Self CUDA %    CUDA total  CUDA time avg    # of Calls  \n",
            "-------------------------------------------------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  \n",
            "                                          ProfilerStep*         1.67%      19.090ms        75.54%     863.461ms     287.820ms       0.000us         0.00%     473.907ms     157.969ms             3  \n",
            "enumerate(DataLoader)#_SingleProcessDataLoaderIter._...        12.39%     141.622ms        18.11%     207.015ms      69.005ms       0.000us         0.00%       0.000us       0.000us             3  \n",
            "                                            aten::empty         0.26%       2.959ms         0.26%       2.959ms       3.161us       0.000us         0.00%       0.000us       0.000us           936  \n",
            "                                         aten::uniform_         0.10%       1.148ms         0.10%       1.148ms       5.979us       0.000us         0.00%       0.000us       0.000us           192  \n",
            "                                             aten::item         0.07%     807.000us         0.09%     973.000us       1.374us       0.000us         0.00%       0.000us       0.000us           708  \n",
            "                              aten::_local_scalar_dense         0.02%     231.000us         0.02%     231.000us       0.326us       0.000us         0.00%       0.000us       0.000us           708  \n",
            "                                             aten::rand         0.05%     608.000us         0.11%       1.272ms      13.250us       0.000us         0.00%       0.000us       0.000us            96  \n",
            "                                               aten::lt         0.09%     976.000us         0.19%       2.227ms      23.198us       0.000us         0.00%       0.000us       0.000us            96  \n",
            "                                               aten::to         0.11%       1.211ms        54.85%     626.994ms     893.154us       0.000us         0.00%      13.076ms      18.627us           702  \n",
            "                                         aten::_to_copy         0.23%       2.585ms        54.77%     626.051ms       1.242ms       0.000us         0.00%      13.076ms      25.944us           504  \n",
            "-------------------------------------------------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  \n",
            "Self CPU time total: 1.143s\n",
            "Self CUDA time total: 1.126s\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(prof.key_averages().table(sort_by=\"cpu_memory_usage\", row_limit=10))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wY7jCw1jJlS-",
        "outputId": "25f5ed93-ceb3-4038-c504-80d783cec813"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "-------------------------------------------------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  \n",
            "                                                   Name    Self CPU %      Self CPU   CPU total %     CPU total  CPU time avg     Self CUDA   Self CUDA %    CUDA total  CUDA time avg    # of Calls  \n",
            "-------------------------------------------------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  \n",
            "                                          ProfilerStep*         1.67%      19.090ms        75.54%     863.461ms     287.820ms       0.000us         0.00%     473.907ms     157.969ms             3  \n",
            "enumerate(DataLoader)#_SingleProcessDataLoaderIter._...        12.39%     141.622ms        18.11%     207.015ms      69.005ms       0.000us         0.00%       0.000us       0.000us             3  \n",
            "                                            aten::empty         0.26%       2.959ms         0.26%       2.959ms       3.161us       0.000us         0.00%       0.000us       0.000us           936  \n",
            "                                         aten::uniform_         0.10%       1.148ms         0.10%       1.148ms       5.979us       0.000us         0.00%       0.000us       0.000us           192  \n",
            "                                             aten::item         0.07%     807.000us         0.09%     973.000us       1.374us       0.000us         0.00%       0.000us       0.000us           708  \n",
            "                              aten::_local_scalar_dense         0.02%     231.000us         0.02%     231.000us       0.326us       0.000us         0.00%       0.000us       0.000us           708  \n",
            "                                             aten::rand         0.05%     608.000us         0.11%       1.272ms      13.250us       0.000us         0.00%       0.000us       0.000us            96  \n",
            "                                               aten::lt         0.09%     976.000us         0.19%       2.227ms      23.198us       0.000us         0.00%       0.000us       0.000us            96  \n",
            "                                               aten::to         0.11%       1.211ms        54.85%     626.994ms     893.154us       0.000us         0.00%      13.076ms      18.627us           702  \n",
            "                                         aten::_to_copy         0.23%       2.585ms        54.77%     626.051ms       1.242ms       0.000us         0.00%      13.076ms      25.944us           504  \n",
            "-------------------------------------------------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  \n",
            "Self CPU time total: 1.143s\n",
            "Self CUDA time total: 1.126s\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(prof.key_averages(group_by_stack_n=5).table(sort_by=\"self_cuda_time_total\", row_limit=2))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-6JeJkznJnFL",
        "outputId": "951f6991-b9d5-48ce-e4e4-e10076b55524"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "-------------------------------------------------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  \n",
            "                                                   Name    Self CPU %      Self CPU   CPU total %     CPU total  CPU time avg     Self CUDA   Self CUDA %    CUDA total  CUDA time avg    # of Calls  \n",
            "-------------------------------------------------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  \n",
            "                             aten::convolution_backward         0.21%       2.345ms         0.38%       4.338ms     180.750us     282.811ms        25.11%     319.341ms      13.306ms            24  \n",
            "                                  volta_sgemm_128x64_nt         0.00%       0.000us         0.00%       0.000us       0.000us     184.778ms        16.41%     184.778ms       3.553ms            52  \n",
            "-------------------------------------------------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  \n",
            "Self CPU time total: 1.143s\n",
            "Self CUDA time total: 1.126s\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UGhIqttCJo5u",
        "outputId": "30dc2dcf-69ae-4b30-eb9f-1f214aeb2500"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!mv /content/log /content/drive/MyDrive"
      ],
      "metadata": {
        "id": "uefqh6jPJ7Kc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Profiling with Automatic Mixed Precision"
      ],
      "metadata": {
        "id": "NRigkrENP1Tm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch, time, gc\n",
        "\n",
        "# Timing utilities\n",
        "start_time = None\n",
        "\n",
        "def start_timer():\n",
        "    global start_time\n",
        "    gc.collect()\n",
        "    torch.cuda.empty_cache()\n",
        "    torch.cuda.reset_max_memory_allocated()\n",
        "    torch.cuda.synchronize()\n",
        "    start_time = time.time()\n",
        "\n",
        "def end_timer_and_print(local_msg):\n",
        "    torch.cuda.synchronize()\n",
        "    end_time = time.time()\n",
        "    print(\"\\n\" + local_msg)\n",
        "    print(\"Total execution time = {:.3f} sec\".format(end_time - start_time))\n",
        "    print(\"Max memory used by tensors = {} bytes\".format(torch.cuda.max_memory_allocated()))"
      ],
      "metadata": {
        "id": "VsLH_Xq_KdwN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.train()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "A7_jrcg-Q9rm",
        "outputId": "15425b85-eae5-4232-9ef5-b63d749e07c8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "VGG(\n",
              "  (features): Sequential(\n",
              "    (0): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "    (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    (2): ReLU(inplace=True)\n",
              "    (3): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
              "    (4): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "    (5): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    (6): ReLU(inplace=True)\n",
              "    (7): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
              "    (8): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "    (9): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    (10): ReLU(inplace=True)\n",
              "    (11): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "    (12): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    (13): ReLU(inplace=True)\n",
              "    (14): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
              "    (15): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "    (16): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    (17): ReLU(inplace=True)\n",
              "    (18): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "    (19): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    (20): ReLU(inplace=True)\n",
              "    (21): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
              "    (22): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "    (23): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    (24): ReLU(inplace=True)\n",
              "    (25): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "    (26): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    (27): ReLU(inplace=True)\n",
              "    (28): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
              "  )\n",
              "  (avgpool): AdaptiveAvgPool2d(output_size=7)\n",
              "  (classifier): Sequential(\n",
              "    (0): Linear(in_features=25088, out_features=4096, bias=True)\n",
              "    (1): ReLU(inplace=True)\n",
              "    (2): Dropout(p=0.5, inplace=False)\n",
              "    (3): Linear(in_features=4096, out_features=4096, bias=True)\n",
              "    (4): ReLU(inplace=True)\n",
              "    (5): Dropout(p=0.5, inplace=False)\n",
              "    (6): Linear(in_features=4096, out_features=10, bias=True)\n",
              "  )\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "use_amp = True\n",
        "scaler = torch.cuda.amp.GradScaler(enabled=use_amp)\n",
        "\n",
        "def train(data):\n",
        "  inputs, labels = data[0].to(device=device), data[1].to(device=device)\n",
        "  with torch.autocast(device_type='cuda', dtype=torch.float16, enabled=use_amp):\n",
        "    outputs,_ = model(inputs)\n",
        "    loss = criterion(outputs, labels)\n",
        "  scaler.scale(loss).backward()\n",
        "  scaler.step(optimizer)\n",
        "  scaler.update()\n",
        "  optimizer.zero_grad() # set_to_non"
      ],
      "metadata": {
        "id": "VTT_3WVRRBq0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "prof = torch.profiler.profile(\n",
        "        schedule=torch.profiler.schedule(wait=1, warmup=1, active=3, repeat=2),\n",
        "        on_trace_ready=torch.profiler.tensorboard_trace_handler('./log/vgg_amp'),\n",
        "        record_shapes=True,\n",
        "        with_stack=True)\n",
        "prof.start()\n",
        "start_timer()\n",
        "for step, batch_data in enumerate(train_loader):\n",
        "\n",
        "    if step >= (1 + 1 + 3) * 2:\n",
        "        break\n",
        "    train(batch_data)\n",
        "    prof.step()\n",
        "prof.stop()\n",
        "end_timer_and_print(\"Mixed precision:\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XJJr__9qSMLb",
        "outputId": "f5d733f4-a183-41cc-c0ab-ccae56443875"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/cuda/memory.py:303: FutureWarning: torch.cuda.reset_max_memory_allocated now calls torch.cuda.reset_peak_memory_stats, which resets /all/ peak memory stats.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Mixed precision:\n",
            "Total execution time = 13.434 sec\n",
            "Max memory used by tensors = 3745605120 bytes\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(prof.key_averages())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Yymu1yPaSr6l",
        "outputId": "9c5d0335-e613-4cae-c10e-e1e8ac6ad1e6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "-------------------------------------------------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  \n",
            "                                                   Name    Self CPU %      Self CPU   CPU total %     CPU total  CPU time avg     Self CUDA   Self CUDA %    CUDA total  CUDA time avg    # of Calls  \n",
            "-------------------------------------------------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  \n",
            "                                          ProfilerStep*         4.25%      30.750ms        91.85%     664.914ms     221.638ms       0.000us         0.00%     297.736ms      99.245ms             3  \n",
            "enumerate(DataLoader)#_SingleProcessDataLoaderIter._...        20.68%     149.674ms        29.75%     215.392ms      71.797ms       0.000us         0.00%       0.000us       0.000us             3  \n",
            "void at::native::(anonymous namespace)::multi_tensor...         0.00%       0.000us         0.00%       0.000us       0.000us      33.254ms         5.53%      33.254ms     627.434us            53  \n",
            "                                            aten::empty         0.46%       3.331ms         0.46%       3.331ms       3.547us       0.000us         0.00%       0.000us       0.000us           939  \n",
            "                                         aten::uniform_         0.16%       1.135ms         0.16%       1.135ms       5.911us       0.000us         0.00%       0.000us       0.000us           192  \n",
            "                                             aten::item         0.13%     969.000us        52.01%     376.529ms     529.577us       0.000us         0.00%       6.000us       0.008us           711  \n",
            "                              aten::_local_scalar_dense         0.03%     213.000us        51.89%     375.603ms     528.274us       6.000us         0.00%       6.000us       0.008us           711  \n",
            "                                             aten::rand         0.08%     609.000us         0.17%       1.200ms      12.500us       0.000us         0.00%       0.000us       0.000us            96  \n",
            "                                               aten::lt         0.14%       1.036ms         0.31%       2.277ms      23.719us       0.000us         0.00%       0.000us       0.000us            96  \n",
            "                                               aten::to         0.25%       1.834ms         4.02%      29.123ms      33.825us       0.000us         0.00%      32.921ms      38.236us           861  \n",
            "                                         aten::_to_copy         0.56%       4.029ms         3.85%      27.857ms      42.400us       0.000us         0.00%      33.008ms      50.240us           657  \n",
            "                                    aten::empty_strided         0.48%       3.446ms         0.48%       3.446ms       3.460us       0.000us         0.00%       0.000us       0.000us           996  \n",
            "                                            aten::copy_         3.21%      23.221ms         5.20%      37.652ms      44.349us      33.008ms         5.48%      33.008ms      38.879us           849  \n",
            "                                       aten::is_nonzero         0.05%     368.000us         0.10%     729.000us       3.797us       0.000us         0.00%       0.000us       0.000us           192  \n",
            "                                          aten::randint         0.13%     976.000us         0.24%       1.726ms       8.990us       0.000us         0.00%       0.000us       0.000us           192  \n",
            "                                          aten::random_         0.06%     424.000us         0.06%     424.000us       2.208us       0.000us         0.00%       0.000us       0.000us           192  \n",
            "void at::native::(anonymous namespace)::multi_tensor...         0.00%       0.000us         0.00%       0.000us       0.000us      25.344ms         4.21%      25.344ms     905.143us            28  \n",
            "                                       aten::lift_fresh         0.02%     114.000us         0.02%     114.000us       0.392us       0.000us         0.00%       0.000us       0.000us           291  \n",
            "                                             aten::view         0.14%       1.037ms         0.14%       1.037ms       2.954us       0.000us         0.00%       0.000us       0.000us           351  \n",
            "                                          aten::permute         0.08%     612.000us         0.10%     733.000us       7.635us       0.000us         0.00%       0.000us       0.000us            96  \n",
            "                                       aten::as_strided         0.04%     322.000us         0.04%     322.000us       1.220us       0.000us         0.00%       0.000us       0.000us           264  \n",
            "                                       aten::contiguous         0.08%     589.000us         1.31%       9.452ms      98.458us       0.000us         0.00%       0.000us       0.000us            96  \n",
            "                                            aten::clone         0.22%       1.578ms         2.46%      17.800ms      92.708us       0.000us         0.00%       0.000us       0.000us           192  \n",
            "                                       aten::empty_like         0.07%     538.000us         0.17%       1.254ms       8.708us       0.000us         0.00%       0.000us       0.000us           144  \n",
            "                                              aten::div         1.24%       8.961ms         1.36%       9.873ms     102.844us       0.000us         0.00%       0.000us       0.000us            96  \n",
            "                                               aten::eq         0.14%       1.000ms         0.27%       1.984ms      20.667us       0.000us         0.00%       0.000us       0.000us            96  \n",
            "                                              aten::any         0.13%     951.000us         0.15%       1.050ms      10.938us       0.000us         0.00%       0.000us       0.000us            96  \n",
            "                                            aten::fill_         0.03%     237.000us         0.07%     523.000us       4.252us       5.055ms         0.84%       5.055ms      41.098us           123  \n",
            "                                             aten::sub_         0.56%       4.088ms         0.56%       4.088ms      42.583us       0.000us         0.00%       0.000us       0.000us            96  \n",
            "                                             aten::div_         0.54%       3.936ms         0.54%       3.936ms      41.000us       0.000us         0.00%       0.000us       0.000us            96  \n",
            "void at::native::(anonymous namespace)::multi_tensor...         0.00%       0.000us         0.00%       0.000us       0.000us      25.298ms         4.20%      25.298ms     903.500us            28  \n",
            "void at::native::(anonymous namespace)::multi_tensor...         0.00%       0.000us         0.00%       0.000us       0.000us      17.976ms         2.99%      17.976ms     642.000us            28  \n",
            "void at::native::(anonymous namespace)::multi_tensor...         0.00%       0.000us         0.00%       0.000us       0.000us      18.018ms         2.99%      18.018ms     643.500us            28  \n",
            "void at::native::(anonymous namespace)::multi_tensor...         0.00%       0.000us         0.00%       0.000us       0.000us      17.956ms         2.98%      17.956ms     641.286us            28  \n",
            "void at::native::(anonymous namespace)::multi_tensor...         0.00%       0.000us         0.00%       0.000us       0.000us      33.239ms         5.52%      33.239ms       1.187ms            28  \n",
            "at::native::amp_update_scale_cuda_kernel(float*, int...         0.00%       0.000us         0.00%       0.000us       0.000us      13.000us         0.00%      13.000us       3.250us             4  \n",
            "                                            aten::stack         0.03%     248.000us         1.30%       9.423ms       3.141ms       0.000us         0.00%       0.000us       0.000us             3  \n",
            "                                              aten::cat         1.27%       9.165ms         1.27%       9.165ms       3.055ms       0.000us         0.00%       0.000us       0.000us             3  \n",
            "                                          aten::detach_         0.00%      13.000us         0.00%      16.000us       5.333us       0.000us         0.00%       0.000us       0.000us             3  \n",
            "                                                detach_         0.00%       5.000us         0.00%       5.000us       1.667us       0.000us         0.00%       0.000us       0.000us             3  \n",
            "                                        cudaMemcpyAsync        53.63%     388.254ms        53.63%     388.254ms      25.884ms       0.000us         0.00%       0.000us       0.000us            15  \n",
            "                       Memcpy HtoD (Pageable -> Device)         0.00%       0.000us         0.00%       0.000us       0.000us      11.987ms         1.99%      11.987ms       1.998ms             6  \n",
            "                                  cudaStreamSynchronize         0.02%     137.000us         0.02%     137.000us      15.222us       0.000us         0.00%       0.000us       0.000us             9  \n",
            "                                           aten::conv2d         0.05%     357.000us         1.66%      12.041ms     250.854us       0.000us         0.00%     148.769ms       3.099ms            48  \n",
            "                                       cudaLaunchKernel         1.13%       8.167ms         1.13%       8.167ms       8.955us      14.524ms         2.41%      14.524ms      15.925us           912  \n",
            "void at::native::unrolled_elementwise_kernel<at::nat...         0.00%       0.000us         0.00%       0.000us       0.000us      10.178ms         1.69%      10.178ms     141.361us            72  \n",
            "                                      aten::convolution         0.04%     284.000us         0.65%       4.721ms     196.708us       0.000us         0.00%      73.757ms       3.073ms            24  \n",
            "                                     aten::_convolution         0.06%     421.000us         0.61%       4.437ms     184.875us       0.000us         0.00%      73.757ms       3.073ms            24  \n",
            "                                aten::cudnn_convolution         0.24%       1.732ms         0.40%       2.862ms     119.250us      54.603ms         9.07%      59.079ms       2.462ms            24  \n",
            "                                  cudaStreamIsCapturing         0.01%      70.000us         0.01%      70.000us       0.556us       0.000us         0.00%       0.000us       0.000us           126  \n",
            "                                  cudaStreamGetPriority         0.00%      19.000us         0.00%      19.000us       0.162us       2.240ms         0.37%       2.240ms      19.145us           117  \n",
            "                       cudaDeviceGetStreamPriorityRange         0.00%      24.000us         0.00%      24.000us       0.205us       6.000us         0.00%       6.000us       0.051us           117  \n",
            "void cask_cudnn::computeOffsetsKernel<false, false>(...         0.00%       0.000us         0.00%       0.000us       0.000us      51.000us         0.01%      51.000us       3.400us            15  \n",
            "                                        cudaMemsetAsync         0.06%     459.000us         0.06%     459.000us       6.120us     271.000us         0.05%     271.000us       3.613us            75  \n",
            "cudnn_volta_fp16_scudnn_fp16_128x32_relu_small_nn_v1...         0.00%       0.000us         0.00%       0.000us       0.000us       4.388ms         0.73%       4.388ms       1.463ms             3  \n",
            "                                          aten::reshape         0.03%     197.000us         0.03%     245.000us       9.074us       0.000us         0.00%       0.000us       0.000us            27  \n",
            "                                   aten::_reshape_alias         0.01%      52.000us         0.01%      52.000us       1.926us       0.000us         0.00%       0.000us       0.000us            27  \n",
            "                                             aten::add_         0.20%       1.422ms         0.39%       2.822ms      16.698us      14.750ms         2.45%      14.750ms      87.278us           169  \n",
            "                                       aten::batch_norm         0.01%      89.000us         0.42%       3.011ms     125.458us       0.000us         0.00%      22.739ms     947.458us            24  \n",
            "                           aten::_batch_norm_impl_index         0.02%     164.000us         0.40%       2.922ms     121.750us       0.000us         0.00%      22.739ms     947.458us            24  \n",
            "                                 aten::cudnn_batch_norm         0.21%       1.555ms         0.38%       2.758ms     114.917us      22.739ms         3.78%      22.739ms     947.458us            24  \n",
            "                                            aten::relu_         0.08%     569.000us         0.18%       1.271ms      42.367us       0.000us         0.00%      11.543ms     384.767us            30  \n",
            "                                       aten::clamp_min_         0.05%     397.000us         0.10%     702.000us      23.400us      11.543ms         1.92%      11.543ms     384.767us            30  \n",
            "                                       aten::max_pool2d         0.01%      65.000us         0.09%     632.000us      42.133us       0.000us         0.00%      11.683ms     778.867us            15  \n",
            "                          aten::max_pool2d_with_indices         0.06%     410.000us         0.08%     567.000us      37.800us      11.683ms         1.94%      11.683ms     778.867us            15  \n",
            "                                                INVALID         0.06%     447.000us         0.06%     447.000us       8.278us      64.000us         0.01%      64.000us       1.185us            54  \n",
            "void at::native::elementwise_kernel<128, 4, at::nati...         0.00%       0.000us         0.00%       0.000us       0.000us      14.678ms         2.44%      14.678ms     611.583us            24  \n",
            "void at::native::vectorized_elementwise_kernel<4, at...         0.00%       0.000us         0.00%       0.000us       0.000us      72.000us         0.01%      72.000us       3.000us            24  \n",
            "void cudnn::bn_fw_tr_1C11_kernel_NCHW<__half, float,...         0.00%       0.000us         0.00%       0.000us       0.000us      15.976ms         2.65%      15.976ms       2.663ms             6  \n",
            "                              aten::adaptive_avg_pool2d         0.00%      13.000us         0.02%     148.000us      49.333us       0.000us         0.00%     844.000us     281.333us             3  \n",
            "                             aten::_adaptive_avg_pool2d         0.01%      65.000us         0.02%     135.000us      45.000us     844.000us         0.14%     844.000us     281.333us             3  \n",
            "                                          aten::resize_         0.00%      21.000us         0.00%      21.000us       3.500us       0.000us         0.00%       0.000us       0.000us             6  \n",
            "                                           aten::linear         0.01%      67.000us         0.47%       3.391ms     188.389us       0.000us         0.00%      16.472ms     915.111us            18  \n",
            "                                                aten::t         0.03%     195.000us         0.06%     408.000us       9.067us       0.000us         0.00%       0.000us       0.000us            45  \n",
            "                                        aten::transpose         0.02%     156.000us         0.03%     213.000us       4.733us       0.000us         0.00%       0.000us       0.000us            45  \n",
            "                                            aten::addmm         0.11%     775.000us         0.15%       1.067ms     118.556us       3.780ms         0.63%       3.780ms     420.000us             9  \n",
            "          cudaOccupancyMaxActiveBlocksPerMultiprocessor         0.01%      42.000us         0.01%      42.000us       2.800us       0.000us         0.00%       0.000us       0.000us            15  \n",
            "                                          aten::dropout         0.00%      28.000us         0.07%     486.000us      81.000us       0.000us         0.00%      33.000us       5.500us             6  \n",
            "                                   aten::native_dropout         0.03%     218.000us         0.06%     458.000us      76.333us      33.000us         0.01%      33.000us       5.500us             6  \n",
            "void at::native::vectorized_elementwise_kernel<4, at...         0.00%       0.000us         0.00%       0.000us       0.000us      11.543ms         1.92%      11.543ms     384.767us            30  \n",
            "cudaOccupancyMaxActiveBlocksPerMultiprocessorWithFla...         0.00%      22.000us         0.00%      22.000us       1.833us       0.000us         0.00%       0.000us       0.000us            12  \n",
            "                               aten::cross_entropy_loss         0.00%      30.000us         0.07%     537.000us     179.000us       0.000us         0.00%      28.000us       9.333us             3  \n",
            "                                      aten::log_softmax         0.00%      28.000us         0.03%     210.000us      70.000us       0.000us         0.00%       9.000us       3.000us             3  \n",
            "                                     aten::_log_softmax         0.02%     127.000us         0.03%     182.000us      60.667us       9.000us         0.00%       9.000us       3.000us             3  \n",
            "                                      aten::nll_loss_nd         0.00%      12.000us         0.04%     297.000us      99.000us       0.000us         0.00%      19.000us       6.333us             3  \n",
            "                                         aten::nll_loss         0.00%      32.000us         0.06%     416.000us      69.333us       0.000us         0.00%      28.000us       4.667us             6  \n",
            "                                 aten::nll_loss_forward         0.01%      86.000us         0.02%     117.000us      39.000us       9.000us         0.00%       9.000us       3.000us             3  \n",
            "                                              aten::mul         0.02%     156.000us         0.03%     251.000us      41.833us      14.000us         0.00%      14.000us       2.333us             6  \n",
            "                                        aten::ones_like         0.00%      18.000us         0.02%     138.000us      46.000us       0.000us         0.00%       6.000us       2.000us             3  \n",
            "      autograd::engine::evaluate_function: MulBackward0         0.01%      69.000us         0.05%     371.000us     123.667us       0.000us         0.00%      26.000us       8.667us             3  \n",
            "                                           MulBackward0         0.01%      41.000us         0.02%     165.000us      55.000us       0.000us         0.00%       7.000us       2.333us             3  \n",
            "                                              aten::sum         0.13%     946.000us         0.19%       1.372ms      38.111us       8.215ms         1.36%       8.215ms     228.194us            36  \n",
            "autograd::engine::evaluate_function: NllLossBackward...         0.00%      34.000us         0.03%     216.000us      72.000us       0.000us         0.00%      15.000us       5.000us             3  \n",
            "                                       NllLossBackward0         0.00%      17.000us         0.03%     182.000us      60.667us       0.000us         0.00%      15.000us       5.000us             3  \n",
            "                                aten::nll_loss_backward         0.01%      59.000us         0.02%     165.000us      55.000us       9.000us         0.00%      15.000us       5.000us             3  \n",
            "                                            aten::zero_         0.01%      90.000us         0.07%     478.000us      22.762us       0.000us         0.00%       5.040ms     240.000us            21  \n",
            "autograd::engine::evaluate_function: ToCopyBackward0...         0.05%     331.000us         0.42%       3.064ms      44.406us       0.000us         0.00%      10.804ms     156.580us            69  \n",
            "                                        ToCopyBackward0         0.04%     282.000us         0.36%       2.605ms      37.754us       0.000us         0.00%      10.780ms     156.232us            69  \n",
            "autograd::engine::evaluate_function: LogSoftmaxBackw...         0.00%      23.000us         0.02%     121.000us      40.333us       0.000us         0.00%       8.000us       2.667us             3  \n",
            "                                    LogSoftmaxBackward0         0.00%      20.000us         0.01%      98.000us      32.667us       0.000us         0.00%       8.000us       2.667us             3  \n",
            "-------------------------------------------------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  \n",
            "Self CPU time total: 723.897ms\n",
            "Self CUDA time total: 601.840ms\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(prof.key_averages().table(sort_by=\"cpu_time_total\", row_limit=10))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xDczy_94TaTc",
        "outputId": "b1e80fc0-647c-41a3-dc12-a2c67ab16dff"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "-------------------------------------------------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  \n",
            "                                                   Name    Self CPU %      Self CPU   CPU total %     CPU total  CPU time avg     Self CUDA   Self CUDA %    CUDA total  CUDA time avg    # of Calls  \n",
            "-------------------------------------------------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  \n",
            "                                          ProfilerStep*         4.25%      30.750ms        91.85%     664.914ms     221.638ms       0.000us         0.00%     297.736ms      99.245ms             3  \n",
            "                                        cudaMemcpyAsync        53.63%     388.254ms        53.63%     388.254ms      25.884ms       0.000us         0.00%       0.000us       0.000us            15  \n",
            "                                             aten::item         0.13%     969.000us        52.01%     376.529ms     529.577us       0.000us         0.00%       6.000us       0.008us           711  \n",
            "                              aten::_local_scalar_dense         0.03%     213.000us        51.89%     375.603ms     528.274us       6.000us         0.00%       6.000us       0.008us           711  \n",
            "enumerate(DataLoader)#_SingleProcessDataLoaderIter._...        20.68%     149.674ms        29.75%     215.392ms      71.797ms       0.000us         0.00%       0.000us       0.000us             3  \n",
            "                                  cudaDeviceSynchronize         5.65%      40.910ms         5.65%      40.910ms      40.910ms       0.000us         0.00%       0.000us       0.000us             1  \n",
            "                                            aten::copy_         3.21%      23.221ms         5.20%      37.652ms      44.349us      33.008ms         5.48%      33.008ms      38.879us           849  \n",
            "                                               aten::to         0.25%       1.834ms         4.02%      29.123ms      33.825us       0.000us         0.00%      32.921ms      38.236us           861  \n",
            "                                         aten::_to_copy         0.56%       4.029ms         3.85%      27.857ms      42.400us       0.000us         0.00%      33.008ms      50.240us           657  \n",
            "                                            aten::clone         0.22%       1.578ms         2.46%      17.800ms      92.708us       0.000us         0.00%       0.000us       0.000us           192  \n",
            "-------------------------------------------------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  \n",
            "Self CPU time total: 723.897ms\n",
            "Self CUDA time total: 601.840ms\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(prof.key_averages(group_by_input_shape=True).table(sort_by=\"cpu_time_total\", row_limit=10))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1EtcnT1lTfb1",
        "outputId": "d3d3a6a6-31dc-47e1-c9bc-fea8e5284bd6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "-------------------------------------------------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  --------------------------------------------------------------------------------  \n",
            "                                                   Name    Self CPU %      Self CPU   CPU total %     CPU total  CPU time avg     Self CUDA   Self CUDA %    CUDA total  CUDA time avg    # of Calls                                                                      Input Shapes  \n",
            "-------------------------------------------------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  --------------------------------------------------------------------------------  \n",
            "                                          ProfilerStep*         4.25%      30.750ms        91.85%     664.914ms     221.638ms       0.000us         0.00%     297.736ms      99.245ms             3                                                                                []  \n",
            "                                        cudaMemcpyAsync        53.63%     388.254ms        53.63%     388.254ms      25.884ms       0.000us         0.00%       0.000us       0.000us            15                                                                                []  \n",
            "                                             aten::item         0.09%     632.000us        51.96%     376.160ms     971.990us       0.000us         0.00%       6.000us       0.016us           387                                                                             [[1]]  \n",
            "                              aten::_local_scalar_dense         0.02%     167.000us        51.88%     375.557ms     970.432us       6.000us         0.00%       6.000us       0.016us           387                                                                             [[1]]  \n",
            "enumerate(DataLoader)#_SingleProcessDataLoaderIter._...        20.68%     149.674ms        29.75%     215.392ms      71.797ms       0.000us         0.00%       0.000us       0.000us             3                                                                                []  \n",
            "                                  cudaDeviceSynchronize         5.65%      40.910ms         5.65%      40.910ms      40.910ms       0.000us         0.00%       0.000us       0.000us             1                                                                                []  \n",
            "                                            aten::copy_         2.89%      20.917ms         2.89%      20.917ms      72.628us       0.000us         0.00%       0.000us       0.000us           288                                                [[3, 224, 224], [3, 224, 224], []]  \n",
            "                                            aten::clone         0.22%       1.578ms         2.46%      17.800ms      92.708us       0.000us         0.00%       0.000us       0.000us           192                                                               [[3, 224, 224], []]  \n",
            "                                         aten::_to_copy         0.01%      44.000us         1.80%      13.036ms       2.173ms       0.000us         0.00%      12.335ms       2.056ms             6                                       [[32, 3, 224, 224], [], [], [], [], [], []]  \n",
            "                                               aten::to         0.01%      64.000us         1.80%      13.032ms       4.344ms       0.000us         0.00%      11.984ms       3.995ms             3                                   [[32, 3, 224, 224], [], [], [], [], [], [], []]  \n",
            "-------------------------------------------------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  --------------------------------------------------------------------------------  \n",
            "Self CPU time total: 723.897ms\n",
            "Self CUDA time total: 601.840ms\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(prof.key_averages().table(sort_by=\"cuda_time_total\", row_limit=10))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YdEGlC6STkLP",
        "outputId": "2694a77f-f6b8-4480-dfdf-2c60d4b29b4f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "-------------------------------------------------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  \n",
            "                                                   Name    Self CPU %      Self CPU   CPU total %     CPU total  CPU time avg     Self CUDA   Self CUDA %    CUDA total  CUDA time avg    # of Calls  \n",
            "-------------------------------------------------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  \n",
            "                                          ProfilerStep*         4.25%      30.750ms        91.85%     664.914ms     221.638ms       0.000us         0.00%     297.736ms      99.245ms             3  \n",
            "                                           aten::conv2d         0.05%     357.000us         1.66%      12.041ms     250.854us       0.000us         0.00%     148.769ms       3.099ms            48  \n",
            "autograd::engine::evaluate_function: ConvolutionBack...         0.05%     373.000us         0.85%       6.168ms     257.000us       0.000us         0.00%     143.162ms       5.965ms            24  \n",
            "                                   ConvolutionBackward0         0.03%     184.000us         0.80%       5.795ms     241.458us       0.000us         0.00%     143.162ms       5.965ms            24  \n",
            "                             aten::convolution_backward         0.38%       2.751ms         0.78%       5.611ms     233.792us     131.885ms        21.91%     143.162ms       5.965ms            24  \n",
            "                               Optimizer.step#Adam.step         0.90%       6.520ms         1.71%      12.390ms       4.130ms       0.000us         0.00%     137.702ms      45.901ms             3  \n",
            "                                      aten::convolution         0.04%     284.000us         0.65%       4.721ms     196.708us       0.000us         0.00%      73.757ms       3.073ms            24  \n",
            "                                     aten::_convolution         0.06%     421.000us         0.61%       4.437ms     184.875us       0.000us         0.00%      73.757ms       3.073ms            24  \n",
            "                                aten::cudnn_convolution         0.24%       1.732ms         0.40%       2.862ms     119.250us      54.603ms         9.07%      59.079ms       2.462ms            24  \n",
            "autograd::engine::evaluate_function: MaxPool2DWithIn...         0.03%     184.000us         0.15%       1.054ms      70.267us       0.000us         0.00%      55.966ms       3.731ms            15  \n",
            "-------------------------------------------------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  \n",
            "Self CPU time total: 723.897ms\n",
            "Self CUDA time total: 601.840ms\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(prof.key_averages().table(sort_by=\"self_cpu_memory_usage\", row_limit=10))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rP-JwEMrTmsi",
        "outputId": "9568d39a-408f-4b02-d3cc-61fe37550cc0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "-------------------------------------------------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  \n",
            "                                                   Name    Self CPU %      Self CPU   CPU total %     CPU total  CPU time avg     Self CUDA   Self CUDA %    CUDA total  CUDA time avg    # of Calls  \n",
            "-------------------------------------------------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  \n",
            "                                          ProfilerStep*         4.25%      30.750ms        91.85%     664.914ms     221.638ms       0.000us         0.00%     297.736ms      99.245ms             3  \n",
            "enumerate(DataLoader)#_SingleProcessDataLoaderIter._...        20.68%     149.674ms        29.75%     215.392ms      71.797ms       0.000us         0.00%       0.000us       0.000us             3  \n",
            "void at::native::(anonymous namespace)::multi_tensor...         0.00%       0.000us         0.00%       0.000us       0.000us      33.254ms         5.53%      33.254ms     627.434us            53  \n",
            "                                            aten::empty         0.46%       3.331ms         0.46%       3.331ms       3.547us       0.000us         0.00%       0.000us       0.000us           939  \n",
            "                                         aten::uniform_         0.16%       1.135ms         0.16%       1.135ms       5.911us       0.000us         0.00%       0.000us       0.000us           192  \n",
            "                                             aten::item         0.13%     969.000us        52.01%     376.529ms     529.577us       0.000us         0.00%       6.000us       0.008us           711  \n",
            "                              aten::_local_scalar_dense         0.03%     213.000us        51.89%     375.603ms     528.274us       6.000us         0.00%       6.000us       0.008us           711  \n",
            "                                             aten::rand         0.08%     609.000us         0.17%       1.200ms      12.500us       0.000us         0.00%       0.000us       0.000us            96  \n",
            "                                               aten::lt         0.14%       1.036ms         0.31%       2.277ms      23.719us       0.000us         0.00%       0.000us       0.000us            96  \n",
            "                                               aten::to         0.25%       1.834ms         4.02%      29.123ms      33.825us       0.000us         0.00%      32.921ms      38.236us           861  \n",
            "-------------------------------------------------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  \n",
            "Self CPU time total: 723.897ms\n",
            "Self CUDA time total: 601.840ms\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(prof.key_averages().table(sort_by=\"cpu_memory_usage\", row_limit=10))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XHkeq9EGTo9e",
        "outputId": "9b352688-5699-4367-daa0-f256abf86b02"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "-------------------------------------------------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  \n",
            "                                                   Name    Self CPU %      Self CPU   CPU total %     CPU total  CPU time avg     Self CUDA   Self CUDA %    CUDA total  CUDA time avg    # of Calls  \n",
            "-------------------------------------------------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  \n",
            "                                          ProfilerStep*         4.25%      30.750ms        91.85%     664.914ms     221.638ms       0.000us         0.00%     297.736ms      99.245ms             3  \n",
            "enumerate(DataLoader)#_SingleProcessDataLoaderIter._...        20.68%     149.674ms        29.75%     215.392ms      71.797ms       0.000us         0.00%       0.000us       0.000us             3  \n",
            "void at::native::(anonymous namespace)::multi_tensor...         0.00%       0.000us         0.00%       0.000us       0.000us      33.254ms         5.53%      33.254ms     627.434us            53  \n",
            "                                            aten::empty         0.46%       3.331ms         0.46%       3.331ms       3.547us       0.000us         0.00%       0.000us       0.000us           939  \n",
            "                                         aten::uniform_         0.16%       1.135ms         0.16%       1.135ms       5.911us       0.000us         0.00%       0.000us       0.000us           192  \n",
            "                                             aten::item         0.13%     969.000us        52.01%     376.529ms     529.577us       0.000us         0.00%       6.000us       0.008us           711  \n",
            "                              aten::_local_scalar_dense         0.03%     213.000us        51.89%     375.603ms     528.274us       6.000us         0.00%       6.000us       0.008us           711  \n",
            "                                             aten::rand         0.08%     609.000us         0.17%       1.200ms      12.500us       0.000us         0.00%       0.000us       0.000us            96  \n",
            "                                               aten::lt         0.14%       1.036ms         0.31%       2.277ms      23.719us       0.000us         0.00%       0.000us       0.000us            96  \n",
            "                                               aten::to         0.25%       1.834ms         4.02%      29.123ms      33.825us       0.000us         0.00%      32.921ms      38.236us           861  \n",
            "-------------------------------------------------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  \n",
            "Self CPU time total: 723.897ms\n",
            "Self CUDA time total: 601.840ms\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(prof.key_averages(group_by_stack_n=5).table(sort_by=\"self_cuda_time_total\", row_limit=2))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YU3PY2-4TrOs",
        "outputId": "3040fa08-ab89-4390-f989-814d8ae93caf"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "-------------------------------------------------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  \n",
            "                                                   Name    Self CPU %      Self CPU   CPU total %     CPU total  CPU time avg     Self CUDA   Self CUDA %    CUDA total  CUDA time avg    # of Calls  \n",
            "-------------------------------------------------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  \n",
            "                             aten::convolution_backward         0.38%       2.751ms         0.78%       5.611ms     233.792us     131.885ms        21.91%     143.162ms       5.965ms            24  \n",
            "                                aten::cudnn_convolution         0.24%       1.732ms         0.40%       2.862ms     119.250us      54.603ms         9.07%      59.079ms       2.462ms            24  \n",
            "-------------------------------------------------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  \n",
            "Self CPU time total: 723.897ms\n",
            "Self CUDA time total: 601.840ms\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_2B5T1odTuuk",
        "outputId": "ff18b724-e76f-405c-8b1c-c0e8910986fd"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!mv /content/log /content/drive/MyDrive"
      ],
      "metadata": {
        "id": "tFM2ACVyUFrR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "IfrXPibHUWQ-"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}